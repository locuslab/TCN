{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import sys\n",
    "sys.path.append(\"../../\")\n",
    "from TCN.mnist_pixel.utils import data_generator\n",
    "from TCN.mnist_pixel.model import TCN\n",
    "import numpy as np\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def customOneHotEncoder(data):\n",
    "    dataAdjust = data.ljust(200,'0')[:200] # padding if not of length and adjusting the data lenght to get a 200x39 input matrix\n",
    "    # define universe of possible input values\n",
    "    alphabet = '0123456789abcdefghijklmnopqrstuvwxyz,._'\n",
    "    # define a mapping of chars to integers\n",
    "    char_to_int = dict((c, i) for i, c in enumerate(alphabet))\n",
    "    int_to_char = dict((i, c) for i, c in enumerate(alphabet))\n",
    "    # integer encode input data\n",
    "    integer_encoded = [char_to_int[char] for char in dataAdjust]\n",
    "    #print(integer_encoded)\n",
    "    # one hot encode\n",
    "    onehot_encoded = list()\n",
    "    for i, value in enumerate(integer_encoded):\n",
    "        letter = [0 for _ in range(len(alphabet))]\n",
    "        letter[value] = 1\n",
    "        onehot_encoded.append(letter)\n",
    "    #print(onehot_encoded) # the real encoding\n",
    "    return onehot_encoded\n",
    "\n",
    "# takes a .csv filename\n",
    "def dataPreprocessing(fileName):\n",
    "    df = pd.read_csv(fileName, header = None)\n",
    "    \n",
    "    #prepare the imput data\n",
    "    xString = df.iloc[:,:41].to_string(header=False, index=False, index_names = False).split('\\n')\n",
    "    xList = [','.join(ele.split()) for ele in xString] # gives comma separated strings for each row of DataFrame\n",
    "    xData = []\n",
    "    for string in xList:\n",
    "        stringLower = string.lower()\n",
    "        oneHot = customOneHotEncoder(stringLower)\n",
    "        xData.append(oneHot)\n",
    "    xMid = np.array(xData)\n",
    "    xArray = xMid.transpose(0,2,1) # convert xMid's dim (size, 200, 39) to (size, 39, 200)\n",
    "    \n",
    "    #prepare the label data\n",
    "    df[41] = np.where(df[41]=='normal', 'normal', 'attack') # replacing anything except 'normal' with 'attack'\n",
    "    Ydf = df[41]\n",
    "    #labelName = Ydf.unique().tolist().sort() # sorted 38 label names\n",
    "    #yArray = Ydf.str.get_dummies().to_numpy() # ndarray of shape(rows/lines, 38)\n",
    "    yArray = Ydf.to_numpy()\n",
    "    \n",
    "    assert xArray.shape[0] == yArray.shape[0], 'unequal input and label sample size'\n",
    "    \n",
    "    \n",
    "    return xArray, yArray # return processed array of input and label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class NSLKDDDataset(Dataset):\n",
    "    def __init__(self, fileName):\n",
    "        self.data = pd.read_csv(fileName, header = None)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # prepare x data\n",
    "        string = list(','.join('%s' %x for x in y) for y in self.data.iloc[[idx], :41].values)\n",
    "        stringLower = string[0].lower()\n",
    "        xData = customOneHotEncoder(stringLower) # Dim (200, 39)\n",
    "        xMid = np.array(xData)\n",
    "        xArray = xMid.transpose() # should be now (39, 200)\n",
    "        \n",
    "        # prepate y data\n",
    "        #self.data.iloc[idx, 41] = np.where(self.data.iloc[idx, 41]=='normal', 0, 1) # replacing normals with 0 and anything else with 1\n",
    "        yArray = np.where(self.data.iloc[idx, 41]=='normal', 0, 1)\n",
    "        \n",
    "        #yArray = Ydf.to_numpy()\n",
    "    \n",
    "        #assert xArray.shape == yArray.shape, 'unequal input and label sample size'\n",
    "        \n",
    "        return torch.from_numpy(xArray), torch.from_numpy(yArray) # returns torch tensor of x and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'batch_size': 64, 'shuffle': True}\n",
    "fileNameTrain = 'KDDTrain+.csv'\n",
    "fileNameTest = 'KDDTest+.csv'\n",
    "datasetTrain = NSLKDDDataset(fileNameTrain)\n",
    "datasetTest = NSLKDDDataset(fileNameTest)\n",
    "dataGeneratorTrain = DataLoader(datasetTrain, **params)\n",
    "dataGeneratorTest = DataLoader(datasetTest, **params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = './data/mnist'\n",
    "batch_size = 64\n",
    "n_classes = 2\n",
    "input_channels = 39\n",
    "seq_length = int(200)\n",
    "epochs = 100\n",
    "steps = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_loader, test_loader = data_generator(root, batch_size)\n",
    "\n",
    "permute = torch.Tensor(np.random.permutation(784).astype(np.float64)).long()\n",
    "channel_sizes = [32] * 6 #hidden nodes times levels \n",
    "kernel_size = 5\n",
    "model = TCN(input_channels, n_classes, channel_sizes, kernel_size=kernel_size, dropout=0.25)\n",
    "\n",
    "\n",
    "lr = 1e-5\n",
    "optimizer = getattr(optim, 'Adam')(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(ep):\n",
    "    global steps\n",
    "    train_loss = 0\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(dataGeneratorTrain):\n",
    "        # print('data Shape: {} target shape: {} data type: {}'.format(data.shape, target.shape, type(data)))\n",
    "        optimizer.zero_grad()\n",
    "        data = data.view(-1, input_channels, seq_length)\n",
    "        data, target = Variable(data), Variable(target)\n",
    "        #print('data Shape: {} target shape: {} data type: {}'.format(data.shape, target.shape, type(data)))\n",
    "        #print(target)\n",
    "        optimizer.zero_grad()\n",
    "        #print(data[0])\n",
    "        data = data.type(torch.FloatTensor)\n",
    "        output = model(data)\n",
    "        #print(output.shape)\n",
    "        target = target.type(torch.LongTensor)\n",
    "        #loss1 = torch.nn.CrossEntropyLoss()\n",
    "        loss = F.nll_loss(output, target) # negative log likelihood\n",
    "        #loss = loss1(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss\n",
    "        steps += seq_length\n",
    "        if batch_idx > 0 and batch_idx % 100 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\\tSteps: {}'.format(\n",
    "                ep, batch_idx * batch_size, len(dataGeneratorTrain.dataset),\n",
    "                100. * batch_idx / len(dataGeneratorTrain), train_loss.item()/100, steps))\n",
    "            train_loss = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in dataGeneratorTest:\n",
    "            model.eval()\n",
    "            #data = data.view(-1, input_channels, seq_length)\n",
    "            data = data.type(torch.FloatTensor)\n",
    "            target = target.type(torch.LongTensor)\n",
    "            data, target = Variable(data, volatile=True), Variable(target)\n",
    "            output = model(data)\n",
    "            #loss1 = torch.nn.CrossEntropyLoss()\n",
    "            test_loss += F.nll_loss(output, target, size_average=False).item()\n",
    "            #test_loss += loss1(output, target).item()\n",
    "            #print(output.data.max(1, keepdim=True)[1])\n",
    "            pred = output.data.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "\n",
    "        test_loss /= len(dataGeneratorTest.dataset)\n",
    "        print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "            test_loss, correct, len(dataGeneratorTest.dataset),\n",
    "            100. * correct / len(dataGeneratorTest.dataset)))\n",
    "        return test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [6400/125973 (5%)]\tLoss: 0.700333\tSteps: 20200\n",
      "Train Epoch: 1 [12800/125973 (10%)]\tLoss: 0.692618\tSteps: 40200\n",
      "Train Epoch: 1 [19200/125973 (15%)]\tLoss: 0.691375\tSteps: 60200\n",
      "Train Epoch: 1 [25600/125973 (20%)]\tLoss: 0.691529\tSteps: 80200\n",
      "Train Epoch: 1 [32000/125973 (25%)]\tLoss: 0.690802\tSteps: 100200\n",
      "Train Epoch: 1 [38400/125973 (30%)]\tLoss: 0.691262\tSteps: 120200\n",
      "Train Epoch: 1 [44800/125973 (36%)]\tLoss: 0.691608\tSteps: 140200\n",
      "Train Epoch: 1 [51200/125973 (41%)]\tLoss: 0.689336\tSteps: 160200\n",
      "Train Epoch: 1 [57600/125973 (46%)]\tLoss: 0.689111\tSteps: 180200\n",
      "Train Epoch: 1 [64000/125973 (51%)]\tLoss: 0.690009\tSteps: 200200\n",
      "Train Epoch: 1 [70400/125973 (56%)]\tLoss: 0.688937\tSteps: 220200\n",
      "Train Epoch: 1 [76800/125973 (61%)]\tLoss: 0.689055\tSteps: 240200\n",
      "Train Epoch: 1 [83200/125973 (66%)]\tLoss: 0.688812\tSteps: 260200\n",
      "Train Epoch: 1 [89600/125973 (71%)]\tLoss: 0.689421\tSteps: 280200\n",
      "Train Epoch: 1 [96000/125973 (76%)]\tLoss: 0.687710\tSteps: 300200\n",
      "Train Epoch: 1 [102400/125973 (81%)]\tLoss: 0.688084\tSteps: 320200\n",
      "Train Epoch: 1 [108800/125973 (86%)]\tLoss: 0.685445\tSteps: 340200\n",
      "Train Epoch: 1 [115200/125973 (91%)]\tLoss: 0.684581\tSteps: 360200\n",
      "Train Epoch: 1 [121600/125973 (96%)]\tLoss: 0.683403\tSteps: 380200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lromo\\OneDrive\\Documents\\virtualenvs\\netsec\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "C:\\Users\\lromo\\OneDrive\\Documents\\virtualenvs\\netsec\\lib\\site-packages\\torch\\nn\\_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.6951, Accuracy: 9711/22544 (43%)\n",
      "\n",
      "Train Epoch: 2 [6400/125973 (5%)]\tLoss: 0.686933\tSteps: 414000\n",
      "Train Epoch: 2 [12800/125973 (10%)]\tLoss: 0.678061\tSteps: 434000\n",
      "Train Epoch: 2 [19200/125973 (15%)]\tLoss: 0.673154\tSteps: 454000\n",
      "Train Epoch: 2 [25600/125973 (20%)]\tLoss: 0.666039\tSteps: 474000\n",
      "Train Epoch: 2 [32000/125973 (25%)]\tLoss: 0.657392\tSteps: 494000\n",
      "Train Epoch: 2 [38400/125973 (30%)]\tLoss: 0.646876\tSteps: 514000\n",
      "Train Epoch: 2 [44800/125973 (36%)]\tLoss: 0.632886\tSteps: 534000\n",
      "Train Epoch: 2 [51200/125973 (41%)]\tLoss: 0.616019\tSteps: 554000\n",
      "Train Epoch: 2 [57600/125973 (46%)]\tLoss: 0.586588\tSteps: 574000\n",
      "Train Epoch: 2 [64000/125973 (51%)]\tLoss: 0.553573\tSteps: 594000\n",
      "Train Epoch: 2 [70400/125973 (56%)]\tLoss: 0.511505\tSteps: 614000\n",
      "Train Epoch: 2 [76800/125973 (61%)]\tLoss: 0.457157\tSteps: 634000\n",
      "Train Epoch: 2 [83200/125973 (66%)]\tLoss: 0.406290\tSteps: 654000\n",
      "Train Epoch: 2 [89600/125973 (71%)]\tLoss: 0.357387\tSteps: 674000\n",
      "Train Epoch: 2 [96000/125973 (76%)]\tLoss: 0.321909\tSteps: 694000\n",
      "Train Epoch: 2 [102400/125973 (81%)]\tLoss: 0.292552\tSteps: 714000\n",
      "Train Epoch: 2 [108800/125973 (86%)]\tLoss: 0.278460\tSteps: 734000\n",
      "Train Epoch: 2 [115200/125973 (91%)]\tLoss: 0.253487\tSteps: 754000\n",
      "Train Epoch: 2 [121600/125973 (96%)]\tLoss: 0.248249\tSteps: 774000\n",
      "\n",
      "Test set: Average loss: 0.4165, Accuracy: 18116/22544 (80%)\n",
      "\n",
      "Train Epoch: 3 [6400/125973 (5%)]\tLoss: 0.220476\tSteps: 807800\n",
      "Train Epoch: 3 [12800/125973 (10%)]\tLoss: 0.221158\tSteps: 827800\n",
      "Train Epoch: 3 [19200/125973 (15%)]\tLoss: 0.199345\tSteps: 847800\n",
      "Train Epoch: 3 [25600/125973 (20%)]\tLoss: 0.212466\tSteps: 867800\n",
      "Train Epoch: 3 [32000/125973 (25%)]\tLoss: 0.205613\tSteps: 887800\n",
      "Train Epoch: 3 [38400/125973 (30%)]\tLoss: 0.204725\tSteps: 907800\n",
      "Train Epoch: 3 [44800/125973 (36%)]\tLoss: 0.206929\tSteps: 927800\n",
      "Train Epoch: 3 [51200/125973 (41%)]\tLoss: 0.183419\tSteps: 947800\n",
      "Train Epoch: 3 [57600/125973 (46%)]\tLoss: 0.179793\tSteps: 967800\n",
      "Train Epoch: 3 [64000/125973 (51%)]\tLoss: 0.196304\tSteps: 987800\n",
      "Train Epoch: 3 [70400/125973 (56%)]\tLoss: 0.176857\tSteps: 1007800\n",
      "Train Epoch: 3 [76800/125973 (61%)]\tLoss: 0.174264\tSteps: 1027800\n",
      "Train Epoch: 3 [83200/125973 (66%)]\tLoss: 0.177899\tSteps: 1047800\n",
      "Train Epoch: 3 [89600/125973 (71%)]\tLoss: 0.175734\tSteps: 1067800\n",
      "Train Epoch: 3 [96000/125973 (76%)]\tLoss: 0.163768\tSteps: 1087800\n",
      "Train Epoch: 3 [102400/125973 (81%)]\tLoss: 0.178283\tSteps: 1107800\n",
      "Train Epoch: 3 [108800/125973 (86%)]\tLoss: 0.169860\tSteps: 1127800\n",
      "Train Epoch: 3 [115200/125973 (91%)]\tLoss: 0.177161\tSteps: 1147800\n",
      "Train Epoch: 3 [121600/125973 (96%)]\tLoss: 0.166871\tSteps: 1167800\n",
      "\n",
      "Test set: Average loss: 0.5319, Accuracy: 17295/22544 (77%)\n",
      "\n",
      "Train Epoch: 4 [6400/125973 (5%)]\tLoss: 0.161421\tSteps: 1201600\n",
      "Train Epoch: 4 [12800/125973 (10%)]\tLoss: 0.161880\tSteps: 1221600\n",
      "Train Epoch: 4 [19200/125973 (15%)]\tLoss: 0.168643\tSteps: 1241600\n",
      "Train Epoch: 4 [25600/125973 (20%)]\tLoss: 0.151034\tSteps: 1261600\n",
      "Train Epoch: 4 [32000/125973 (25%)]\tLoss: 0.151836\tSteps: 1281600\n",
      "Train Epoch: 4 [38400/125973 (30%)]\tLoss: 0.147145\tSteps: 1301600\n",
      "Train Epoch: 4 [44800/125973 (36%)]\tLoss: 0.151078\tSteps: 1321600\n",
      "Train Epoch: 4 [51200/125973 (41%)]\tLoss: 0.150433\tSteps: 1341600\n",
      "Train Epoch: 4 [57600/125973 (46%)]\tLoss: 0.150594\tSteps: 1361600\n",
      "Train Epoch: 4 [64000/125973 (51%)]\tLoss: 0.152543\tSteps: 1381600\n",
      "Train Epoch: 4 [70400/125973 (56%)]\tLoss: 0.153182\tSteps: 1401600\n",
      "Train Epoch: 4 [76800/125973 (61%)]\tLoss: 0.156608\tSteps: 1421600\n",
      "Train Epoch: 4 [83200/125973 (66%)]\tLoss: 0.140340\tSteps: 1441600\n",
      "Train Epoch: 4 [89600/125973 (71%)]\tLoss: 0.140179\tSteps: 1461600\n",
      "Train Epoch: 4 [96000/125973 (76%)]\tLoss: 0.134444\tSteps: 1481600\n",
      "Train Epoch: 4 [102400/125973 (81%)]\tLoss: 0.132921\tSteps: 1501600\n",
      "Train Epoch: 4 [108800/125973 (86%)]\tLoss: 0.137269\tSteps: 1521600\n",
      "Train Epoch: 4 [115200/125973 (91%)]\tLoss: 0.139151\tSteps: 1541600\n",
      "Train Epoch: 4 [121600/125973 (96%)]\tLoss: 0.132805\tSteps: 1561600\n",
      "\n",
      "Test set: Average loss: 0.6145, Accuracy: 17301/22544 (77%)\n",
      "\n",
      "Train Epoch: 5 [6400/125973 (5%)]\tLoss: 0.150300\tSteps: 1595400\n",
      "Train Epoch: 5 [12800/125973 (10%)]\tLoss: 0.130036\tSteps: 1615400\n",
      "Train Epoch: 5 [19200/125973 (15%)]\tLoss: 0.135338\tSteps: 1635400\n",
      "Train Epoch: 5 [25600/125973 (20%)]\tLoss: 0.129910\tSteps: 1655400\n",
      "Train Epoch: 5 [32000/125973 (25%)]\tLoss: 0.126714\tSteps: 1675400\n",
      "Train Epoch: 5 [38400/125973 (30%)]\tLoss: 0.129713\tSteps: 1695400\n",
      "Train Epoch: 5 [44800/125973 (36%)]\tLoss: 0.126106\tSteps: 1715400\n",
      "Train Epoch: 5 [51200/125973 (41%)]\tLoss: 0.135949\tSteps: 1735400\n",
      "Train Epoch: 5 [57600/125973 (46%)]\tLoss: 0.127689\tSteps: 1755400\n",
      "Train Epoch: 5 [64000/125973 (51%)]\tLoss: 0.129831\tSteps: 1775400\n",
      "Train Epoch: 5 [70400/125973 (56%)]\tLoss: 0.119605\tSteps: 1795400\n",
      "Train Epoch: 5 [76800/125973 (61%)]\tLoss: 0.129727\tSteps: 1815400\n",
      "Train Epoch: 5 [83200/125973 (66%)]\tLoss: 0.123482\tSteps: 1835400\n",
      "Train Epoch: 5 [89600/125973 (71%)]\tLoss: 0.123039\tSteps: 1855400\n",
      "Train Epoch: 5 [96000/125973 (76%)]\tLoss: 0.113707\tSteps: 1875400\n",
      "Train Epoch: 5 [102400/125973 (81%)]\tLoss: 0.121012\tSteps: 1895400\n",
      "Train Epoch: 5 [108800/125973 (86%)]\tLoss: 0.114928\tSteps: 1915400\n",
      "Train Epoch: 5 [115200/125973 (91%)]\tLoss: 0.118354\tSteps: 1935400\n",
      "Train Epoch: 5 [121600/125973 (96%)]\tLoss: 0.117072\tSteps: 1955400\n",
      "\n",
      "Test set: Average loss: 0.6389, Accuracy: 17346/22544 (77%)\n",
      "\n",
      "Train Epoch: 6 [6400/125973 (5%)]\tLoss: 0.115487\tSteps: 1989200\n",
      "Train Epoch: 6 [12800/125973 (10%)]\tLoss: 0.117156\tSteps: 2009200\n",
      "Train Epoch: 6 [19200/125973 (15%)]\tLoss: 0.113246\tSteps: 2029200\n",
      "Train Epoch: 6 [25600/125973 (20%)]\tLoss: 0.117931\tSteps: 2049200\n",
      "Train Epoch: 6 [32000/125973 (25%)]\tLoss: 0.118711\tSteps: 2069200\n",
      "Train Epoch: 6 [38400/125973 (30%)]\tLoss: 0.101515\tSteps: 2089200\n",
      "Train Epoch: 6 [44800/125973 (36%)]\tLoss: 0.106610\tSteps: 2109200\n",
      "Train Epoch: 6 [51200/125973 (41%)]\tLoss: 0.107020\tSteps: 2129200\n",
      "Train Epoch: 6 [57600/125973 (46%)]\tLoss: 0.116986\tSteps: 2149200\n",
      "Train Epoch: 6 [64000/125973 (51%)]\tLoss: 0.103039\tSteps: 2169200\n",
      "Train Epoch: 6 [70400/125973 (56%)]\tLoss: 0.096389\tSteps: 2189200\n",
      "Train Epoch: 6 [76800/125973 (61%)]\tLoss: 0.099226\tSteps: 2209200\n",
      "Train Epoch: 6 [83200/125973 (66%)]\tLoss: 0.096209\tSteps: 2229200\n",
      "Train Epoch: 6 [89600/125973 (71%)]\tLoss: 0.095960\tSteps: 2249200\n",
      "Train Epoch: 6 [96000/125973 (76%)]\tLoss: 0.090631\tSteps: 2269200\n",
      "Train Epoch: 6 [102400/125973 (81%)]\tLoss: 0.094678\tSteps: 2289200\n",
      "Train Epoch: 6 [108800/125973 (86%)]\tLoss: 0.093726\tSteps: 2309200\n",
      "Train Epoch: 6 [115200/125973 (91%)]\tLoss: 0.091619\tSteps: 2329200\n",
      "Train Epoch: 6 [121600/125973 (96%)]\tLoss: 0.088890\tSteps: 2349200\n",
      "\n",
      "Test set: Average loss: 0.6647, Accuracy: 18174/22544 (81%)\n",
      "\n",
      "Train Epoch: 7 [6400/125973 (5%)]\tLoss: 0.093959\tSteps: 2383000\n",
      "Train Epoch: 7 [12800/125973 (10%)]\tLoss: 0.088348\tSteps: 2403000\n",
      "Train Epoch: 7 [19200/125973 (15%)]\tLoss: 0.085836\tSteps: 2423000\n",
      "Train Epoch: 7 [25600/125973 (20%)]\tLoss: 0.083424\tSteps: 2443000\n",
      "Train Epoch: 7 [32000/125973 (25%)]\tLoss: 0.083933\tSteps: 2463000\n",
      "Train Epoch: 7 [38400/125973 (30%)]\tLoss: 0.089269\tSteps: 2483000\n",
      "Train Epoch: 7 [44800/125973 (36%)]\tLoss: 0.088813\tSteps: 2503000\n",
      "Train Epoch: 7 [51200/125973 (41%)]\tLoss: 0.082588\tSteps: 2523000\n",
      "Train Epoch: 7 [57600/125973 (46%)]\tLoss: 0.082013\tSteps: 2543000\n",
      "Train Epoch: 7 [64000/125973 (51%)]\tLoss: 0.088386\tSteps: 2563000\n",
      "Train Epoch: 7 [70400/125973 (56%)]\tLoss: 0.076674\tSteps: 2583000\n",
      "Train Epoch: 7 [76800/125973 (61%)]\tLoss: 0.089188\tSteps: 2603000\n",
      "Train Epoch: 7 [83200/125973 (66%)]\tLoss: 0.090937\tSteps: 2623000\n",
      "Train Epoch: 7 [89600/125973 (71%)]\tLoss: 0.076122\tSteps: 2643000\n",
      "Train Epoch: 7 [96000/125973 (76%)]\tLoss: 0.082563\tSteps: 2663000\n",
      "Train Epoch: 7 [102400/125973 (81%)]\tLoss: 0.085174\tSteps: 2683000\n",
      "Train Epoch: 7 [108800/125973 (86%)]\tLoss: 0.088436\tSteps: 2703000\n",
      "Train Epoch: 7 [115200/125973 (91%)]\tLoss: 0.071752\tSteps: 2723000\n",
      "Train Epoch: 7 [121600/125973 (96%)]\tLoss: 0.094411\tSteps: 2743000\n",
      "\n",
      "Test set: Average loss: 0.6809, Accuracy: 18327/22544 (81%)\n",
      "\n",
      "Train Epoch: 8 [6400/125973 (5%)]\tLoss: 0.078352\tSteps: 2776800\n",
      "Train Epoch: 8 [12800/125973 (10%)]\tLoss: 0.077989\tSteps: 2796800\n",
      "Train Epoch: 8 [19200/125973 (15%)]\tLoss: 0.076808\tSteps: 2816800\n",
      "Train Epoch: 8 [25600/125973 (20%)]\tLoss: 0.084457\tSteps: 2836800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 8 [32000/125973 (25%)]\tLoss: 0.078489\tSteps: 2856800\n",
      "Train Epoch: 8 [38400/125973 (30%)]\tLoss: 0.073644\tSteps: 2876800\n",
      "Train Epoch: 8 [44800/125973 (36%)]\tLoss: 0.074217\tSteps: 2896800\n",
      "Train Epoch: 8 [51200/125973 (41%)]\tLoss: 0.075495\tSteps: 2916800\n",
      "Train Epoch: 8 [57600/125973 (46%)]\tLoss: 0.074413\tSteps: 2936800\n",
      "Train Epoch: 8 [64000/125973 (51%)]\tLoss: 0.074227\tSteps: 2956800\n",
      "Train Epoch: 8 [70400/125973 (56%)]\tLoss: 0.075641\tSteps: 2976800\n",
      "Train Epoch: 8 [76800/125973 (61%)]\tLoss: 0.078454\tSteps: 2996800\n",
      "Train Epoch: 8 [83200/125973 (66%)]\tLoss: 0.063563\tSteps: 3016800\n",
      "Train Epoch: 8 [89600/125973 (71%)]\tLoss: 0.071026\tSteps: 3036800\n",
      "Train Epoch: 8 [96000/125973 (76%)]\tLoss: 0.074914\tSteps: 3056800\n",
      "Train Epoch: 8 [102400/125973 (81%)]\tLoss: 0.074422\tSteps: 3076800\n",
      "Train Epoch: 8 [108800/125973 (86%)]\tLoss: 0.071356\tSteps: 3096800\n",
      "Train Epoch: 8 [115200/125973 (91%)]\tLoss: 0.065733\tSteps: 3116800\n",
      "Train Epoch: 8 [121600/125973 (96%)]\tLoss: 0.063697\tSteps: 3136800\n",
      "\n",
      "Test set: Average loss: 0.7459, Accuracy: 18279/22544 (81%)\n",
      "\n",
      "Train Epoch: 9 [6400/125973 (5%)]\tLoss: 0.071375\tSteps: 3170600\n",
      "Train Epoch: 9 [12800/125973 (10%)]\tLoss: 0.073640\tSteps: 3190600\n",
      "Train Epoch: 9 [19200/125973 (15%)]\tLoss: 0.064884\tSteps: 3210600\n",
      "Train Epoch: 9 [25600/125973 (20%)]\tLoss: 0.066239\tSteps: 3230600\n",
      "Train Epoch: 9 [32000/125973 (25%)]\tLoss: 0.071239\tSteps: 3250600\n",
      "Train Epoch: 9 [38400/125973 (30%)]\tLoss: 0.066654\tSteps: 3270600\n",
      "Train Epoch: 9 [44800/125973 (36%)]\tLoss: 0.067403\tSteps: 3290600\n",
      "Train Epoch: 9 [51200/125973 (41%)]\tLoss: 0.064840\tSteps: 3310600\n",
      "Train Epoch: 9 [57600/125973 (46%)]\tLoss: 0.063761\tSteps: 3330600\n",
      "Train Epoch: 9 [64000/125973 (51%)]\tLoss: 0.066112\tSteps: 3350600\n",
      "Train Epoch: 9 [70400/125973 (56%)]\tLoss: 0.061346\tSteps: 3370600\n",
      "Train Epoch: 9 [76800/125973 (61%)]\tLoss: 0.073852\tSteps: 3390600\n",
      "Train Epoch: 9 [83200/125973 (66%)]\tLoss: 0.067768\tSteps: 3410600\n",
      "Train Epoch: 9 [89600/125973 (71%)]\tLoss: 0.059564\tSteps: 3430600\n",
      "Train Epoch: 9 [96000/125973 (76%)]\tLoss: 0.063458\tSteps: 3450600\n",
      "Train Epoch: 9 [102400/125973 (81%)]\tLoss: 0.054592\tSteps: 3470600\n",
      "Train Epoch: 9 [108800/125973 (86%)]\tLoss: 0.061721\tSteps: 3490600\n",
      "Train Epoch: 9 [115200/125973 (91%)]\tLoss: 0.066493\tSteps: 3510600\n",
      "Train Epoch: 9 [121600/125973 (96%)]\tLoss: 0.066775\tSteps: 3530600\n",
      "\n",
      "Test set: Average loss: 0.7256, Accuracy: 18427/22544 (82%)\n",
      "\n",
      "Train Epoch: 10 [6400/125973 (5%)]\tLoss: 0.063419\tSteps: 3564400\n",
      "Train Epoch: 10 [12800/125973 (10%)]\tLoss: 0.066051\tSteps: 3584400\n",
      "Train Epoch: 10 [19200/125973 (15%)]\tLoss: 0.062793\tSteps: 3604400\n",
      "Train Epoch: 10 [25600/125973 (20%)]\tLoss: 0.069126\tSteps: 3624400\n",
      "Train Epoch: 10 [32000/125973 (25%)]\tLoss: 0.060385\tSteps: 3644400\n",
      "Train Epoch: 10 [38400/125973 (30%)]\tLoss: 0.060090\tSteps: 3664400\n",
      "Train Epoch: 10 [44800/125973 (36%)]\tLoss: 0.065938\tSteps: 3684400\n",
      "Train Epoch: 10 [51200/125973 (41%)]\tLoss: 0.058887\tSteps: 3704400\n",
      "Train Epoch: 10 [57600/125973 (46%)]\tLoss: 0.058383\tSteps: 3724400\n",
      "Train Epoch: 10 [64000/125973 (51%)]\tLoss: 0.055583\tSteps: 3744400\n",
      "Train Epoch: 10 [70400/125973 (56%)]\tLoss: 0.058934\tSteps: 3764400\n",
      "Train Epoch: 10 [76800/125973 (61%)]\tLoss: 0.060185\tSteps: 3784400\n",
      "Train Epoch: 10 [83200/125973 (66%)]\tLoss: 0.064828\tSteps: 3804400\n",
      "Train Epoch: 10 [89600/125973 (71%)]\tLoss: 0.050528\tSteps: 3824400\n",
      "Train Epoch: 10 [96000/125973 (76%)]\tLoss: 0.061774\tSteps: 3844400\n",
      "Train Epoch: 10 [102400/125973 (81%)]\tLoss: 0.052951\tSteps: 3864400\n",
      "Train Epoch: 10 [108800/125973 (86%)]\tLoss: 0.056470\tSteps: 3884400\n",
      "Train Epoch: 10 [115200/125973 (91%)]\tLoss: 0.050231\tSteps: 3904400\n",
      "Train Epoch: 10 [121600/125973 (96%)]\tLoss: 0.060763\tSteps: 3924400\n",
      "\n",
      "Test set: Average loss: 0.8012, Accuracy: 18226/22544 (81%)\n",
      "\n",
      "Train Epoch: 11 [6400/125973 (5%)]\tLoss: 0.055673\tSteps: 3958200\n",
      "Train Epoch: 11 [12800/125973 (10%)]\tLoss: 0.047952\tSteps: 3978200\n",
      "Train Epoch: 11 [19200/125973 (15%)]\tLoss: 0.057841\tSteps: 3998200\n",
      "Train Epoch: 11 [25600/125973 (20%)]\tLoss: 0.054486\tSteps: 4018200\n",
      "Train Epoch: 11 [32000/125973 (25%)]\tLoss: 0.049353\tSteps: 4038200\n",
      "Train Epoch: 11 [38400/125973 (30%)]\tLoss: 0.058726\tSteps: 4058200\n",
      "Train Epoch: 11 [44800/125973 (36%)]\tLoss: 0.059661\tSteps: 4078200\n",
      "Train Epoch: 11 [51200/125973 (41%)]\tLoss: 0.060898\tSteps: 4098200\n",
      "Train Epoch: 11 [57600/125973 (46%)]\tLoss: 0.049553\tSteps: 4118200\n",
      "Train Epoch: 11 [64000/125973 (51%)]\tLoss: 0.054498\tSteps: 4138200\n",
      "Train Epoch: 11 [70400/125973 (56%)]\tLoss: 0.063936\tSteps: 4158200\n",
      "Train Epoch: 11 [76800/125973 (61%)]\tLoss: 0.054263\tSteps: 4178200\n",
      "Train Epoch: 11 [83200/125973 (66%)]\tLoss: 0.060650\tSteps: 4198200\n",
      "Train Epoch: 11 [89600/125973 (71%)]\tLoss: 0.058227\tSteps: 4218200\n",
      "Train Epoch: 11 [96000/125973 (76%)]\tLoss: 0.052825\tSteps: 4238200\n",
      "Train Epoch: 11 [102400/125973 (81%)]\tLoss: 0.055390\tSteps: 4258200\n",
      "Train Epoch: 11 [108800/125973 (86%)]\tLoss: 0.052978\tSteps: 4278200\n",
      "Train Epoch: 11 [115200/125973 (91%)]\tLoss: 0.056879\tSteps: 4298200\n",
      "Train Epoch: 11 [121600/125973 (96%)]\tLoss: 0.049001\tSteps: 4318200\n",
      "\n",
      "Test set: Average loss: 0.7838, Accuracy: 18352/22544 (81%)\n",
      "\n",
      "Train Epoch: 12 [6400/125973 (5%)]\tLoss: 0.055924\tSteps: 4352000\n",
      "Train Epoch: 12 [12800/125973 (10%)]\tLoss: 0.062019\tSteps: 4372000\n",
      "Train Epoch: 12 [19200/125973 (15%)]\tLoss: 0.058023\tSteps: 4392000\n",
      "Train Epoch: 12 [25600/125973 (20%)]\tLoss: 0.044840\tSteps: 4412000\n",
      "Train Epoch: 12 [32000/125973 (25%)]\tLoss: 0.049454\tSteps: 4432000\n",
      "Train Epoch: 12 [38400/125973 (30%)]\tLoss: 0.061339\tSteps: 4452000\n",
      "Train Epoch: 12 [44800/125973 (36%)]\tLoss: 0.051567\tSteps: 4472000\n",
      "Train Epoch: 12 [51200/125973 (41%)]\tLoss: 0.050890\tSteps: 4492000\n",
      "Train Epoch: 12 [57600/125973 (46%)]\tLoss: 0.053839\tSteps: 4512000\n",
      "Train Epoch: 12 [64000/125973 (51%)]\tLoss: 0.051314\tSteps: 4532000\n",
      "Train Epoch: 12 [70400/125973 (56%)]\tLoss: 0.055340\tSteps: 4552000\n",
      "Train Epoch: 12 [76800/125973 (61%)]\tLoss: 0.050139\tSteps: 4572000\n",
      "Train Epoch: 12 [83200/125973 (66%)]\tLoss: 0.056874\tSteps: 4592000\n",
      "Train Epoch: 12 [89600/125973 (71%)]\tLoss: 0.057733\tSteps: 4612000\n",
      "Train Epoch: 12 [96000/125973 (76%)]\tLoss: 0.054542\tSteps: 4632000\n",
      "Train Epoch: 12 [102400/125973 (81%)]\tLoss: 0.047009\tSteps: 4652000\n",
      "Train Epoch: 12 [108800/125973 (86%)]\tLoss: 0.054854\tSteps: 4672000\n",
      "Train Epoch: 12 [115200/125973 (91%)]\tLoss: 0.051792\tSteps: 4692000\n",
      "Train Epoch: 12 [121600/125973 (96%)]\tLoss: 0.056493\tSteps: 4712000\n",
      "\n",
      "Test set: Average loss: 0.7948, Accuracy: 18326/22544 (81%)\n",
      "\n",
      "Train Epoch: 13 [6400/125973 (5%)]\tLoss: 0.053585\tSteps: 4745800\n",
      "Train Epoch: 13 [12800/125973 (10%)]\tLoss: 0.051598\tSteps: 4765800\n",
      "Train Epoch: 13 [19200/125973 (15%)]\tLoss: 0.057632\tSteps: 4785800\n",
      "Train Epoch: 13 [25600/125973 (20%)]\tLoss: 0.054771\tSteps: 4805800\n",
      "Train Epoch: 13 [32000/125973 (25%)]\tLoss: 0.065909\tSteps: 4825800\n",
      "Train Epoch: 13 [38400/125973 (30%)]\tLoss: 0.051104\tSteps: 4845800\n",
      "Train Epoch: 13 [44800/125973 (36%)]\tLoss: 0.063219\tSteps: 4865800\n",
      "Train Epoch: 13 [51200/125973 (41%)]\tLoss: 0.049208\tSteps: 4885800\n",
      "Train Epoch: 13 [57600/125973 (46%)]\tLoss: 0.060289\tSteps: 4905800\n",
      "Train Epoch: 13 [64000/125973 (51%)]\tLoss: 0.058730\tSteps: 4925800\n",
      "Train Epoch: 13 [70400/125973 (56%)]\tLoss: 0.053334\tSteps: 4945800\n",
      "Train Epoch: 13 [76800/125973 (61%)]\tLoss: 0.051846\tSteps: 4965800\n",
      "Train Epoch: 13 [83200/125973 (66%)]\tLoss: 0.052255\tSteps: 4985800\n",
      "Train Epoch: 13 [89600/125973 (71%)]\tLoss: 0.055763\tSteps: 5005800\n",
      "Train Epoch: 13 [96000/125973 (76%)]\tLoss: 0.058485\tSteps: 5025800\n",
      "Train Epoch: 13 [102400/125973 (81%)]\tLoss: 0.048224\tSteps: 5045800\n",
      "Train Epoch: 13 [108800/125973 (86%)]\tLoss: 0.055152\tSteps: 5065800\n",
      "Train Epoch: 13 [115200/125973 (91%)]\tLoss: 0.049049\tSteps: 5085800\n",
      "Train Epoch: 13 [121600/125973 (96%)]\tLoss: 0.055766\tSteps: 5105800\n",
      "\n",
      "Test set: Average loss: 0.7919, Accuracy: 18337/22544 (81%)\n",
      "\n",
      "Train Epoch: 14 [6400/125973 (5%)]\tLoss: 0.055125\tSteps: 5139600\n",
      "Train Epoch: 14 [12800/125973 (10%)]\tLoss: 0.049157\tSteps: 5159600\n",
      "Train Epoch: 14 [19200/125973 (15%)]\tLoss: 0.051085\tSteps: 5179600\n",
      "Train Epoch: 14 [25600/125973 (20%)]\tLoss: 0.053171\tSteps: 5199600\n",
      "Train Epoch: 14 [32000/125973 (25%)]\tLoss: 0.053089\tSteps: 5219600\n",
      "Train Epoch: 14 [38400/125973 (30%)]\tLoss: 0.052538\tSteps: 5239600\n",
      "Train Epoch: 14 [44800/125973 (36%)]\tLoss: 0.046886\tSteps: 5259600\n",
      "Train Epoch: 14 [51200/125973 (41%)]\tLoss: 0.058567\tSteps: 5279600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 14 [57600/125973 (46%)]\tLoss: 0.053177\tSteps: 5299600\n",
      "Train Epoch: 14 [64000/125973 (51%)]\tLoss: 0.053768\tSteps: 5319600\n",
      "Train Epoch: 14 [70400/125973 (56%)]\tLoss: 0.052623\tSteps: 5339600\n",
      "Train Epoch: 14 [76800/125973 (61%)]\tLoss: 0.055718\tSteps: 5359600\n",
      "Train Epoch: 14 [83200/125973 (66%)]\tLoss: 0.059129\tSteps: 5379600\n",
      "Train Epoch: 14 [89600/125973 (71%)]\tLoss: 0.062593\tSteps: 5399600\n",
      "Train Epoch: 14 [96000/125973 (76%)]\tLoss: 0.053587\tSteps: 5419600\n",
      "Train Epoch: 14 [102400/125973 (81%)]\tLoss: 0.051357\tSteps: 5439600\n",
      "Train Epoch: 14 [108800/125973 (86%)]\tLoss: 0.045785\tSteps: 5459600\n",
      "Train Epoch: 14 [115200/125973 (91%)]\tLoss: 0.052333\tSteps: 5479600\n",
      "Train Epoch: 14 [121600/125973 (96%)]\tLoss: 0.047946\tSteps: 5499600\n",
      "\n",
      "Test set: Average loss: 0.7983, Accuracy: 18319/22544 (81%)\n",
      "\n",
      "Train Epoch: 15 [6400/125973 (5%)]\tLoss: 0.056878\tSteps: 5533400\n",
      "Train Epoch: 15 [12800/125973 (10%)]\tLoss: 0.050647\tSteps: 5553400\n",
      "Train Epoch: 15 [19200/125973 (15%)]\tLoss: 0.048080\tSteps: 5573400\n",
      "Train Epoch: 15 [25600/125973 (20%)]\tLoss: 0.048896\tSteps: 5593400\n",
      "Train Epoch: 15 [32000/125973 (25%)]\tLoss: 0.053591\tSteps: 5613400\n",
      "Train Epoch: 15 [38400/125973 (30%)]\tLoss: 0.049337\tSteps: 5633400\n",
      "Train Epoch: 15 [44800/125973 (36%)]\tLoss: 0.045114\tSteps: 5653400\n",
      "Train Epoch: 15 [51200/125973 (41%)]\tLoss: 0.055513\tSteps: 5673400\n",
      "Train Epoch: 15 [57600/125973 (46%)]\tLoss: 0.056115\tSteps: 5693400\n",
      "Train Epoch: 15 [64000/125973 (51%)]\tLoss: 0.044656\tSteps: 5713400\n",
      "Train Epoch: 15 [70400/125973 (56%)]\tLoss: 0.049821\tSteps: 5733400\n",
      "Train Epoch: 15 [76800/125973 (61%)]\tLoss: 0.061470\tSteps: 5753400\n",
      "Train Epoch: 15 [83200/125973 (66%)]\tLoss: 0.059221\tSteps: 5773400\n",
      "Train Epoch: 15 [89600/125973 (71%)]\tLoss: 0.047984\tSteps: 5793400\n",
      "Train Epoch: 15 [96000/125973 (76%)]\tLoss: 0.056033\tSteps: 5813400\n",
      "Train Epoch: 15 [102400/125973 (81%)]\tLoss: 0.054719\tSteps: 5833400\n",
      "Train Epoch: 15 [108800/125973 (86%)]\tLoss: 0.058180\tSteps: 5853400\n",
      "Train Epoch: 15 [115200/125973 (91%)]\tLoss: 0.043762\tSteps: 5873400\n",
      "Train Epoch: 15 [121600/125973 (96%)]\tLoss: 0.052732\tSteps: 5893400\n",
      "\n",
      "Test set: Average loss: 0.7995, Accuracy: 18332/22544 (81%)\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-f30cd6ac13df>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"__main__\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m         \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m         \u001b[0mtest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m10\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-a2dae5835c37>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(ep)\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# negative log likelihood\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[1;31m#loss = loss1(output, target)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[0mtrain_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive\\Documents\\virtualenvs\\netsec\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[1;32m--> 221\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    222\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    223\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive\\Documents\\virtualenvs\\netsec\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m    130\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 132\u001b[1;33m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m    133\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    for epoch in range(1, epochs+1):\n",
    "        train(epoch)\n",
    "        test()\n",
    "        if epoch % 10 == 0:\n",
    "            lr /= 10\n",
    "            for param_group in optimizer.param_groups:\n",
    "                param_group['lr'] = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "def get_metrics(dataLoader):\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    precision = 0\n",
    "    recall = 0\n",
    "    f1_score = 0\n",
    "    accuracy = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in dataLoader: # just 1 batch\n",
    "            model.eval()\n",
    "            data = data.type(torch.FloatTensor)\n",
    "            target = target.type(torch.LongTensor)\n",
    "            output = model(data)\n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "            #print(predicted)\n",
    "            total+=target.size(0)\n",
    "            correct+=(predicted == target).sum().item()\n",
    "            report = classification_report(target, predicted, output_dict=True)\n",
    "            precision += report['macro avg']['precision']\n",
    "            recall += report['macro avg']['recall']\n",
    "            f1_score += report['macro avg']['f1-score']\n",
    "            accuracy += report['accuracy']\n",
    "            print(report)\n",
    "    print(\"Precision: {}, Recall: {}, F1-Score: {}, Accuracy: {}, AccuracyCust: {}\".format(precision, recall, f1_score, accuracy, correct/total))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lromo\\OneDrive\\Documents\\virtualenvs\\netsec\\lib\\site-packages\\ipykernel_launcher.py:16: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1],\n",
      "        [1],\n",
      "        [0],\n",
      "        ...,\n",
      "        [0],\n",
      "        [0],\n",
      "        [0]])\n",
      "\n",
      "Test set: Average loss: 0.0000, Accuracy: 18338/22544 (81%)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fileNameVal = 'Ds.csv'\n",
    "datasetVal = NSLKDDDataset(fileNameVal)\n",
    "params = {'batch_size': 22544, 'shuffle': True}\n",
    "dataGeneratorVal = DataLoader(datasetVal, **params)\n",
    "#RuntimeError: expected scalar type Int but found Float\n",
    "#get_metrics(dataGeneratorVal)\n",
    "def val():\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in dataGeneratorVal:\n",
    "            model.eval()\n",
    "            #data = data.view(-1, input_channels, seq_length)\n",
    "            data = data.type(torch.FloatTensor)\n",
    "            target = target.type(torch.LongTensor)\n",
    "            data, target = Variable(data, volatile=True), Variable(target)\n",
    "            output = model(data)\n",
    "            #loss1 = torch.nn.CrossEntropyLoss()\n",
    "            #test_loss += F.nll_loss(output, target, size_average=False).item()\n",
    "            #test_loss += loss1(output, target).item()\n",
    "            #print(output.data.max(1, keepdim=True)[1])\n",
    "            pred = output.data.max(1, keepdim=True)[1]\n",
    "            print(pred)\n",
    "            correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "\n",
    "        test_loss /= len(dataGeneratorTest.dataset)\n",
    "        print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "            test_loss, correct, len(dataGeneratorVal.dataset),\n",
    "            100. * correct / len(dataGeneratorVal.dataset)))\n",
    "        return test_loss\n",
    "\n",
    "val()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'0': {'precision': 0.7219579066204338, 'recall': 0.9219441870044279, 'f1-score': 0.8097865412445729, 'support': 9711}, '1': {'precision': 0.9252686581879128, 'recall': 0.7313176965635471, 'f1-score': 0.8169394150417827, 'support': 12833}, 'accuracy': 0.8134315117104329, 'macro avg': {'precision': 0.8236132824041733, 'recall': 0.8266309417839874, 'f1-score': 0.8133629781431778, 'support': 22544}, 'weighted avg': {'precision': 0.8376910007858641, 'recall': 0.8134315117104329, 'f1-score': 0.8138582600806088, 'support': 22544}}\n",
      "Precision: 0.8236132824041733, Recall: 0.8266309417839874, F1-Score: 0.8133629781431778, Accuracy: 0.8134315117104329, AccuracyCust: 0.8134315117104329\n"
     ]
    }
   ],
   "source": [
    "get_metrics(dataGeneratorVal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'0': {'precision': 0.9411764705882353, 'recall': 1.0, 'f1-score': 0.9696969696969697, 'support': 32}, '1': {'precision': 1.0, 'recall': 0.9375, 'f1-score': 0.967741935483871, 'support': 32}, 'accuracy': 0.96875, 'macro avg': {'precision': 0.9705882352941176, 'recall': 0.96875, 'f1-score': 0.9687194525904204, 'support': 64}, 'weighted avg': {'precision': 0.9705882352941176, 'recall': 0.96875, 'f1-score': 0.9687194525904204, 'support': 64}}\n",
      "{'0': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 22}, '1': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 42}, 'accuracy': 1.0, 'macro avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 64}, 'weighted avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 64}}\n",
      "{'0': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 35}, '1': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 29}, 'accuracy': 1.0, 'macro avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 64}, 'weighted avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 64}}\n",
      "{'0': {'precision': 0.9705882352941176, 'recall': 0.9705882352941176, 'f1-score': 0.9705882352941176, 'support': 34}, '1': {'precision': 0.9666666666666667, 'recall': 0.9666666666666667, 'f1-score': 0.9666666666666667, 'support': 30}, 'accuracy': 0.96875, 'macro avg': {'precision': 0.9686274509803922, 'recall': 0.9686274509803922, 'f1-score': 0.9686274509803922, 'support': 64}, 'weighted avg': {'precision': 0.96875, 'recall': 0.96875, 'f1-score': 0.96875, 'support': 64}}\n",
      "{'0': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 33}, '1': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 31}, 'accuracy': 1.0, 'macro avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 64}, 'weighted avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 64}}\n",
      "{'0': {'precision': 0.972972972972973, 'recall': 1.0, 'f1-score': 0.9863013698630138, 'support': 36}, '1': {'precision': 1.0, 'recall': 0.9642857142857143, 'f1-score': 0.9818181818181818, 'support': 28}, 'accuracy': 0.984375, 'macro avg': {'precision': 0.9864864864864865, 'recall': 0.9821428571428572, 'f1-score': 0.9840597758405978, 'support': 64}, 'weighted avg': {'precision': 0.9847972972972974, 'recall': 0.984375, 'f1-score': 0.9843399750933998, 'support': 64}}\n",
      "{'0': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 38}, '1': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 26}, 'accuracy': 1.0, 'macro avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 64}, 'weighted avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 64}}\n",
      "{'0': {'precision': 1.0, 'recall': 0.972972972972973, 'f1-score': 0.9863013698630138, 'support': 37}, '1': {'precision': 0.9642857142857143, 'recall': 1.0, 'f1-score': 0.9818181818181818, 'support': 27}, 'accuracy': 0.984375, 'macro avg': {'precision': 0.9821428571428572, 'recall': 0.9864864864864865, 'f1-score': 0.9840597758405978, 'support': 64}, 'weighted avg': {'precision': 0.9849330357142857, 'recall': 0.984375, 'f1-score': 0.9844100249066002, 'support': 64}}\n",
      "{'0': {'precision': 1.0, 'recall': 0.9354838709677419, 'f1-score': 0.9666666666666666, 'support': 31}, '1': {'precision': 0.9428571428571428, 'recall': 1.0, 'f1-score': 0.9705882352941176, 'support': 33}, 'accuracy': 0.96875, 'macro avg': {'precision': 0.9714285714285714, 'recall': 0.967741935483871, 'f1-score': 0.968627450980392, 'support': 64}, 'weighted avg': {'precision': 0.9705357142857143, 'recall': 0.96875, 'f1-score': 0.9686887254901961, 'support': 64}}\n",
      "{'0': {'precision': 0.9696969696969697, 'recall': 1.0, 'f1-score': 0.9846153846153847, 'support': 32}, '1': {'precision': 1.0, 'recall': 0.96875, 'f1-score': 0.9841269841269841, 'support': 32}, 'accuracy': 0.984375, 'macro avg': {'precision': 0.9848484848484849, 'recall': 0.984375, 'f1-score': 0.9843711843711844, 'support': 64}, 'weighted avg': {'precision': 0.9848484848484849, 'recall': 0.984375, 'f1-score': 0.9843711843711844, 'support': 64}}\n",
      "{'0': {'precision': 0.9722222222222222, 'recall': 1.0, 'f1-score': 0.9859154929577464, 'support': 35}, '1': {'precision': 1.0, 'recall': 0.9655172413793104, 'f1-score': 0.9824561403508771, 'support': 29}, 'accuracy': 0.984375, 'macro avg': {'precision': 0.9861111111111112, 'recall': 0.9827586206896552, 'f1-score': 0.9841858166543118, 'support': 64}, 'weighted avg': {'precision': 0.9848090277777778, 'recall': 0.984375, 'f1-score': 0.9843479738077587, 'support': 64}}\n",
      "{'0': {'precision': 0.9714285714285714, 'recall': 0.9714285714285714, 'f1-score': 0.9714285714285714, 'support': 35}, '1': {'precision': 0.9655172413793104, 'recall': 0.9655172413793104, 'f1-score': 0.9655172413793104, 'support': 29}, 'accuracy': 0.96875, 'macro avg': {'precision': 0.9684729064039409, 'recall': 0.9684729064039409, 'f1-score': 0.9684729064039409, 'support': 64}, 'weighted avg': {'precision': 0.96875, 'recall': 0.96875, 'f1-score': 0.96875, 'support': 64}}\n",
      "{'0': {'precision': 1.0, 'recall': 0.9655172413793104, 'f1-score': 0.9824561403508771, 'support': 29}, '1': {'precision': 0.9722222222222222, 'recall': 1.0, 'f1-score': 0.9859154929577464, 'support': 35}, 'accuracy': 0.984375, 'macro avg': {'precision': 0.9861111111111112, 'recall': 0.9827586206896552, 'f1-score': 0.9841858166543118, 'support': 64}, 'weighted avg': {'precision': 0.9848090277777778, 'recall': 0.984375, 'f1-score': 0.9843479738077587, 'support': 64}}\n",
      "{'0': {'precision': 0.9666666666666667, 'recall': 1.0, 'f1-score': 0.983050847457627, 'support': 29}, '1': {'precision': 1.0, 'recall': 0.9714285714285714, 'f1-score': 0.9855072463768115, 'support': 35}, 'accuracy': 0.984375, 'macro avg': {'precision': 0.9833333333333334, 'recall': 0.9857142857142858, 'f1-score': 0.9842790469172193, 'support': 64}, 'weighted avg': {'precision': 0.9848958333333333, 'recall': 0.984375, 'f1-score': 0.9843941906165561, 'support': 64}}\n",
      "{'0': {'precision': 1.0, 'recall': 0.975, 'f1-score': 0.9873417721518987, 'support': 40}, '1': {'precision': 0.96, 'recall': 1.0, 'f1-score': 0.9795918367346939, 'support': 24}, 'accuracy': 0.984375, 'macro avg': {'precision': 0.98, 'recall': 0.9875, 'f1-score': 0.9834668044432963, 'support': 64}, 'weighted avg': {'precision': 0.985, 'recall': 0.984375, 'f1-score': 0.9844355463704468, 'support': 64}}\n",
      "{'0': {'precision': 0.9722222222222222, 'recall': 0.9722222222222222, 'f1-score': 0.9722222222222222, 'support': 36}, '1': {'precision': 0.9642857142857143, 'recall': 0.9642857142857143, 'f1-score': 0.9642857142857143, 'support': 28}, 'accuracy': 0.96875, 'macro avg': {'precision': 0.9682539682539683, 'recall': 0.9682539682539683, 'f1-score': 0.9682539682539683, 'support': 64}, 'weighted avg': {'precision': 0.96875, 'recall': 0.96875, 'f1-score': 0.96875, 'support': 64}}\n",
      "{'0': {'precision': 0.9512195121951219, 'recall': 1.0, 'f1-score': 0.975, 'support': 39}, '1': {'precision': 1.0, 'recall': 0.92, 'f1-score': 0.9583333333333334, 'support': 25}, 'accuracy': 0.96875, 'macro avg': {'precision': 0.975609756097561, 'recall': 0.96, 'f1-score': 0.9666666666666667, 'support': 64}, 'weighted avg': {'precision': 0.9702743902439024, 'recall': 0.96875, 'f1-score': 0.9684895833333333, 'support': 64}}\n",
      "{'0': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 35}, '1': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 29}, 'accuracy': 1.0, 'macro avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 64}, 'weighted avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 64}}\n",
      "{'0': {'precision': 0.9714285714285714, 'recall': 0.9714285714285714, 'f1-score': 0.9714285714285714, 'support': 35}, '1': {'precision': 0.9655172413793104, 'recall': 0.9655172413793104, 'f1-score': 0.9655172413793104, 'support': 29}, 'accuracy': 0.96875, 'macro avg': {'precision': 0.9684729064039409, 'recall': 0.9684729064039409, 'f1-score': 0.9684729064039409, 'support': 64}, 'weighted avg': {'precision': 0.96875, 'recall': 0.96875, 'f1-score': 0.96875, 'support': 64}}\n",
      "{'0': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 34}, '1': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 30}, 'accuracy': 1.0, 'macro avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 64}, 'weighted avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 64}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'0': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 39}, '1': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 25}, 'accuracy': 1.0, 'macro avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 64}, 'weighted avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 64}}\n",
      "{'0': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 35}, '1': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 29}, 'accuracy': 1.0, 'macro avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 64}, 'weighted avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 64}}\n",
      "{'0': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 36}, '1': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 28}, 'accuracy': 1.0, 'macro avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 64}, 'weighted avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 64}}\n",
      "{'0': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 37}, '1': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 27}, 'accuracy': 1.0, 'macro avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 64}, 'weighted avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 64}}\n",
      "{'0': {'precision': 0.9354838709677419, 'recall': 1.0, 'f1-score': 0.9666666666666666, 'support': 29}, '1': {'precision': 1.0, 'recall': 0.9428571428571428, 'f1-score': 0.9705882352941176, 'support': 35}, 'accuracy': 0.96875, 'macro avg': {'precision': 0.967741935483871, 'recall': 0.9714285714285714, 'f1-score': 0.968627450980392, 'support': 64}, 'weighted avg': {'precision': 0.970766129032258, 'recall': 0.96875, 'f1-score': 0.9688112745098039, 'support': 64}}\n",
      "{'0': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 37}, '1': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 27}, 'accuracy': 1.0, 'macro avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 64}, 'weighted avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 64}}\n",
      "{'0': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 31}, '1': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 33}, 'accuracy': 1.0, 'macro avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 64}, 'weighted avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 64}}\n",
      "{'0': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 34}, '1': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 30}, 'accuracy': 1.0, 'macro avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 64}, 'weighted avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 64}}\n",
      "{'0': {'precision': 1.0, 'recall': 0.9722222222222222, 'f1-score': 0.9859154929577464, 'support': 36}, '1': {'precision': 0.9655172413793104, 'recall': 1.0, 'f1-score': 0.9824561403508771, 'support': 28}, 'accuracy': 0.984375, 'macro avg': {'precision': 0.9827586206896552, 'recall': 0.9861111111111112, 'f1-score': 0.9841858166543118, 'support': 64}, 'weighted avg': {'precision': 0.9849137931034483, 'recall': 0.984375, 'f1-score': 0.9844020261922412, 'support': 64}}\n",
      "{'0': {'precision': 0.9629629629629629, 'recall': 1.0, 'f1-score': 0.9811320754716981, 'support': 26}, '1': {'precision': 1.0, 'recall': 0.9736842105263158, 'f1-score': 0.9866666666666666, 'support': 38}, 'accuracy': 0.984375, 'macro avg': {'precision': 0.9814814814814814, 'recall': 0.986842105263158, 'f1-score': 0.9838993710691823, 'support': 64}, 'weighted avg': {'precision': 0.9849537037037037, 'recall': 0.984375, 'f1-score': 0.9844182389937106, 'support': 64}}\n",
      "{'0': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 37}, '1': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 27}, 'accuracy': 1.0, 'macro avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 64}, 'weighted avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 64}}\n",
      "{'0': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 36}, '1': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 28}, 'accuracy': 1.0, 'macro avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 64}, 'weighted avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 64}}\n",
      "{'0': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 34}, '1': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 30}, 'accuracy': 1.0, 'macro avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 64}, 'weighted avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 64}}\n",
      "{'0': {'precision': 0.967741935483871, 'recall': 0.967741935483871, 'f1-score': 0.967741935483871, 'support': 31}, '1': {'precision': 0.9696969696969697, 'recall': 0.9696969696969697, 'f1-score': 0.9696969696969697, 'support': 33}, 'accuracy': 0.96875, 'macro avg': {'precision': 0.9687194525904204, 'recall': 0.9687194525904204, 'f1-score': 0.9687194525904204, 'support': 64}, 'weighted avg': {'precision': 0.96875, 'recall': 0.96875, 'f1-score': 0.96875, 'support': 64}}\n",
      "{'0': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 33}, '1': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 31}, 'accuracy': 1.0, 'macro avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 64}, 'weighted avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 64}}\n",
      "{'0': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 28}, '1': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 36}, 'accuracy': 1.0, 'macro avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 64}, 'weighted avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 64}}\n",
      "{'0': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 39}, '1': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 25}, 'accuracy': 1.0, 'macro avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 64}, 'weighted avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 64}}\n",
      "{'0': {'precision': 0.9459459459459459, 'recall': 1.0, 'f1-score': 0.9722222222222222, 'support': 35}, '1': {'precision': 1.0, 'recall': 0.9310344827586207, 'f1-score': 0.9642857142857143, 'support': 29}, 'accuracy': 0.96875, 'macro avg': {'precision': 0.972972972972973, 'recall': 0.9655172413793103, 'f1-score': 0.9682539682539683, 'support': 64}, 'weighted avg': {'precision': 0.9704391891891891, 'recall': 0.96875, 'f1-score': 0.9686259920634921, 'support': 64}}\n",
      "{'0': {'precision': 0.9705882352941176, 'recall': 1.0, 'f1-score': 0.9850746268656716, 'support': 33}, '1': {'precision': 1.0, 'recall': 0.967741935483871, 'f1-score': 0.9836065573770492, 'support': 31}, 'accuracy': 0.984375, 'macro avg': {'precision': 0.9852941176470589, 'recall': 0.9838709677419355, 'f1-score': 0.9843405921213604, 'support': 64}, 'weighted avg': {'precision': 0.9848345588235294, 'recall': 0.984375, 'f1-score': 0.9843635307071201, 'support': 64}}\n",
      "{'0': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 29}, '1': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 35}, 'accuracy': 1.0, 'macro avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 64}, 'weighted avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 64}}\n",
      "{'0': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 37}, '1': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 27}, 'accuracy': 1.0, 'macro avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 64}, 'weighted avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 64}}\n",
      "{'0': {'precision': 0.95, 'recall': 1.0, 'f1-score': 0.9743589743589743, 'support': 38}, '1': {'precision': 1.0, 'recall': 0.9230769230769231, 'f1-score': 0.9600000000000001, 'support': 26}, 'accuracy': 0.96875, 'macro avg': {'precision': 0.975, 'recall': 0.9615384615384616, 'f1-score': 0.9671794871794872, 'support': 64}, 'weighted avg': {'precision': 0.9703125, 'recall': 0.96875, 'f1-score': 0.968525641025641, 'support': 64}}\n",
      "{'0': {'precision': 0.9714285714285714, 'recall': 1.0, 'f1-score': 0.9855072463768115, 'support': 34}, '1': {'precision': 1.0, 'recall': 0.9666666666666667, 'f1-score': 0.983050847457627, 'support': 30}, 'accuracy': 0.984375, 'macro avg': {'precision': 0.9857142857142858, 'recall': 0.9833333333333334, 'f1-score': 0.9842790469172193, 'support': 64}, 'weighted avg': {'precision': 0.9848214285714285, 'recall': 0.984375, 'f1-score': 0.9843558093834439, 'support': 64}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'0': {'precision': 0.9473684210526315, 'recall': 0.972972972972973, 'f1-score': 0.9599999999999999, 'support': 37}, '1': {'precision': 0.9615384615384616, 'recall': 0.9259259259259259, 'f1-score': 0.9433962264150944, 'support': 27}, 'accuracy': 0.953125, 'macro avg': {'precision': 0.9544534412955465, 'recall': 0.9494494494494494, 'f1-score': 0.951698113207547, 'support': 64}, 'weighted avg': {'precision': 0.9533464068825912, 'recall': 0.953125, 'f1-score': 0.9529952830188679, 'support': 64}}\n",
      "{'0': {'precision': 1.0, 'recall': 0.9666666666666667, 'f1-score': 0.983050847457627, 'support': 30}, '1': {'precision': 0.9714285714285714, 'recall': 1.0, 'f1-score': 0.9855072463768115, 'support': 34}, 'accuracy': 0.984375, 'macro avg': {'precision': 0.9857142857142858, 'recall': 0.9833333333333334, 'f1-score': 0.9842790469172193, 'support': 64}, 'weighted avg': {'precision': 0.9848214285714285, 'recall': 0.984375, 'f1-score': 0.9843558093834439, 'support': 64}}\n",
      "{'0': {'precision': 0.9736842105263158, 'recall': 1.0, 'f1-score': 0.9866666666666666, 'support': 37}, '1': {'precision': 1.0, 'recall': 0.9629629629629629, 'f1-score': 0.9811320754716981, 'support': 27}, 'accuracy': 0.984375, 'macro avg': {'precision': 0.986842105263158, 'recall': 0.9814814814814814, 'f1-score': 0.9838993710691823, 'support': 64}, 'weighted avg': {'precision': 0.9847861842105263, 'recall': 0.984375, 'f1-score': 0.9843317610062892, 'support': 64}}\n",
      "{'0': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 40}, '1': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 24}, 'accuracy': 1.0, 'macro avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 64}, 'weighted avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 64}}\n",
      "{'0': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 37}, '1': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 27}, 'accuracy': 1.0, 'macro avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 64}, 'weighted avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 64}}\n",
      "{'0': {'precision': 0.9705882352941176, 'recall': 1.0, 'f1-score': 0.9850746268656716, 'support': 33}, '1': {'precision': 1.0, 'recall': 0.967741935483871, 'f1-score': 0.9836065573770492, 'support': 31}, 'accuracy': 0.984375, 'macro avg': {'precision': 0.9852941176470589, 'recall': 0.9838709677419355, 'f1-score': 0.9843405921213604, 'support': 64}, 'weighted avg': {'precision': 0.9848345588235294, 'recall': 0.984375, 'f1-score': 0.9843635307071201, 'support': 64}}\n",
      "{'0': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 31}, '1': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 33}, 'accuracy': 1.0, 'macro avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 64}, 'weighted avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 64}}\n",
      "{'0': {'precision': 1.0, 'recall': 0.96875, 'f1-score': 0.9841269841269841, 'support': 32}, '1': {'precision': 0.9696969696969697, 'recall': 1.0, 'f1-score': 0.9846153846153847, 'support': 32}, 'accuracy': 0.984375, 'macro avg': {'precision': 0.9848484848484849, 'recall': 0.984375, 'f1-score': 0.9843711843711844, 'support': 64}, 'weighted avg': {'precision': 0.9848484848484849, 'recall': 0.984375, 'f1-score': 0.9843711843711844, 'support': 64}}\n",
      "{'0': {'precision': 1.0, 'recall': 0.96875, 'f1-score': 0.9841269841269841, 'support': 32}, '1': {'precision': 0.9696969696969697, 'recall': 1.0, 'f1-score': 0.9846153846153847, 'support': 32}, 'accuracy': 0.984375, 'macro avg': {'precision': 0.9848484848484849, 'recall': 0.984375, 'f1-score': 0.9843711843711844, 'support': 64}, 'weighted avg': {'precision': 0.9848484848484849, 'recall': 0.984375, 'f1-score': 0.9843711843711844, 'support': 64}}\n",
      "{'0': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 33}, '1': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 31}, 'accuracy': 1.0, 'macro avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 64}, 'weighted avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 64}}\n",
      "{'0': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 30}, '1': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 34}, 'accuracy': 1.0, 'macro avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 64}, 'weighted avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 64}}\n",
      "{'0': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 32}, '1': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 32}, 'accuracy': 1.0, 'macro avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 64}, 'weighted avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 64}}\n",
      "{'0': {'precision': 0.9722222222222222, 'recall': 1.0, 'f1-score': 0.9859154929577464, 'support': 35}, '1': {'precision': 1.0, 'recall': 0.9655172413793104, 'f1-score': 0.9824561403508771, 'support': 29}, 'accuracy': 0.984375, 'macro avg': {'precision': 0.9861111111111112, 'recall': 0.9827586206896552, 'f1-score': 0.9841858166543118, 'support': 64}, 'weighted avg': {'precision': 0.9848090277777778, 'recall': 0.984375, 'f1-score': 0.9843479738077587, 'support': 64}}\n",
      "{'0': {'precision': 0.9722222222222222, 'recall': 1.0, 'f1-score': 0.9859154929577464, 'support': 35}, '1': {'precision': 1.0, 'recall': 0.9655172413793104, 'f1-score': 0.9824561403508771, 'support': 29}, 'accuracy': 0.984375, 'macro avg': {'precision': 0.9861111111111112, 'recall': 0.9827586206896552, 'f1-score': 0.9841858166543118, 'support': 64}, 'weighted avg': {'precision': 0.9848090277777778, 'recall': 0.984375, 'f1-score': 0.9843479738077587, 'support': 64}}\n",
      "{'0': {'precision': 1.0, 'recall': 0.9714285714285714, 'f1-score': 0.9855072463768115, 'support': 35}, '1': {'precision': 0.9666666666666667, 'recall': 1.0, 'f1-score': 0.983050847457627, 'support': 29}, 'accuracy': 0.984375, 'macro avg': {'precision': 0.9833333333333334, 'recall': 0.9857142857142858, 'f1-score': 0.9842790469172193, 'support': 64}, 'weighted avg': {'precision': 0.9848958333333333, 'recall': 0.984375, 'f1-score': 0.9843941906165561, 'support': 64}}\n",
      "{'0': {'precision': 1.0, 'recall': 0.9722222222222222, 'f1-score': 0.9859154929577464, 'support': 36}, '1': {'precision': 0.9655172413793104, 'recall': 1.0, 'f1-score': 0.9824561403508771, 'support': 28}, 'accuracy': 0.984375, 'macro avg': {'precision': 0.9827586206896552, 'recall': 0.9861111111111112, 'f1-score': 0.9841858166543118, 'support': 64}, 'weighted avg': {'precision': 0.9849137931034483, 'recall': 0.984375, 'f1-score': 0.9844020261922412, 'support': 64}}\n",
      "{'0': {'precision': 0.9722222222222222, 'recall': 0.9722222222222222, 'f1-score': 0.9722222222222222, 'support': 36}, '1': {'precision': 0.9642857142857143, 'recall': 0.9642857142857143, 'f1-score': 0.9642857142857143, 'support': 28}, 'accuracy': 0.96875, 'macro avg': {'precision': 0.9682539682539683, 'recall': 0.9682539682539683, 'f1-score': 0.9682539682539683, 'support': 64}, 'weighted avg': {'precision': 0.96875, 'recall': 0.96875, 'f1-score': 0.96875, 'support': 64}}\n",
      "{'0': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 32}, '1': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 32}, 'accuracy': 1.0, 'macro avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 64}, 'weighted avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 64}}\n",
      "{'0': {'precision': 0.9696969696969697, 'recall': 1.0, 'f1-score': 0.9846153846153847, 'support': 32}, '1': {'precision': 1.0, 'recall': 0.96875, 'f1-score': 0.9841269841269841, 'support': 32}, 'accuracy': 0.984375, 'macro avg': {'precision': 0.9848484848484849, 'recall': 0.984375, 'f1-score': 0.9843711843711844, 'support': 64}, 'weighted avg': {'precision': 0.9848484848484849, 'recall': 0.984375, 'f1-score': 0.9843711843711844, 'support': 64}}\n",
      "{'0': {'precision': 0.975609756097561, 'recall': 1.0, 'f1-score': 0.9876543209876543, 'support': 40}, '1': {'precision': 1.0, 'recall': 0.9583333333333334, 'f1-score': 0.9787234042553191, 'support': 24}, 'accuracy': 0.984375, 'macro avg': {'precision': 0.9878048780487805, 'recall': 0.9791666666666667, 'f1-score': 0.9831888626214866, 'support': 64}, 'weighted avg': {'precision': 0.9847560975609756, 'recall': 0.984375, 'f1-score': 0.9843052272130286, 'support': 64}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'0': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 30}, '1': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 34}, 'accuracy': 1.0, 'macro avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 64}, 'weighted avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 64}}\n",
      "{'0': {'precision': 0.9714285714285714, 'recall': 1.0, 'f1-score': 0.9855072463768115, 'support': 34}, '1': {'precision': 1.0, 'recall': 0.9666666666666667, 'f1-score': 0.983050847457627, 'support': 30}, 'accuracy': 0.984375, 'macro avg': {'precision': 0.9857142857142858, 'recall': 0.9833333333333334, 'f1-score': 0.9842790469172193, 'support': 64}, 'weighted avg': {'precision': 0.9848214285714285, 'recall': 0.984375, 'f1-score': 0.9843558093834439, 'support': 64}}\n",
      "{'0': {'precision': 0.9736842105263158, 'recall': 1.0, 'f1-score': 0.9866666666666666, 'support': 37}, '1': {'precision': 1.0, 'recall': 0.9629629629629629, 'f1-score': 0.9811320754716981, 'support': 27}, 'accuracy': 0.984375, 'macro avg': {'precision': 0.986842105263158, 'recall': 0.9814814814814814, 'f1-score': 0.9838993710691823, 'support': 64}, 'weighted avg': {'precision': 0.9847861842105263, 'recall': 0.984375, 'f1-score': 0.9843317610062892, 'support': 64}}\n",
      "{'0': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 30}, '1': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 34}, 'accuracy': 1.0, 'macro avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 64}, 'weighted avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 64}}\n",
      "{'0': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 30}, '1': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 34}, 'accuracy': 1.0, 'macro avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 64}, 'weighted avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 64}}\n",
      "{'0': {'precision': 1.0, 'recall': 0.9705882352941176, 'f1-score': 0.9850746268656716, 'support': 34}, '1': {'precision': 0.967741935483871, 'recall': 1.0, 'f1-score': 0.9836065573770492, 'support': 30}, 'accuracy': 0.984375, 'macro avg': {'precision': 0.9838709677419355, 'recall': 0.9852941176470589, 'f1-score': 0.9843405921213604, 'support': 64}, 'weighted avg': {'precision': 0.9848790322580645, 'recall': 0.984375, 'f1-score': 0.9843864692928799, 'support': 64}}\n",
      "{'0': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 39}, '1': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 25}, 'accuracy': 1.0, 'macro avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 64}, 'weighted avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 64}}\n",
      "{'0': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 34}, '1': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 30}, 'accuracy': 1.0, 'macro avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 64}, 'weighted avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 64}}\n",
      "{'0': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 35}, '1': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 29}, 'accuracy': 1.0, 'macro avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 64}, 'weighted avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 64}}\n",
      "{'0': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 42}, '1': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 22}, 'accuracy': 1.0, 'macro avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 64}, 'weighted avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 64}}\n",
      "{'0': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 41}, '1': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 23}, 'accuracy': 1.0, 'macro avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 64}, 'weighted avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 64}}\n",
      "{'0': {'precision': 0.9696969696969697, 'recall': 1.0, 'f1-score': 0.9846153846153847, 'support': 32}, '1': {'precision': 1.0, 'recall': 0.96875, 'f1-score': 0.9841269841269841, 'support': 32}, 'accuracy': 0.984375, 'macro avg': {'precision': 0.9848484848484849, 'recall': 0.984375, 'f1-score': 0.9843711843711844, 'support': 64}, 'weighted avg': {'precision': 0.9848484848484849, 'recall': 0.984375, 'f1-score': 0.9843711843711844, 'support': 64}}\n",
      "{'0': {'precision': 0.9736842105263158, 'recall': 1.0, 'f1-score': 0.9866666666666666, 'support': 37}, '1': {'precision': 1.0, 'recall': 0.9629629629629629, 'f1-score': 0.9811320754716981, 'support': 27}, 'accuracy': 0.984375, 'macro avg': {'precision': 0.986842105263158, 'recall': 0.9814814814814814, 'f1-score': 0.9838993710691823, 'support': 64}, 'weighted avg': {'precision': 0.9847861842105263, 'recall': 0.984375, 'f1-score': 0.9843317610062892, 'support': 64}}\n",
      "{'0': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 34}, '1': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 30}, 'accuracy': 1.0, 'macro avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 64}, 'weighted avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 64}}\n",
      "{'0': {'precision': 0.9736842105263158, 'recall': 1.0, 'f1-score': 0.9866666666666666, 'support': 37}, '1': {'precision': 1.0, 'recall': 0.9629629629629629, 'f1-score': 0.9811320754716981, 'support': 27}, 'accuracy': 0.984375, 'macro avg': {'precision': 0.986842105263158, 'recall': 0.9814814814814814, 'f1-score': 0.9838993710691823, 'support': 64}, 'weighted avg': {'precision': 0.9847861842105263, 'recall': 0.984375, 'f1-score': 0.9843317610062892, 'support': 64}}\n",
      "{'0': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 36}, '1': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 28}, 'accuracy': 1.0, 'macro avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 64}, 'weighted avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 64}}\n",
      "{'0': {'precision': 0.9743589743589743, 'recall': 1.0, 'f1-score': 0.9870129870129869, 'support': 38}, '1': {'precision': 1.0, 'recall': 0.9615384615384616, 'f1-score': 0.9803921568627451, 'support': 26}, 'accuracy': 0.984375, 'macro avg': {'precision': 0.9871794871794872, 'recall': 0.9807692307692308, 'f1-score': 0.983702571937866, 'support': 64}, 'weighted avg': {'precision': 0.984775641025641, 'recall': 0.984375, 'f1-score': 0.984323274764451, 'support': 64}}\n",
      "{'0': {'precision': 0.9444444444444444, 'recall': 1.0, 'f1-score': 0.9714285714285714, 'support': 34}, '1': {'precision': 1.0, 'recall': 0.9333333333333333, 'f1-score': 0.9655172413793104, 'support': 30}, 'accuracy': 0.96875, 'macro avg': {'precision': 0.9722222222222222, 'recall': 0.9666666666666667, 'f1-score': 0.9684729064039409, 'support': 64}, 'weighted avg': {'precision': 0.970486111111111, 'recall': 0.96875, 'f1-score': 0.9686576354679803, 'support': 64}}\n",
      "{'0': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 34}, '1': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 30}, 'accuracy': 1.0, 'macro avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 64}, 'weighted avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 64}}\n",
      "{'0': {'precision': 0.9722222222222222, 'recall': 1.0, 'f1-score': 0.9859154929577464, 'support': 35}, '1': {'precision': 1.0, 'recall': 0.9655172413793104, 'f1-score': 0.9824561403508771, 'support': 29}, 'accuracy': 0.984375, 'macro avg': {'precision': 0.9861111111111112, 'recall': 0.9827586206896552, 'f1-score': 0.9841858166543118, 'support': 64}, 'weighted avg': {'precision': 0.9848090277777778, 'recall': 0.984375, 'f1-score': 0.9843479738077587, 'support': 64}}\n",
      "{'0': {'precision': 1.0, 'recall': 0.967741935483871, 'f1-score': 0.9836065573770492, 'support': 31}, '1': {'precision': 0.9705882352941176, 'recall': 1.0, 'f1-score': 0.9850746268656716, 'support': 33}, 'accuracy': 0.984375, 'macro avg': {'precision': 0.9852941176470589, 'recall': 0.9838709677419355, 'f1-score': 0.9843405921213604, 'support': 64}, 'weighted avg': {'precision': 0.9848345588235294, 'recall': 0.984375, 'f1-score': 0.9843635307071201, 'support': 64}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'0': {'precision': 0.9655172413793104, 'recall': 0.9655172413793104, 'f1-score': 0.9655172413793104, 'support': 29}, '1': {'precision': 0.9714285714285714, 'recall': 0.9714285714285714, 'f1-score': 0.9714285714285714, 'support': 35}, 'accuracy': 0.96875, 'macro avg': {'precision': 0.9684729064039409, 'recall': 0.9684729064039409, 'f1-score': 0.9684729064039409, 'support': 64}, 'weighted avg': {'precision': 0.96875, 'recall': 0.96875, 'f1-score': 0.96875, 'support': 64}}\n",
      "{'0': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 38}, '1': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 26}, 'accuracy': 1.0, 'macro avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 64}, 'weighted avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 64}}\n",
      "{'0': {'precision': 0.9696969696969697, 'recall': 1.0, 'f1-score': 0.9846153846153847, 'support': 32}, '1': {'precision': 1.0, 'recall': 0.96875, 'f1-score': 0.9841269841269841, 'support': 32}, 'accuracy': 0.984375, 'macro avg': {'precision': 0.9848484848484849, 'recall': 0.984375, 'f1-score': 0.9843711843711844, 'support': 64}, 'weighted avg': {'precision': 0.9848484848484849, 'recall': 0.984375, 'f1-score': 0.9843711843711844, 'support': 64}}\n",
      "{'0': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 36}, '1': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 28}, 'accuracy': 1.0, 'macro avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 64}, 'weighted avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 64}}\n",
      "{'0': {'precision': 0.9642857142857143, 'recall': 1.0, 'f1-score': 0.9818181818181818, 'support': 27}, '1': {'precision': 1.0, 'recall': 0.972972972972973, 'f1-score': 0.9863013698630138, 'support': 37}, 'accuracy': 0.984375, 'macro avg': {'precision': 0.9821428571428572, 'recall': 0.9864864864864865, 'f1-score': 0.9840597758405978, 'support': 64}, 'weighted avg': {'precision': 0.9849330357142857, 'recall': 0.984375, 'f1-score': 0.9844100249066002, 'support': 64}}\n",
      "{'0': {'precision': 0.95, 'recall': 0.9743589743589743, 'f1-score': 0.9620253164556962, 'support': 39}, '1': {'precision': 0.9583333333333334, 'recall': 0.92, 'f1-score': 0.9387755102040817, 'support': 25}, 'accuracy': 0.953125, 'macro avg': {'precision': 0.9541666666666666, 'recall': 0.9471794871794872, 'f1-score': 0.9504004133298889, 'support': 64}, 'weighted avg': {'precision': 0.9532552083333333, 'recall': 0.953125, 'f1-score': 0.9529433608886593, 'support': 64}}\n",
      "{'0': {'precision': 0.9722222222222222, 'recall': 1.0, 'f1-score': 0.9859154929577464, 'support': 35}, '1': {'precision': 1.0, 'recall': 0.9655172413793104, 'f1-score': 0.9824561403508771, 'support': 29}, 'accuracy': 0.984375, 'macro avg': {'precision': 0.9861111111111112, 'recall': 0.9827586206896552, 'f1-score': 0.9841858166543118, 'support': 64}, 'weighted avg': {'precision': 0.9848090277777778, 'recall': 0.984375, 'f1-score': 0.9843479738077587, 'support': 64}}\n",
      "{'0': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 33}, '1': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 31}, 'accuracy': 1.0, 'macro avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 64}, 'weighted avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 64}}\n",
      "{'0': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 30}, '1': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 34}, 'accuracy': 1.0, 'macro avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 64}, 'weighted avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 64}}\n",
      "{'0': {'precision': 0.9696969696969697, 'recall': 1.0, 'f1-score': 0.9846153846153847, 'support': 32}, '1': {'precision': 1.0, 'recall': 0.96875, 'f1-score': 0.9841269841269841, 'support': 32}, 'accuracy': 0.984375, 'macro avg': {'precision': 0.9848484848484849, 'recall': 0.984375, 'f1-score': 0.9843711843711844, 'support': 64}, 'weighted avg': {'precision': 0.9848484848484849, 'recall': 0.984375, 'f1-score': 0.9843711843711844, 'support': 64}}\n",
      "{'0': {'precision': 0.9655172413793104, 'recall': 1.0, 'f1-score': 0.9824561403508771, 'support': 28}, '1': {'precision': 1.0, 'recall': 0.9722222222222222, 'f1-score': 0.9859154929577464, 'support': 36}, 'accuracy': 0.984375, 'macro avg': {'precision': 0.9827586206896552, 'recall': 0.9861111111111112, 'f1-score': 0.9841858166543118, 'support': 64}, 'weighted avg': {'precision': 0.9849137931034483, 'recall': 0.984375, 'f1-score': 0.9844020261922412, 'support': 64}}\n",
      "{'0': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 32}, '1': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 32}, 'accuracy': 1.0, 'macro avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 64}, 'weighted avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 64}}\n",
      "{'0': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 34}, '1': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 30}, 'accuracy': 1.0, 'macro avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 64}, 'weighted avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 64}}\n",
      "{'0': {'precision': 0.9705882352941176, 'recall': 1.0, 'f1-score': 0.9850746268656716, 'support': 33}, '1': {'precision': 1.0, 'recall': 0.967741935483871, 'f1-score': 0.9836065573770492, 'support': 31}, 'accuracy': 0.984375, 'macro avg': {'precision': 0.9852941176470589, 'recall': 0.9838709677419355, 'f1-score': 0.9843405921213604, 'support': 64}, 'weighted avg': {'precision': 0.9848345588235294, 'recall': 0.984375, 'f1-score': 0.9843635307071201, 'support': 64}}\n",
      "{'0': {'precision': 0.96875, 'recall': 1.0, 'f1-score': 0.9841269841269841, 'support': 31}, '1': {'precision': 1.0, 'recall': 0.9696969696969697, 'f1-score': 0.9846153846153847, 'support': 33}, 'accuracy': 0.984375, 'macro avg': {'precision': 0.984375, 'recall': 0.9848484848484849, 'f1-score': 0.9843711843711844, 'support': 64}, 'weighted avg': {'precision': 0.98486328125, 'recall': 0.984375, 'f1-score': 0.9843788156288156, 'support': 64}}\n",
      "{'0': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 36}, '1': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 28}, 'accuracy': 1.0, 'macro avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 64}, 'weighted avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 64}}\n",
      "{'0': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 37}, '1': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 27}, 'accuracy': 1.0, 'macro avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 64}, 'weighted avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 64}}\n",
      "{'0': {'precision': 0.972972972972973, 'recall': 1.0, 'f1-score': 0.9863013698630138, 'support': 36}, '1': {'precision': 1.0, 'recall': 0.9642857142857143, 'f1-score': 0.9818181818181818, 'support': 28}, 'accuracy': 0.984375, 'macro avg': {'precision': 0.9864864864864865, 'recall': 0.9821428571428572, 'f1-score': 0.9840597758405978, 'support': 64}, 'weighted avg': {'precision': 0.9847972972972974, 'recall': 0.984375, 'f1-score': 0.9843399750933998, 'support': 64}}\n",
      "{'0': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 31}, '1': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 33}, 'accuracy': 1.0, 'macro avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 64}, 'weighted avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 64}}\n",
      "{'0': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 36}, '1': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 28}, 'accuracy': 1.0, 'macro avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 64}, 'weighted avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 64}}\n",
      "{'0': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 32}, '1': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 32}, 'accuracy': 1.0, 'macro avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 64}, 'weighted avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 64}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'0': {'precision': 0.9375, 'recall': 0.967741935483871, 'f1-score': 0.9523809523809523, 'support': 31}, '1': {'precision': 0.96875, 'recall': 0.9393939393939394, 'f1-score': 0.9538461538461539, 'support': 33}, 'accuracy': 0.953125, 'macro avg': {'precision': 0.953125, 'recall': 0.9535679374389052, 'f1-score': 0.9531135531135531, 'support': 64}, 'weighted avg': {'precision': 0.95361328125, 'recall': 0.953125, 'f1-score': 0.9531364468864469, 'support': 64}}\n",
      "{'0': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 38}, '1': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 26}, 'accuracy': 1.0, 'macro avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 64}, 'weighted avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 64}}\n",
      "{'0': {'precision': 0.96875, 'recall': 1.0, 'f1-score': 0.9841269841269841, 'support': 31}, '1': {'precision': 1.0, 'recall': 0.9696969696969697, 'f1-score': 0.9846153846153847, 'support': 33}, 'accuracy': 0.984375, 'macro avg': {'precision': 0.984375, 'recall': 0.9848484848484849, 'f1-score': 0.9843711843711844, 'support': 64}, 'weighted avg': {'precision': 0.98486328125, 'recall': 0.984375, 'f1-score': 0.9843788156288156, 'support': 64}}\n",
      "{'0': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 35}, '1': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 29}, 'accuracy': 1.0, 'macro avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 64}, 'weighted avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 64}}\n",
      "{'0': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 32}, '1': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 32}, 'accuracy': 1.0, 'macro avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 64}, 'weighted avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 64}}\n",
      "{'0': {'precision': 0.9736842105263158, 'recall': 1.0, 'f1-score': 0.9866666666666666, 'support': 37}, '1': {'precision': 1.0, 'recall': 0.9629629629629629, 'f1-score': 0.9811320754716981, 'support': 27}, 'accuracy': 0.984375, 'macro avg': {'precision': 0.986842105263158, 'recall': 0.9814814814814814, 'f1-score': 0.9838993710691823, 'support': 64}, 'weighted avg': {'precision': 0.9847861842105263, 'recall': 0.984375, 'f1-score': 0.9843317610062892, 'support': 64}}\n",
      "{'0': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 37}, '1': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 27}, 'accuracy': 1.0, 'macro avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 64}, 'weighted avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 64}}\n",
      "{'0': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 29}, '1': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 35}, 'accuracy': 1.0, 'macro avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 64}, 'weighted avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 64}}\n",
      "{'0': {'precision': 0.9767441860465116, 'recall': 1.0, 'f1-score': 0.988235294117647, 'support': 42}, '1': {'precision': 1.0, 'recall': 0.9545454545454546, 'f1-score': 0.9767441860465117, 'support': 22}, 'accuracy': 0.984375, 'macro avg': {'precision': 0.9883720930232558, 'recall': 0.9772727272727273, 'f1-score': 0.9824897400820793, 'support': 64}, 'weighted avg': {'precision': 0.9847383720930232, 'recall': 0.984375, 'f1-score': 0.9842852257181942, 'support': 64}}\n",
      "{'0': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 35}, '1': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 29}, 'accuracy': 1.0, 'macro avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 64}, 'weighted avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 64}}\n",
      "{'0': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 34}, '1': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 30}, 'accuracy': 1.0, 'macro avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 64}, 'weighted avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 64}}\n",
      "{'0': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 34}, '1': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 30}, 'accuracy': 1.0, 'macro avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 64}, 'weighted avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 64}}\n",
      "{'0': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 40}, '1': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 24}, 'accuracy': 1.0, 'macro avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 64}, 'weighted avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 64}}\n",
      "{'0': {'precision': 0.9545454545454546, 'recall': 1.0, 'f1-score': 0.9767441860465117, 'support': 42}, '1': {'precision': 1.0, 'recall': 0.9090909090909091, 'f1-score': 0.9523809523809523, 'support': 22}, 'accuracy': 0.96875, 'macro avg': {'precision': 0.9772727272727273, 'recall': 0.9545454545454546, 'f1-score': 0.9645625692137321, 'support': 64}, 'weighted avg': {'precision': 0.9701704545454546, 'recall': 0.96875, 'f1-score': 0.9683693244739757, 'support': 64}}\n",
      "{'0': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 31}, '1': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 33}, 'accuracy': 1.0, 'macro avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 64}, 'weighted avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 64}}\n",
      "{'0': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 40}, '1': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 24}, 'accuracy': 1.0, 'macro avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 64}, 'weighted avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 64}}\n",
      "{'0': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 35}, '1': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 29}, 'accuracy': 1.0, 'macro avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 64}, 'weighted avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 64}}\n",
      "{'0': {'precision': 0.9782608695652174, 'recall': 1.0, 'f1-score': 0.989010989010989, 'support': 45}, '1': {'precision': 1.0, 'recall': 0.9473684210526315, 'f1-score': 0.972972972972973, 'support': 19}, 'accuracy': 0.984375, 'macro avg': {'precision': 0.9891304347826086, 'recall': 0.9736842105263157, 'f1-score': 0.980991980991981, 'support': 64}, 'weighted avg': {'precision': 0.9847146739130435, 'recall': 0.984375, 'f1-score': 0.984249702999703, 'support': 64}}\n",
      "{'0': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 40}, '1': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 24}, 'accuracy': 1.0, 'macro avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 64}, 'weighted avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 64}}\n",
      "{'0': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 29}, '1': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 35}, 'accuracy': 1.0, 'macro avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 64}, 'weighted avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 64}}\n",
      "{'0': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 37}, '1': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 27}, 'accuracy': 1.0, 'macro avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 64}, 'weighted avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 64}}\n",
      "{'0': {'precision': 1.0, 'recall': 0.96875, 'f1-score': 0.9841269841269841, 'support': 32}, '1': {'precision': 0.9696969696969697, 'recall': 1.0, 'f1-score': 0.9846153846153847, 'support': 32}, 'accuracy': 0.984375, 'macro avg': {'precision': 0.9848484848484849, 'recall': 0.984375, 'f1-score': 0.9843711843711844, 'support': 64}, 'weighted avg': {'precision': 0.9848484848484849, 'recall': 0.984375, 'f1-score': 0.9843711843711844, 'support': 64}}\n",
      "{'0': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 32}, '1': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 32}, 'accuracy': 1.0, 'macro avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 64}, 'weighted avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 64}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'0': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 27}, '1': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 37}, 'accuracy': 1.0, 'macro avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 64}, 'weighted avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 64}}\n",
      "{'0': {'precision': 0.9705882352941176, 'recall': 1.0, 'f1-score': 0.9850746268656716, 'support': 33}, '1': {'precision': 1.0, 'recall': 0.967741935483871, 'f1-score': 0.9836065573770492, 'support': 31}, 'accuracy': 0.984375, 'macro avg': {'precision': 0.9852941176470589, 'recall': 0.9838709677419355, 'f1-score': 0.9843405921213604, 'support': 64}, 'weighted avg': {'precision': 0.9848345588235294, 'recall': 0.984375, 'f1-score': 0.9843635307071201, 'support': 64}}\n",
      "{'0': {'precision': 1.0, 'recall': 0.9705882352941176, 'f1-score': 0.9850746268656716, 'support': 34}, '1': {'precision': 0.967741935483871, 'recall': 1.0, 'f1-score': 0.9836065573770492, 'support': 30}, 'accuracy': 0.984375, 'macro avg': {'precision': 0.9838709677419355, 'recall': 0.9852941176470589, 'f1-score': 0.9843405921213604, 'support': 64}, 'weighted avg': {'precision': 0.9848790322580645, 'recall': 0.984375, 'f1-score': 0.9843864692928799, 'support': 64}}\n",
      "{'0': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 34}, '1': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 30}, 'accuracy': 1.0, 'macro avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 64}, 'weighted avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 64}}\n",
      "{'0': {'precision': 0.9428571428571428, 'recall': 1.0, 'f1-score': 0.9705882352941176, 'support': 33}, '1': {'precision': 1.0, 'recall': 0.9354838709677419, 'f1-score': 0.9666666666666666, 'support': 31}, 'accuracy': 0.96875, 'macro avg': {'precision': 0.9714285714285714, 'recall': 0.967741935483871, 'f1-score': 0.968627450980392, 'support': 64}, 'weighted avg': {'precision': 0.9705357142857143, 'recall': 0.96875, 'f1-score': 0.9686887254901961, 'support': 64}}\n",
      "{'0': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 38}, '1': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 26}, 'accuracy': 1.0, 'macro avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 64}, 'weighted avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 64}}\n",
      "{'0': {'precision': 0.975609756097561, 'recall': 1.0, 'f1-score': 0.9876543209876543, 'support': 40}, '1': {'precision': 1.0, 'recall': 0.9583333333333334, 'f1-score': 0.9787234042553191, 'support': 24}, 'accuracy': 0.984375, 'macro avg': {'precision': 0.9878048780487805, 'recall': 0.9791666666666667, 'f1-score': 0.9831888626214866, 'support': 64}, 'weighted avg': {'precision': 0.9847560975609756, 'recall': 0.984375, 'f1-score': 0.9843052272130286, 'support': 64}}\n",
      "{'0': {'precision': 0.9411764705882353, 'recall': 0.9696969696969697, 'f1-score': 0.955223880597015, 'support': 33}, '1': {'precision': 0.9666666666666667, 'recall': 0.9354838709677419, 'f1-score': 0.9508196721311476, 'support': 31}, 'accuracy': 0.953125, 'macro avg': {'precision': 0.9539215686274509, 'recall': 0.9525904203323559, 'f1-score': 0.9530217763640814, 'support': 64}, 'weighted avg': {'precision': 0.9535232843137256, 'recall': 0.953125, 'f1-score': 0.9530905921213605, 'support': 64}}\n",
      "{'0': {'precision': 0.9714285714285714, 'recall': 1.0, 'f1-score': 0.9855072463768115, 'support': 34}, '1': {'precision': 1.0, 'recall': 0.9666666666666667, 'f1-score': 0.983050847457627, 'support': 30}, 'accuracy': 0.984375, 'macro avg': {'precision': 0.9857142857142858, 'recall': 0.9833333333333334, 'f1-score': 0.9842790469172193, 'support': 64}, 'weighted avg': {'precision': 0.9848214285714285, 'recall': 0.984375, 'f1-score': 0.9843558093834439, 'support': 64}}\n",
      "{'0': {'precision': 1.0, 'recall': 0.96875, 'f1-score': 0.9841269841269841, 'support': 32}, '1': {'precision': 0.9696969696969697, 'recall': 1.0, 'f1-score': 0.9846153846153847, 'support': 32}, 'accuracy': 0.984375, 'macro avg': {'precision': 0.9848484848484849, 'recall': 0.984375, 'f1-score': 0.9843711843711844, 'support': 64}, 'weighted avg': {'precision': 0.9848484848484849, 'recall': 0.984375, 'f1-score': 0.9843711843711844, 'support': 64}}\n",
      "{'0': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 43}, '1': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 21}, 'accuracy': 1.0, 'macro avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 64}, 'weighted avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 64}}\n",
      "{'0': {'precision': 0.9705882352941176, 'recall': 1.0, 'f1-score': 0.9850746268656716, 'support': 33}, '1': {'precision': 1.0, 'recall': 0.967741935483871, 'f1-score': 0.9836065573770492, 'support': 31}, 'accuracy': 0.984375, 'macro avg': {'precision': 0.9852941176470589, 'recall': 0.9838709677419355, 'f1-score': 0.9843405921213604, 'support': 64}, 'weighted avg': {'precision': 0.9848345588235294, 'recall': 0.984375, 'f1-score': 0.9843635307071201, 'support': 64}}\n",
      "{'0': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 34}, '1': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 30}, 'accuracy': 1.0, 'macro avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 64}, 'weighted avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 64}}\n",
      "{'0': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 30}, '1': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 34}, 'accuracy': 1.0, 'macro avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 64}, 'weighted avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 64}}\n",
      "{'0': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 33}, '1': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 31}, 'accuracy': 1.0, 'macro avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 64}, 'weighted avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 64}}\n",
      "{'0': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 34}, '1': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 30}, 'accuracy': 1.0, 'macro avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 64}, 'weighted avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 64}}\n",
      "{'0': {'precision': 0.9714285714285714, 'recall': 1.0, 'f1-score': 0.9855072463768115, 'support': 34}, '1': {'precision': 1.0, 'recall': 0.9666666666666667, 'f1-score': 0.983050847457627, 'support': 30}, 'accuracy': 0.984375, 'macro avg': {'precision': 0.9857142857142858, 'recall': 0.9833333333333334, 'f1-score': 0.9842790469172193, 'support': 64}, 'weighted avg': {'precision': 0.9848214285714285, 'recall': 0.984375, 'f1-score': 0.9843558093834439, 'support': 64}}\n",
      "{'0': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 38}, '1': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 26}, 'accuracy': 1.0, 'macro avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 64}, 'weighted avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 64}}\n",
      "{'0': {'precision': 1.0, 'recall': 0.975, 'f1-score': 0.9873417721518987, 'support': 40}, '1': {'precision': 0.96, 'recall': 1.0, 'f1-score': 0.9795918367346939, 'support': 24}, 'accuracy': 0.984375, 'macro avg': {'precision': 0.98, 'recall': 0.9875, 'f1-score': 0.9834668044432963, 'support': 64}, 'weighted avg': {'precision': 0.985, 'recall': 0.984375, 'f1-score': 0.9844355463704468, 'support': 64}}\n",
      "{'0': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 30}, '1': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 34}, 'accuracy': 1.0, 'macro avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 64}, 'weighted avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 64}}\n",
      "{'0': {'precision': 1.0, 'recall': 0.9696969696969697, 'f1-score': 0.9846153846153847, 'support': 33}, '1': {'precision': 0.96875, 'recall': 1.0, 'f1-score': 0.9841269841269841, 'support': 31}, 'accuracy': 0.984375, 'macro avg': {'precision': 0.984375, 'recall': 0.9848484848484849, 'f1-score': 0.9843711843711844, 'support': 64}, 'weighted avg': {'precision': 0.98486328125, 'recall': 0.984375, 'f1-score': 0.9843788156288156, 'support': 64}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'0': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 36}, '1': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 28}, 'accuracy': 1.0, 'macro avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 64}, 'weighted avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 64}}\n",
      "{'0': {'precision': 0.972972972972973, 'recall': 0.9473684210526315, 'f1-score': 0.9599999999999999, 'support': 38}, '1': {'precision': 0.9259259259259259, 'recall': 0.9615384615384616, 'f1-score': 0.9433962264150944, 'support': 26}, 'accuracy': 0.953125, 'macro avg': {'precision': 0.9494494494494494, 'recall': 0.9544534412955465, 'f1-score': 0.951698113207547, 'support': 64}, 'weighted avg': {'precision': 0.9538601101101101, 'recall': 0.953125, 'f1-score': 0.9532547169811321, 'support': 64}}\n",
      "{'0': {'precision': 0.96875, 'recall': 1.0, 'f1-score': 0.9841269841269841, 'support': 31}, '1': {'precision': 1.0, 'recall': 0.9696969696969697, 'f1-score': 0.9846153846153847, 'support': 33}, 'accuracy': 0.984375, 'macro avg': {'precision': 0.984375, 'recall': 0.9848484848484849, 'f1-score': 0.9843711843711844, 'support': 64}, 'weighted avg': {'precision': 0.98486328125, 'recall': 0.984375, 'f1-score': 0.9843788156288156, 'support': 64}}\n",
      "{'0': {'precision': 1.0, 'recall': 0.9615384615384616, 'f1-score': 0.9803921568627451, 'support': 26}, '1': {'precision': 0.9743589743589743, 'recall': 1.0, 'f1-score': 0.9870129870129869, 'support': 38}, 'accuracy': 0.984375, 'macro avg': {'precision': 0.9871794871794872, 'recall': 0.9807692307692308, 'f1-score': 0.983702571937866, 'support': 64}, 'weighted avg': {'precision': 0.984775641025641, 'recall': 0.984375, 'f1-score': 0.984323274764451, 'support': 64}}\n",
      "{'0': {'precision': 0.9428571428571428, 'recall': 1.0, 'f1-score': 0.9705882352941176, 'support': 33}, '1': {'precision': 1.0, 'recall': 0.9354838709677419, 'f1-score': 0.9666666666666666, 'support': 31}, 'accuracy': 0.96875, 'macro avg': {'precision': 0.9714285714285714, 'recall': 0.967741935483871, 'f1-score': 0.968627450980392, 'support': 64}, 'weighted avg': {'precision': 0.9705357142857143, 'recall': 0.96875, 'f1-score': 0.9686887254901961, 'support': 64}}\n",
      "{'0': {'precision': 0.9696969696969697, 'recall': 1.0, 'f1-score': 0.9846153846153847, 'support': 32}, '1': {'precision': 1.0, 'recall': 0.96875, 'f1-score': 0.9841269841269841, 'support': 32}, 'accuracy': 0.984375, 'macro avg': {'precision': 0.9848484848484849, 'recall': 0.984375, 'f1-score': 0.9843711843711844, 'support': 64}, 'weighted avg': {'precision': 0.9848484848484849, 'recall': 0.984375, 'f1-score': 0.9843711843711844, 'support': 64}}\n",
      "{'0': {'precision': 0.9666666666666667, 'recall': 1.0, 'f1-score': 0.983050847457627, 'support': 29}, '1': {'precision': 1.0, 'recall': 0.9714285714285714, 'f1-score': 0.9855072463768115, 'support': 35}, 'accuracy': 0.984375, 'macro avg': {'precision': 0.9833333333333334, 'recall': 0.9857142857142858, 'f1-score': 0.9842790469172193, 'support': 64}, 'weighted avg': {'precision': 0.9848958333333333, 'recall': 0.984375, 'f1-score': 0.9843941906165561, 'support': 64}}\n",
      "{'0': {'precision': 0.9666666666666667, 'recall': 1.0, 'f1-score': 0.983050847457627, 'support': 29}, '1': {'precision': 1.0, 'recall': 0.9714285714285714, 'f1-score': 0.9855072463768115, 'support': 35}, 'accuracy': 0.984375, 'macro avg': {'precision': 0.9833333333333334, 'recall': 0.9857142857142858, 'f1-score': 0.9842790469172193, 'support': 64}, 'weighted avg': {'precision': 0.9848958333333333, 'recall': 0.984375, 'f1-score': 0.9843941906165561, 'support': 64}}\n",
      "{'0': {'precision': 0.9705882352941176, 'recall': 0.9705882352941176, 'f1-score': 0.9705882352941176, 'support': 34}, '1': {'precision': 0.9666666666666667, 'recall': 0.9666666666666667, 'f1-score': 0.9666666666666667, 'support': 30}, 'accuracy': 0.96875, 'macro avg': {'precision': 0.9686274509803922, 'recall': 0.9686274509803922, 'f1-score': 0.9686274509803922, 'support': 64}, 'weighted avg': {'precision': 0.96875, 'recall': 0.96875, 'f1-score': 0.96875, 'support': 64}}\n",
      "{'0': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 35}, '1': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 29}, 'accuracy': 1.0, 'macro avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 64}, 'weighted avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 64}}\n",
      "{'0': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 31}, '1': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 33}, 'accuracy': 1.0, 'macro avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 64}, 'weighted avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 64}}\n",
      "{'0': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 32}, '1': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 32}, 'accuracy': 1.0, 'macro avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 64}, 'weighted avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 64}}\n",
      "{'0': {'precision': 0.9696969696969697, 'recall': 1.0, 'f1-score': 0.9846153846153847, 'support': 32}, '1': {'precision': 1.0, 'recall': 0.96875, 'f1-score': 0.9841269841269841, 'support': 32}, 'accuracy': 0.984375, 'macro avg': {'precision': 0.9848484848484849, 'recall': 0.984375, 'f1-score': 0.9843711843711844, 'support': 64}, 'weighted avg': {'precision': 0.9848484848484849, 'recall': 0.984375, 'f1-score': 0.9843711843711844, 'support': 64}}\n",
      "{'0': {'precision': 1.0, 'recall': 0.967741935483871, 'f1-score': 0.9836065573770492, 'support': 31}, '1': {'precision': 0.9705882352941176, 'recall': 1.0, 'f1-score': 0.9850746268656716, 'support': 33}, 'accuracy': 0.984375, 'macro avg': {'precision': 0.9852941176470589, 'recall': 0.9838709677419355, 'f1-score': 0.9843405921213604, 'support': 64}, 'weighted avg': {'precision': 0.9848345588235294, 'recall': 0.984375, 'f1-score': 0.9843635307071201, 'support': 64}}\n",
      "{'0': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 34}, '1': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 30}, 'accuracy': 1.0, 'macro avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 64}, 'weighted avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 64}}\n",
      "{'0': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 40}, '1': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 24}, 'accuracy': 1.0, 'macro avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 64}, 'weighted avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 64}}\n",
      "{'0': {'precision': 0.9722222222222222, 'recall': 1.0, 'f1-score': 0.9859154929577464, 'support': 35}, '1': {'precision': 1.0, 'recall': 0.9655172413793104, 'f1-score': 0.9824561403508771, 'support': 29}, 'accuracy': 0.984375, 'macro avg': {'precision': 0.9861111111111112, 'recall': 0.9827586206896552, 'f1-score': 0.9841858166543118, 'support': 64}, 'weighted avg': {'precision': 0.9848090277777778, 'recall': 0.984375, 'f1-score': 0.9843479738077587, 'support': 64}}\n",
      "{'0': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 29}, '1': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 35}, 'accuracy': 1.0, 'macro avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 64}, 'weighted avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 64}}\n",
      "{'0': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 32}, '1': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 32}, 'accuracy': 1.0, 'macro avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 64}, 'weighted avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 64}}\n",
      "{'0': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 28}, '1': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 36}, 'accuracy': 1.0, 'macro avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 64}, 'weighted avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 64}}\n",
      "{'0': {'precision': 0.96875, 'recall': 1.0, 'f1-score': 0.9841269841269841, 'support': 31}, '1': {'precision': 1.0, 'recall': 0.9696969696969697, 'f1-score': 0.9846153846153847, 'support': 33}, 'accuracy': 0.984375, 'macro avg': {'precision': 0.984375, 'recall': 0.9848484848484849, 'f1-score': 0.9843711843711844, 'support': 64}, 'weighted avg': {'precision': 0.98486328125, 'recall': 0.984375, 'f1-score': 0.9843788156288156, 'support': 64}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'0': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 33}, '1': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 31}, 'accuracy': 1.0, 'macro avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 64}, 'weighted avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 64}}\n",
      "{'0': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 26}, '1': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 38}, 'accuracy': 1.0, 'macro avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 64}, 'weighted avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 64}}\n",
      "{'0': {'precision': 0.9714285714285714, 'recall': 1.0, 'f1-score': 0.9855072463768115, 'support': 34}, '1': {'precision': 1.0, 'recall': 0.9666666666666667, 'f1-score': 0.983050847457627, 'support': 30}, 'accuracy': 0.984375, 'macro avg': {'precision': 0.9857142857142858, 'recall': 0.9833333333333334, 'f1-score': 0.9842790469172193, 'support': 64}, 'weighted avg': {'precision': 0.9848214285714285, 'recall': 0.984375, 'f1-score': 0.9843558093834439, 'support': 64}}\n",
      "{'0': {'precision': 0.9666666666666667, 'recall': 0.9666666666666667, 'f1-score': 0.9666666666666667, 'support': 30}, '1': {'precision': 0.9705882352941176, 'recall': 0.9705882352941176, 'f1-score': 0.9705882352941176, 'support': 34}, 'accuracy': 0.96875, 'macro avg': {'precision': 0.9686274509803922, 'recall': 0.9686274509803922, 'f1-score': 0.9686274509803922, 'support': 64}, 'weighted avg': {'precision': 0.96875, 'recall': 0.96875, 'f1-score': 0.96875, 'support': 64}}\n",
      "{'0': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 34}, '1': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 30}, 'accuracy': 1.0, 'macro avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 64}, 'weighted avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 64}}\n",
      "{'0': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 34}, '1': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 30}, 'accuracy': 1.0, 'macro avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 64}, 'weighted avg': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 64}}\n",
      "{'0': {'precision': 0.9411764705882353, 'recall': 0.9411764705882353, 'f1-score': 0.9411764705882353, 'support': 34}, '1': {'precision': 0.9333333333333333, 'recall': 0.9333333333333333, 'f1-score': 0.9333333333333333, 'support': 30}, 'accuracy': 0.9375, 'macro avg': {'precision': 0.9372549019607843, 'recall': 0.9372549019607843, 'f1-score': 0.9372549019607843, 'support': 64}, 'weighted avg': {'precision': 0.9375, 'recall': 0.9375, 'f1-score': 0.9375, 'support': 64}}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-6a00bb802760>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mget_metrics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataGeneratorTrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-11-e3806bd56255>\u001b[0m in \u001b[0;36mget_metrics\u001b[1;34m(dataLoader)\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0maccuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdataLoader\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m# just 1 batch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive\\Documents\\virtualenvs\\netsec\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    433\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    434\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 435\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    436\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    437\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive\\Documents\\virtualenvs\\netsec\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    473\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    474\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 475\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    476\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    477\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive\\Documents\\virtualenvs\\netsec\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive\\Documents\\virtualenvs\\netsec\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-204c2cd3eed9>\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[1;31m# prepare x data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m         \u001b[0mstring\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m','\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'%s'\u001b[0m \u001b[1;33m%\u001b[0m\u001b[0mx\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0my\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;36m41\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m         \u001b[0mstringLower\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstring\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[0mxData\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcustomOneHotEncoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstringLower\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Dim (200, 39)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive\\Documents\\virtualenvs\\netsec\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    871\u001b[0m                     \u001b[1;31m# AttributeError for IntervalTree get_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    872\u001b[0m                     \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 873\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_tuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    874\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    875\u001b[0m             \u001b[1;31m# we by definition only have the 0th axis\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive\\Documents\\virtualenvs\\netsec\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_getitem_tuple\u001b[1;34m(self, tup)\u001b[0m\n\u001b[0;32m   1447\u001b[0m             \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1448\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1449\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_tuple_same_dim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1450\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1451\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_get_list_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive\\Documents\\virtualenvs\\netsec\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_getitem_tuple_same_dim\u001b[1;34m(self, tup)\u001b[0m\n\u001b[0;32m    748\u001b[0m                 \u001b[1;32mcontinue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    749\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 750\u001b[1;33m             \u001b[0mretval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mretval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    751\u001b[0m             \u001b[1;31m# We should never have retval.ndim < self.ndim, as that should\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    752\u001b[0m             \u001b[1;31m#  be handled by the _getitem_lowerdim call above.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive\\Documents\\virtualenvs\\netsec\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1474\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_getitem_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1475\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mslice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1476\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_slice_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1477\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1478\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive\\Documents\\virtualenvs\\netsec\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_get_slice_axis\u001b[1;34m(self, slice_obj, axis)\u001b[0m\n\u001b[0;32m   1507\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1508\u001b[0m         \u001b[0mlabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_positional_slice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mslice_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1509\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mslice_obj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1510\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1511\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_convert_to_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_setter\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive\\Documents\\virtualenvs\\netsec\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_slice\u001b[1;34m(self, slobj, axis)\u001b[0m\n\u001b[0;32m   3557\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mslobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mslice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mslobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3558\u001b[0m         \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_block_manager_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3559\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_slice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mslobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3560\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3561\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive\\Documents\\virtualenvs\\netsec\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mget_slice\u001b[1;34m(self, slobj, axis)\u001b[0m\n\u001b[0;32m    758\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    759\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 760\u001b[1;33m             \u001b[0mnew_blocks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slice_take_blocks_ax0\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mslobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    761\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    762\u001b[0m             \u001b[0mslicer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mslice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mslobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive\\Documents\\virtualenvs\\netsec\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36m_slice_take_blocks_ax0\u001b[1;34m(self, slice_or_indexer, fill_value, only_slice)\u001b[0m\n\u001b[0;32m   1356\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1357\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0msl_type\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"slice\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"mask\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1358\u001b[1;33m             \u001b[0mblknos\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblknos\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mslobj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1359\u001b[0m             \u001b[0mblklocs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblklocs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mslobj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1360\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive\\Documents\\virtualenvs\\netsec\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mblknos\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    173\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_blknos\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    174\u001b[0m             \u001b[1;31m# Note: these can be altered by other BlockManager methods.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 175\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_rebuild_blknos_and_blklocs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    176\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    177\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_blknos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive\\Documents\\virtualenvs\\netsec\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36m_rebuild_blknos_and_blklocs\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    248\u001b[0m             \u001b[0mrl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mblk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmgr_locs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    249\u001b[0m             \u001b[0mnew_blknos\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mblkno\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 250\u001b[1;33m             \u001b[0mnew_blklocs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    251\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    252\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnew_blknos\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "get_metrics(dataGeneratorTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
