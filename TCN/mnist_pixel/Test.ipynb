{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import sys\n",
    "sys.path.append(\"../../\")\n",
    "from TCN.mnist_pixel.utils import data_generator\n",
    "from TCN.mnist_pixel.model import TCN\n",
    "import numpy as np\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def customOneHotEncoder(data):\n",
    "    dataAdjust = data.ljust(200,'0')[:200] # padding if not of length and adjusting the data lenght to get a 200x39 input matrix\n",
    "    # define universe of possible input values\n",
    "    alphabet = '0123456789abcdefghijklmnopqrstuvwxyz,._'\n",
    "    # define a mapping of chars to integers\n",
    "    char_to_int = dict((c, i) for i, c in enumerate(alphabet))\n",
    "    int_to_char = dict((i, c) for i, c in enumerate(alphabet))\n",
    "    # integer encode input data\n",
    "    integer_encoded = [char_to_int[char] for char in dataAdjust]\n",
    "    #print(integer_encoded)\n",
    "    # one hot encode\n",
    "    onehot_encoded = list()\n",
    "    for i, value in enumerate(integer_encoded):\n",
    "        letter = [0 for _ in range(len(alphabet))]\n",
    "        letter[value] = 1\n",
    "        onehot_encoded.append(letter)\n",
    "    #print(onehot_encoded) # the real encoding\n",
    "    return onehot_encoded\n",
    "\n",
    "# takes a .csv filename\n",
    "def dataPreprocessing(fileName):\n",
    "    df = pd.read_csv(fileName, header = None)\n",
    "    \n",
    "    #prepare the imput data\n",
    "    xString = df.iloc[:,:41].to_string(header=False, index=False, index_names = False).split('\\n')\n",
    "    xList = [','.join(ele.split()) for ele in xString] # gives comma separated strings for each row of DataFrame\n",
    "    xData = []\n",
    "    for string in xList:\n",
    "        stringLower = string.lower()\n",
    "        oneHot = customOneHotEncoder(stringLower)\n",
    "        xData.append(oneHot)\n",
    "    xMid = np.array(xData)\n",
    "    xArray = xMid.transpose(0,2,1) # convert xMid's dim (size, 200, 39) to (size, 39, 200)\n",
    "    \n",
    "    #prepare the label data\n",
    "    df[41] = np.where(df[41]=='normal', 'normal', 'attack') # replacing anything except 'normal' with 'attack'\n",
    "    Ydf = df[41]\n",
    "    #labelName = Ydf.unique().tolist().sort() # sorted 38 label names\n",
    "    #yArray = Ydf.str.get_dummies().to_numpy() # ndarray of shape(rows/lines, 38)\n",
    "    yArray = Ydf.to_numpy()\n",
    "    \n",
    "    assert xArray.shape[0] == yArray.shape[0], 'unequal input and label sample size'\n",
    "    \n",
    "    \n",
    "    return xArray, yArray # return processed array of input and label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class NSLKDDDataset(Dataset):\n",
    "    def __init__(self, fileName):\n",
    "        self.data = pd.read_csv(fileName, header = None)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # prepare x data\n",
    "        string = list(','.join('%s' %x for x in y) for y in self.data.iloc[[idx], :41].values)\n",
    "        stringLower = string[0].lower()\n",
    "        xData = customOneHotEncoder(stringLower) # Dim (200, 39)\n",
    "        xMid = np.array(xData)\n",
    "        xArray = xMid.transpose() # should be now (39, 200)\n",
    "        \n",
    "        # prepate y data\n",
    "        #self.data.iloc[idx, 41] = np.where(self.data.iloc[idx, 41]=='normal', 0, 1) # replacing normals with 0 and anything else with 1\n",
    "        yArray = np.where(self.data.iloc[idx, 41]=='normal', 0, 1)\n",
    "        \n",
    "        #yArray = Ydf.to_numpy()\n",
    "    \n",
    "        #assert xArray.shape == yArray.shape, 'unequal input and label sample size'\n",
    "        \n",
    "        return torch.from_numpy(xArray), torch.from_numpy(yArray) # returns torch tensor of x and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split contents of kddtrain\n",
    "#output KDDVal.csv AND kddtrain.csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100778 25195\n"
     ]
    }
   ],
   "source": [
    "params = {'batch_size': 64, 'shuffle': True}\n",
    "fileNameTrain = 'KDDTrain+.csv'\n",
    "fileNameTest = 'KDDTest+.csv'\n",
    "#split kddtrain\n",
    "#datasetVal = NLSKDDDataset(filenameVal)\n",
    "dataset = NSLKDDDataset(fileNameTrain)\n",
    "total_length= 125973\n",
    "train_length = int(0.8 * total_length)\n",
    "val_length = total_length - train_length\n",
    "datasetTrain, datasetVal = torch.utils.data.random_split(dataset, [train_length, val_length])#125973 \n",
    "datasetTest = NSLKDDDataset(fileNameTest)\n",
    "dataGeneratorTrain = DataLoader(datasetTrain, **params)\n",
    "dataGeneratorTest = DataLoader(datasetTest, **params)\n",
    "dataGeneratorVal = DataLoader(datasetVal, **params)\n",
    "\n",
    "print(len(dataGeneratorTrain.dataset), len(dataGeneratorVal.dataset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = './data/mnist'\n",
    "batch_size = 64\n",
    "n_classes = 2\n",
    "input_channels = 39\n",
    "seq_length = int(200)\n",
    "epochs = 100\n",
    "steps = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_loader, test_loader = data_generator(root, batch_size)\n",
    "\n",
    "permute = torch.Tensor(np.random.permutation(784).astype(np.float64)).long()\n",
    "channel_sizes = [32] * 6 #hidden nodes times levels \n",
    "kernel_size = 5\n",
    "model = TCN(input_channels, n_classes, channel_sizes, kernel_size=kernel_size, dropout=0.25)\n",
    "\n",
    "\n",
    "lr = 1e-5\n",
    "optimizer = getattr(optim, 'Adam')(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(ep):\n",
    "    global steps\n",
    "    train_loss = 0\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(dataGeneratorTrain):\n",
    "        # print('data Shape: {} target shape: {} data type: {}'.format(data.shape, target.shape, type(data)))\n",
    "        optimizer.zero_grad()\n",
    "        data = data.view(-1, input_channels, seq_length)\n",
    "        data, target = Variable(data), Variable(target)\n",
    "        #print('data Shape: {} target shape: {} data type: {}'.format(data.shape, target.shape, type(data)))\n",
    "        #print(target)\n",
    "        optimizer.zero_grad()\n",
    "        #print(data[0])\n",
    "        data = data.type(torch.FloatTensor)\n",
    "        output = model(data)\n",
    "        #print(output.shape)\n",
    "        target = target.type(torch.LongTensor)\n",
    "        #loss1 = torch.nn.CrossEntropyLoss()\n",
    "        loss = F.nll_loss(output, target) # negative log likelihood\n",
    "        #loss = loss1(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss\n",
    "        steps += seq_length\n",
    "        if batch_idx > 0 and batch_idx % 100 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\\tSteps: {}'.format(\n",
    "                ep, batch_idx * batch_size, len(dataGeneratorTrain.dataset),\n",
    "                100. * batch_idx / len(dataGeneratorTrain), train_loss.item()/100, steps))\n",
    "            train_loss = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in dataGeneratorVal:\n",
    "            model.eval()\n",
    "            #data = data.view(-1, input_channels, seq_length)\n",
    "            data = data.type(torch.FloatTensor)\n",
    "            target = target.type(torch.LongTensor)\n",
    "            data, target = Variable(data, volatile=True), Variable(target)\n",
    "            output = model(data)\n",
    "            #loss1 = torch.nn.CrossEntropyLoss()\n",
    "            test_loss += F.nll_loss(output, target, size_average=False).item()\n",
    "            #test_loss += loss1(output, target).item()\n",
    "            #print(output.data.max(1, keepdim=True)[1])\n",
    "            pred = output.data.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "\n",
    "        test_loss /= len(dataGeneratorTest.dataset)\n",
    "        print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "            test_loss, correct, len(dataGeneratorVal.dataset),\n",
    "            100. * correct / len(dataGeneratorVal.dataset)))\n",
    "        return test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [6400/100778 (6%)]\tLoss: 0.701377\tSteps: 20200\n",
      "Train Epoch: 1 [12800/100778 (13%)]\tLoss: 0.691883\tSteps: 40200\n",
      "Train Epoch: 1 [19200/100778 (19%)]\tLoss: 0.691944\tSteps: 60200\n",
      "Train Epoch: 1 [25600/100778 (25%)]\tLoss: 0.691023\tSteps: 80200\n",
      "Train Epoch: 1 [32000/100778 (32%)]\tLoss: 0.690488\tSteps: 100200\n",
      "Train Epoch: 1 [38400/100778 (38%)]\tLoss: 0.690594\tSteps: 120200\n",
      "Train Epoch: 1 [44800/100778 (44%)]\tLoss: 0.688506\tSteps: 140200\n",
      "Train Epoch: 1 [51200/100778 (51%)]\tLoss: 0.688375\tSteps: 160200\n",
      "Train Epoch: 1 [57600/100778 (57%)]\tLoss: 0.689154\tSteps: 180200\n",
      "Train Epoch: 1 [64000/100778 (63%)]\tLoss: 0.687747\tSteps: 200200\n",
      "Train Epoch: 1 [70400/100778 (70%)]\tLoss: 0.689063\tSteps: 220200\n",
      "Train Epoch: 1 [76800/100778 (76%)]\tLoss: 0.687365\tSteps: 240200\n",
      "Train Epoch: 1 [83200/100778 (83%)]\tLoss: 0.687785\tSteps: 260200\n",
      "Train Epoch: 1 [89600/100778 (89%)]\tLoss: 0.685704\tSteps: 280200\n",
      "Train Epoch: 1 [96000/100778 (95%)]\tLoss: 0.684722\tSteps: 300200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lromo\\OneDrive\\Documents\\virtualenvs\\netsec\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "C:\\Users\\lromo\\OneDrive\\Documents\\virtualenvs\\netsec\\lib\\site-packages\\torch\\nn\\_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.7627, Accuracy: 13357/25195 (53%)\n",
      "\n",
      "Train Epoch: 2 [6400/100778 (6%)]\tLoss: 0.688875\tSteps: 335200\n",
      "Train Epoch: 2 [12800/100778 (13%)]\tLoss: 0.680082\tSteps: 355200\n",
      "Train Epoch: 2 [19200/100778 (19%)]\tLoss: 0.676398\tSteps: 375200\n",
      "Train Epoch: 2 [25600/100778 (25%)]\tLoss: 0.674662\tSteps: 395200\n",
      "Train Epoch: 2 [32000/100778 (32%)]\tLoss: 0.667230\tSteps: 415200\n",
      "Train Epoch: 2 [38400/100778 (38%)]\tLoss: 0.661322\tSteps: 435200\n",
      "Train Epoch: 2 [44800/100778 (44%)]\tLoss: 0.650348\tSteps: 455200\n",
      "Train Epoch: 2 [51200/100778 (51%)]\tLoss: 0.630112\tSteps: 475200\n",
      "Train Epoch: 2 [57600/100778 (57%)]\tLoss: 0.603128\tSteps: 495200\n",
      "Train Epoch: 2 [64000/100778 (63%)]\tLoss: 0.553956\tSteps: 515200\n",
      "Train Epoch: 2 [70400/100778 (70%)]\tLoss: 0.474554\tSteps: 535200\n",
      "Train Epoch: 2 [76800/100778 (76%)]\tLoss: 0.381434\tSteps: 555200\n",
      "Train Epoch: 2 [83200/100778 (83%)]\tLoss: 0.295456\tSteps: 575200\n",
      "Train Epoch: 2 [89600/100778 (89%)]\tLoss: 0.252966\tSteps: 595200\n",
      "Train Epoch: 2 [96000/100778 (95%)]\tLoss: 0.237057\tSteps: 615200\n",
      "\n",
      "Test set: Average loss: 0.2021, Accuracy: 23612/25195 (94%)\n",
      "\n",
      "Train Epoch: 3 [6400/100778 (6%)]\tLoss: 0.216042\tSteps: 650200\n",
      "Train Epoch: 3 [12800/100778 (13%)]\tLoss: 0.207561\tSteps: 670200\n",
      "Train Epoch: 3 [19200/100778 (19%)]\tLoss: 0.196472\tSteps: 690200\n",
      "Train Epoch: 3 [25600/100778 (25%)]\tLoss: 0.200109\tSteps: 710200\n",
      "Train Epoch: 3 [32000/100778 (32%)]\tLoss: 0.198147\tSteps: 730200\n",
      "Train Epoch: 3 [38400/100778 (38%)]\tLoss: 0.188426\tSteps: 750200\n",
      "Train Epoch: 3 [44800/100778 (44%)]\tLoss: 0.190157\tSteps: 770200\n",
      "Train Epoch: 3 [51200/100778 (51%)]\tLoss: 0.165395\tSteps: 790200\n",
      "Train Epoch: 3 [57600/100778 (57%)]\tLoss: 0.178806\tSteps: 810200\n",
      "Train Epoch: 3 [64000/100778 (63%)]\tLoss: 0.161705\tSteps: 830200\n",
      "Train Epoch: 3 [70400/100778 (70%)]\tLoss: 0.168914\tSteps: 850200\n",
      "Train Epoch: 3 [76800/100778 (76%)]\tLoss: 0.155069\tSteps: 870200\n",
      "Train Epoch: 3 [83200/100778 (83%)]\tLoss: 0.174590\tSteps: 890200\n",
      "Train Epoch: 3 [89600/100778 (89%)]\tLoss: 0.162759\tSteps: 910200\n",
      "Train Epoch: 3 [96000/100778 (95%)]\tLoss: 0.165212\tSteps: 930200\n",
      "\n",
      "Test set: Average loss: 0.1374, Accuracy: 24346/25195 (97%)\n",
      "\n",
      "Train Epoch: 4 [6400/100778 (6%)]\tLoss: 0.159793\tSteps: 965200\n",
      "Train Epoch: 4 [12800/100778 (13%)]\tLoss: 0.143760\tSteps: 985200\n",
      "Train Epoch: 4 [19200/100778 (19%)]\tLoss: 0.150207\tSteps: 1005200\n",
      "Train Epoch: 4 [25600/100778 (25%)]\tLoss: 0.142578\tSteps: 1025200\n",
      "Train Epoch: 4 [32000/100778 (32%)]\tLoss: 0.134392\tSteps: 1045200\n",
      "Train Epoch: 4 [38400/100778 (38%)]\tLoss: 0.154825\tSteps: 1065200\n",
      "Train Epoch: 4 [44800/100778 (44%)]\tLoss: 0.140105\tSteps: 1085200\n",
      "Train Epoch: 4 [51200/100778 (51%)]\tLoss: 0.155607\tSteps: 1105200\n",
      "Train Epoch: 4 [57600/100778 (57%)]\tLoss: 0.140549\tSteps: 1125200\n",
      "Train Epoch: 4 [64000/100778 (63%)]\tLoss: 0.143156\tSteps: 1145200\n",
      "Train Epoch: 4 [70400/100778 (70%)]\tLoss: 0.150206\tSteps: 1165200\n",
      "Train Epoch: 4 [76800/100778 (76%)]\tLoss: 0.138935\tSteps: 1185200\n",
      "Train Epoch: 4 [83200/100778 (83%)]\tLoss: 0.136263\tSteps: 1205200\n",
      "Train Epoch: 4 [89600/100778 (89%)]\tLoss: 0.138462\tSteps: 1225200\n",
      "Train Epoch: 4 [96000/100778 (95%)]\tLoss: 0.133706\tSteps: 1245200\n",
      "\n",
      "Test set: Average loss: 0.1191, Accuracy: 24417/25195 (97%)\n",
      "\n",
      "Train Epoch: 5 [6400/100778 (6%)]\tLoss: 0.128760\tSteps: 1280200\n",
      "Train Epoch: 5 [12800/100778 (13%)]\tLoss: 0.132387\tSteps: 1300200\n",
      "Train Epoch: 5 [19200/100778 (19%)]\tLoss: 0.129929\tSteps: 1320200\n",
      "Train Epoch: 5 [25600/100778 (25%)]\tLoss: 0.126821\tSteps: 1340200\n",
      "Train Epoch: 5 [32000/100778 (32%)]\tLoss: 0.135639\tSteps: 1360200\n",
      "Train Epoch: 5 [38400/100778 (38%)]\tLoss: 0.125922\tSteps: 1380200\n",
      "Train Epoch: 5 [44800/100778 (44%)]\tLoss: 0.137946\tSteps: 1400200\n",
      "Train Epoch: 5 [51200/100778 (51%)]\tLoss: 0.121509\tSteps: 1420200\n",
      "Train Epoch: 5 [57600/100778 (57%)]\tLoss: 0.129264\tSteps: 1440200\n",
      "Train Epoch: 5 [64000/100778 (63%)]\tLoss: 0.125476\tSteps: 1460200\n",
      "Train Epoch: 5 [70400/100778 (70%)]\tLoss: 0.128383\tSteps: 1480200\n",
      "Train Epoch: 5 [76800/100778 (76%)]\tLoss: 0.124586\tSteps: 1500200\n",
      "Train Epoch: 5 [83200/100778 (83%)]\tLoss: 0.129106\tSteps: 1520200\n",
      "Train Epoch: 5 [89600/100778 (89%)]\tLoss: 0.112871\tSteps: 1540200\n",
      "Train Epoch: 5 [96000/100778 (95%)]\tLoss: 0.134023\tSteps: 1560200\n",
      "\n",
      "Test set: Average loss: 0.1077, Accuracy: 24444/25195 (97%)\n",
      "\n",
      "Train Epoch: 6 [6400/100778 (6%)]\tLoss: 0.119524\tSteps: 1595200\n",
      "Train Epoch: 6 [12800/100778 (13%)]\tLoss: 0.124696\tSteps: 1615200\n",
      "Train Epoch: 6 [19200/100778 (19%)]\tLoss: 0.119012\tSteps: 1635200\n",
      "Train Epoch: 6 [25600/100778 (25%)]\tLoss: 0.115942\tSteps: 1655200\n",
      "Train Epoch: 6 [32000/100778 (32%)]\tLoss: 0.120331\tSteps: 1675200\n",
      "Train Epoch: 6 [38400/100778 (38%)]\tLoss: 0.112475\tSteps: 1695200\n",
      "Train Epoch: 6 [44800/100778 (44%)]\tLoss: 0.111941\tSteps: 1715200\n",
      "Train Epoch: 6 [51200/100778 (51%)]\tLoss: 0.101516\tSteps: 1735200\n",
      "Train Epoch: 6 [57600/100778 (57%)]\tLoss: 0.116125\tSteps: 1755200\n",
      "Train Epoch: 6 [64000/100778 (63%)]\tLoss: 0.111848\tSteps: 1775200\n",
      "Train Epoch: 6 [70400/100778 (70%)]\tLoss: 0.112760\tSteps: 1795200\n",
      "Train Epoch: 6 [76800/100778 (76%)]\tLoss: 0.114174\tSteps: 1815200\n",
      "Train Epoch: 6 [83200/100778 (83%)]\tLoss: 0.119326\tSteps: 1835200\n",
      "Train Epoch: 6 [89600/100778 (89%)]\tLoss: 0.108552\tSteps: 1855200\n",
      "Train Epoch: 6 [96000/100778 (95%)]\tLoss: 0.116294\tSteps: 1875200\n",
      "\n",
      "Test set: Average loss: 0.0962, Accuracy: 24498/25195 (97%)\n",
      "\n",
      "Train Epoch: 7 [6400/100778 (6%)]\tLoss: 0.102329\tSteps: 1910200\n",
      "Train Epoch: 7 [12800/100778 (13%)]\tLoss: 0.105201\tSteps: 1930200\n",
      "Train Epoch: 7 [19200/100778 (19%)]\tLoss: 0.108903\tSteps: 1950200\n",
      "Train Epoch: 7 [25600/100778 (25%)]\tLoss: 0.109338\tSteps: 1970200\n",
      "Train Epoch: 7 [32000/100778 (32%)]\tLoss: 0.109760\tSteps: 1990200\n",
      "Train Epoch: 7 [38400/100778 (38%)]\tLoss: 0.103377\tSteps: 2010200\n",
      "Train Epoch: 7 [44800/100778 (44%)]\tLoss: 0.093600\tSteps: 2030200\n",
      "Train Epoch: 7 [51200/100778 (51%)]\tLoss: 0.099724\tSteps: 2050200\n",
      "Train Epoch: 7 [57600/100778 (57%)]\tLoss: 0.096585\tSteps: 2070200\n",
      "Train Epoch: 7 [64000/100778 (63%)]\tLoss: 0.111518\tSteps: 2090200\n",
      "Train Epoch: 7 [70400/100778 (70%)]\tLoss: 0.087941\tSteps: 2110200\n",
      "Train Epoch: 7 [76800/100778 (76%)]\tLoss: 0.106771\tSteps: 2130200\n",
      "Train Epoch: 7 [83200/100778 (83%)]\tLoss: 0.106024\tSteps: 2150200\n",
      "Train Epoch: 7 [89600/100778 (89%)]\tLoss: 0.104594\tSteps: 2170200\n",
      "Train Epoch: 7 [96000/100778 (95%)]\tLoss: 0.101828\tSteps: 2190200\n",
      "\n",
      "Test set: Average loss: 0.0747, Accuracy: 24597/25195 (98%)\n",
      "\n",
      "Train Epoch: 8 [6400/100778 (6%)]\tLoss: 0.091049\tSteps: 2225200\n",
      "Train Epoch: 8 [12800/100778 (13%)]\tLoss: 0.085804\tSteps: 2245200\n",
      "Train Epoch: 8 [19200/100778 (19%)]\tLoss: 0.088470\tSteps: 2265200\n",
      "Train Epoch: 8 [25600/100778 (25%)]\tLoss: 0.094754\tSteps: 2285200\n",
      "Train Epoch: 8 [32000/100778 (32%)]\tLoss: 0.082391\tSteps: 2305200\n",
      "Train Epoch: 8 [38400/100778 (38%)]\tLoss: 0.087805\tSteps: 2325200\n",
      "Train Epoch: 8 [44800/100778 (44%)]\tLoss: 0.078620\tSteps: 2345200\n",
      "Train Epoch: 8 [51200/100778 (51%)]\tLoss: 0.082233\tSteps: 2365200\n",
      "Train Epoch: 8 [57600/100778 (57%)]\tLoss: 0.087913\tSteps: 2385200\n",
      "Train Epoch: 8 [64000/100778 (63%)]\tLoss: 0.068166\tSteps: 2405200\n",
      "Train Epoch: 8 [70400/100778 (70%)]\tLoss: 0.078052\tSteps: 2425200\n",
      "Train Epoch: 8 [76800/100778 (76%)]\tLoss: 0.071666\tSteps: 2445200\n",
      "Train Epoch: 8 [83200/100778 (83%)]\tLoss: 0.076583\tSteps: 2465200\n",
      "Train Epoch: 8 [89600/100778 (89%)]\tLoss: 0.086148\tSteps: 2485200\n",
      "Train Epoch: 8 [96000/100778 (95%)]\tLoss: 0.075946\tSteps: 2505200\n",
      "\n",
      "Test set: Average loss: 0.0528, Accuracy: 24849/25195 (99%)\n",
      "\n",
      "Train Epoch: 9 [6400/100778 (6%)]\tLoss: 0.073399\tSteps: 2540200\n",
      "Train Epoch: 9 [12800/100778 (13%)]\tLoss: 0.080690\tSteps: 2560200\n",
      "Train Epoch: 9 [19200/100778 (19%)]\tLoss: 0.063848\tSteps: 2580200\n",
      "Train Epoch: 9 [25600/100778 (25%)]\tLoss: 0.079634\tSteps: 2600200\n",
      "Train Epoch: 9 [32000/100778 (32%)]\tLoss: 0.070585\tSteps: 2620200\n",
      "Train Epoch: 9 [38400/100778 (38%)]\tLoss: 0.070313\tSteps: 2640200\n",
      "Train Epoch: 9 [44800/100778 (44%)]\tLoss: 0.068282\tSteps: 2660200\n",
      "Train Epoch: 9 [51200/100778 (51%)]\tLoss: 0.077804\tSteps: 2680200\n",
      "Train Epoch: 9 [57600/100778 (57%)]\tLoss: 0.078250\tSteps: 2700200\n",
      "Train Epoch: 9 [64000/100778 (63%)]\tLoss: 0.062364\tSteps: 2720200\n",
      "Train Epoch: 9 [70400/100778 (70%)]\tLoss: 0.067671\tSteps: 2740200\n",
      "Train Epoch: 9 [76800/100778 (76%)]\tLoss: 0.069734\tSteps: 2760200\n",
      "Train Epoch: 9 [83200/100778 (83%)]\tLoss: 0.070298\tSteps: 2780200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 9 [89600/100778 (89%)]\tLoss: 0.066449\tSteps: 2800200\n",
      "Train Epoch: 9 [96000/100778 (95%)]\tLoss: 0.064326\tSteps: 2820200\n",
      "\n",
      "Test set: Average loss: 0.0456, Accuracy: 24933/25195 (99%)\n",
      "\n",
      "Train Epoch: 10 [6400/100778 (6%)]\tLoss: 0.057592\tSteps: 2855200\n",
      "Train Epoch: 10 [12800/100778 (13%)]\tLoss: 0.068901\tSteps: 2875200\n",
      "Train Epoch: 10 [19200/100778 (19%)]\tLoss: 0.066829\tSteps: 2895200\n",
      "Train Epoch: 10 [25600/100778 (25%)]\tLoss: 0.068241\tSteps: 2915200\n",
      "Train Epoch: 10 [32000/100778 (32%)]\tLoss: 0.059929\tSteps: 2935200\n",
      "Train Epoch: 10 [38400/100778 (38%)]\tLoss: 0.062180\tSteps: 2955200\n",
      "Train Epoch: 10 [44800/100778 (44%)]\tLoss: 0.062534\tSteps: 2975200\n",
      "Train Epoch: 10 [51200/100778 (51%)]\tLoss: 0.065844\tSteps: 2995200\n",
      "Train Epoch: 10 [57600/100778 (57%)]\tLoss: 0.065552\tSteps: 3015200\n",
      "Train Epoch: 10 [64000/100778 (63%)]\tLoss: 0.068157\tSteps: 3035200\n",
      "Train Epoch: 10 [70400/100778 (70%)]\tLoss: 0.057296\tSteps: 3055200\n",
      "Train Epoch: 10 [76800/100778 (76%)]\tLoss: 0.064670\tSteps: 3075200\n",
      "Train Epoch: 10 [83200/100778 (83%)]\tLoss: 0.062732\tSteps: 3095200\n",
      "Train Epoch: 10 [89600/100778 (89%)]\tLoss: 0.060252\tSteps: 3115200\n",
      "Train Epoch: 10 [96000/100778 (95%)]\tLoss: 0.061766\tSteps: 3135200\n",
      "\n",
      "Test set: Average loss: 0.0413, Accuracy: 24955/25195 (99%)\n",
      "\n",
      "Train Epoch: 11 [6400/100778 (6%)]\tLoss: 0.055086\tSteps: 3170200\n",
      "Train Epoch: 11 [12800/100778 (13%)]\tLoss: 0.056614\tSteps: 3190200\n",
      "Train Epoch: 11 [19200/100778 (19%)]\tLoss: 0.055459\tSteps: 3210200\n",
      "Train Epoch: 11 [25600/100778 (25%)]\tLoss: 0.057288\tSteps: 3230200\n",
      "Train Epoch: 11 [32000/100778 (32%)]\tLoss: 0.055544\tSteps: 3250200\n",
      "Train Epoch: 11 [38400/100778 (38%)]\tLoss: 0.064591\tSteps: 3270200\n",
      "Train Epoch: 11 [44800/100778 (44%)]\tLoss: 0.062764\tSteps: 3290200\n",
      "Train Epoch: 11 [51200/100778 (51%)]\tLoss: 0.057343\tSteps: 3310200\n",
      "Train Epoch: 11 [57600/100778 (57%)]\tLoss: 0.064757\tSteps: 3330200\n",
      "Train Epoch: 11 [64000/100778 (63%)]\tLoss: 0.066864\tSteps: 3350200\n",
      "Train Epoch: 11 [70400/100778 (70%)]\tLoss: 0.060791\tSteps: 3370200\n",
      "Train Epoch: 11 [76800/100778 (76%)]\tLoss: 0.065992\tSteps: 3390200\n",
      "Train Epoch: 11 [83200/100778 (83%)]\tLoss: 0.053463\tSteps: 3410200\n",
      "Train Epoch: 11 [89600/100778 (89%)]\tLoss: 0.062069\tSteps: 3430200\n",
      "Train Epoch: 11 [96000/100778 (95%)]\tLoss: 0.062981\tSteps: 3450200\n",
      "\n",
      "Test set: Average loss: 0.0408, Accuracy: 24954/25195 (99%)\n",
      "\n",
      "Train Epoch: 12 [6400/100778 (6%)]\tLoss: 0.062135\tSteps: 3485200\n",
      "Train Epoch: 12 [12800/100778 (13%)]\tLoss: 0.062698\tSteps: 3505200\n",
      "Train Epoch: 12 [19200/100778 (19%)]\tLoss: 0.067252\tSteps: 3525200\n",
      "Train Epoch: 12 [25600/100778 (25%)]\tLoss: 0.062111\tSteps: 3545200\n",
      "Train Epoch: 12 [32000/100778 (32%)]\tLoss: 0.063644\tSteps: 3565200\n",
      "Train Epoch: 12 [38400/100778 (38%)]\tLoss: 0.054042\tSteps: 3585200\n",
      "Train Epoch: 12 [44800/100778 (44%)]\tLoss: 0.064835\tSteps: 3605200\n",
      "Train Epoch: 12 [51200/100778 (51%)]\tLoss: 0.061527\tSteps: 3625200\n",
      "Train Epoch: 12 [57600/100778 (57%)]\tLoss: 0.061653\tSteps: 3645200\n",
      "Train Epoch: 12 [64000/100778 (63%)]\tLoss: 0.057986\tSteps: 3665200\n",
      "Train Epoch: 12 [70400/100778 (70%)]\tLoss: 0.066977\tSteps: 3685200\n",
      "Train Epoch: 12 [76800/100778 (76%)]\tLoss: 0.060483\tSteps: 3705200\n",
      "Train Epoch: 12 [83200/100778 (83%)]\tLoss: 0.058244\tSteps: 3725200\n",
      "Train Epoch: 12 [89600/100778 (89%)]\tLoss: 0.061645\tSteps: 3745200\n",
      "Train Epoch: 12 [96000/100778 (95%)]\tLoss: 0.058628\tSteps: 3765200\n",
      "\n",
      "Test set: Average loss: 0.0404, Accuracy: 24956/25195 (99%)\n",
      "\n",
      "Train Epoch: 13 [6400/100778 (6%)]\tLoss: 0.052665\tSteps: 3800200\n",
      "Train Epoch: 13 [12800/100778 (13%)]\tLoss: 0.059285\tSteps: 3820200\n",
      "Train Epoch: 13 [19200/100778 (19%)]\tLoss: 0.060879\tSteps: 3840200\n",
      "Train Epoch: 13 [25600/100778 (25%)]\tLoss: 0.063013\tSteps: 3860200\n",
      "Train Epoch: 13 [32000/100778 (32%)]\tLoss: 0.055073\tSteps: 3880200\n",
      "Train Epoch: 13 [38400/100778 (38%)]\tLoss: 0.062743\tSteps: 3900200\n",
      "Train Epoch: 13 [44800/100778 (44%)]\tLoss: 0.059831\tSteps: 3920200\n",
      "Train Epoch: 13 [51200/100778 (51%)]\tLoss: 0.059415\tSteps: 3940200\n",
      "Train Epoch: 13 [57600/100778 (57%)]\tLoss: 0.056820\tSteps: 3960200\n",
      "Train Epoch: 13 [64000/100778 (63%)]\tLoss: 0.060737\tSteps: 3980200\n",
      "Train Epoch: 13 [70400/100778 (70%)]\tLoss: 0.069067\tSteps: 4000200\n",
      "Train Epoch: 13 [76800/100778 (76%)]\tLoss: 0.060755\tSteps: 4020200\n",
      "Train Epoch: 13 [83200/100778 (83%)]\tLoss: 0.065310\tSteps: 4040200\n",
      "Train Epoch: 13 [89600/100778 (89%)]\tLoss: 0.057237\tSteps: 4060200\n",
      "Train Epoch: 13 [96000/100778 (95%)]\tLoss: 0.064257\tSteps: 4080200\n",
      "\n",
      "Test set: Average loss: 0.0401, Accuracy: 24954/25195 (99%)\n",
      "\n",
      "Train Epoch: 14 [6400/100778 (6%)]\tLoss: 0.057215\tSteps: 4115200\n",
      "Train Epoch: 14 [12800/100778 (13%)]\tLoss: 0.061078\tSteps: 4135200\n",
      "Train Epoch: 14 [19200/100778 (19%)]\tLoss: 0.068686\tSteps: 4155200\n",
      "Train Epoch: 14 [25600/100778 (25%)]\tLoss: 0.058787\tSteps: 4175200\n",
      "Train Epoch: 14 [32000/100778 (32%)]\tLoss: 0.056224\tSteps: 4195200\n",
      "Train Epoch: 14 [38400/100778 (38%)]\tLoss: 0.057157\tSteps: 4215200\n",
      "Train Epoch: 14 [44800/100778 (44%)]\tLoss: 0.059192\tSteps: 4235200\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-f30cd6ac13df>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"__main__\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m         \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m         \u001b[0mtest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m10\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-8-a2dae5835c37>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(ep)\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# negative log likelihood\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[1;31m#loss = loss1(output, target)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[0mtrain_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive\\Documents\\virtualenvs\\netsec\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[1;32m--> 221\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    222\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    223\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive\\Documents\\virtualenvs\\netsec\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m    130\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 132\u001b[1;33m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m    133\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    for epoch in range(1, epochs+1):\n",
    "        train(epoch)\n",
    "        test()\n",
    "        if epoch % 10 == 0:\n",
    "            lr /= 10\n",
    "            for param_group in optimizer.param_groups:\n",
    "                param_group['lr'] = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "def get_metrics(dataLoader):\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    precision = 0\n",
    "    recall = 0\n",
    "    f1_score = 0\n",
    "    accuracy = 0\n",
    "    precisionList = []\n",
    "    recallList = []\n",
    "    f1_scoreList = []\n",
    "    accuracyList = []\n",
    "    with torch.no_grad():\n",
    "        for data, target in dataLoader: # just 1 batch\n",
    "            model.eval()\n",
    "            data = data.type(torch.FloatTensor)\n",
    "            target = target.type(torch.LongTensor)\n",
    "            output = model(data)\n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "            #print(predicted)\n",
    "            total+=target.size(0)\n",
    "            correct+=(predicted == target).sum().item()\n",
    "            report = classification_report(target, predicted, output_dict=True)\n",
    "            precision += report['macro avg']['precision']\n",
    "            precisionList.append(report['macro avg']['precision'])\n",
    "            recall += report['macro avg']['recall']\n",
    "            recallList.append(report['macro avg']['recall'])\n",
    "            f1_score += report['macro avg']['f1-score']\n",
    "            f1_scoreList.append(report['macro avg']['f1-score'])\n",
    "            accuracy += report['accuracy']\n",
    "            accuracyList.append(report['accuracy'])\n",
    "            #print(report)\n",
    "    #print(\"Precision: {}, Recall: {}, F1-Score: {}, Accuracy: {}, AccuracyCust: {}\".format(precision/total, recall/total, f1_score/total, accuracy/total, correct/total))\n",
    "    return precisionList, recallList, f1_scoreList, accuracyList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lromo\\OneDrive\\Documents\\virtualenvs\\netsec\\lib\\site-packages\\ipykernel_launcher.py:16: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0000, Accuracy: 18349/22544 (81%)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fileNameVal = 'Ds.csv'\n",
    "datasetVal = NSLKDDDataset(fileNameVal)\n",
    "params = {'batch_size': 22544, 'shuffle': True}\n",
    "dataGeneratorVal = DataLoader(datasetVal, **params)\n",
    "#RuntimeError: expected scalar type Int but found Float\n",
    "#get_metrics(dataGeneratorVal)\n",
    "def val():\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in dataGeneratorTest:\n",
    "            model.eval()\n",
    "            #data = data.view(-1, input_channels, seq_length)\n",
    "            data = data.type(torch.FloatTensor)\n",
    "            target = target.type(torch.LongTensor)\n",
    "            data, target = Variable(data, volatile=True), Variable(target)\n",
    "            output = model(data)\n",
    "            #loss1 = torch.nn.CrossEntropyLoss()\n",
    "            #test_loss += F.nll_loss(output, target, size_average=False).item()\n",
    "            #test_loss += loss1(output, target).item()\n",
    "            #print(output.data.max(1, keepdim=True)[1])\n",
    "            pred = output.data.max(1, keepdim=True)[1]\n",
    "            #print(pred)\n",
    "            correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "\n",
    "        test_loss /= len(dataGeneratorTest.dataset)\n",
    "        print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "            test_loss, correct, len(dataGeneratorVal.dataset),\n",
    "            100. * correct / len(dataGeneratorVal.dataset)))\n",
    "        return test_loss\n",
    "\n",
    "val()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([1.0,\n",
       "  0.9880952380952381,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.986842105263158,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9848484848484849,\n",
       "  0.9833333333333334,\n",
       "  0.9687194525904204,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.986842105263158,\n",
       "  1.0,\n",
       "  0.967741935483871,\n",
       "  0.9722222222222222,\n",
       "  0.9861111111111112,\n",
       "  0.9848484848484849,\n",
       "  1.0,\n",
       "  0.98,\n",
       "  0.9676113360323887,\n",
       "  0.9827586206896552,\n",
       "  1.0,\n",
       "  0.9857142857142858,\n",
       "  1.0,\n",
       "  0.9838709677419355,\n",
       "  0.9543589743589743,\n",
       "  1.0,\n",
       "  0.9827586206896552,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9875,\n",
       "  0.9857142857142858,\n",
       "  0.9655172413793103,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9807692307692308,\n",
       "  0.9833333333333334,\n",
       "  0.9642857142857143,\n",
       "  1.0,\n",
       "  0.9671794871794872,\n",
       "  0.9864864864864865,\n",
       "  0.9848484848484849,\n",
       "  0.9696969696969697,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9687194525904204,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9848484848484849,\n",
       "  0.9848484848484849,\n",
       "  1.0,\n",
       "  0.9827586206896552,\n",
       "  0.9782608695652174,\n",
       "  1.0,\n",
       "  0.9714285714285714,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9848484848484849,\n",
       "  0.9687194525904204,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9861111111111112,\n",
       "  0.9848484848484849,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  0.9852941176470589,\n",
       "  1.0,\n",
       "  0.9861111111111112,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9861111111111112,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9864864864864865,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  0.9871794871794872,\n",
       "  1.0,\n",
       "  0.9852941176470589,\n",
       "  0.9814814814814814,\n",
       "  1.0,\n",
       "  0.9833333333333334,\n",
       "  0.9852941176470589,\n",
       "  0.9852941176470589,\n",
       "  1.0,\n",
       "  0.95,\n",
       "  0.98,\n",
       "  1.0,\n",
       "  0.9857142857142858,\n",
       "  1.0,\n",
       "  0.9827586206896552,\n",
       "  1.0,\n",
       "  0.9686274509803922,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.967967967967968,\n",
       "  1.0,\n",
       "  0.9807692307692308,\n",
       "  1.0,\n",
       "  0.9404761904761905,\n",
       "  0.9642857142857143,\n",
       "  0.9814814814814814,\n",
       "  1.0,\n",
       "  0.9857142857142858,\n",
       "  0.9861111111111112,\n",
       "  0.9655172413793103,\n",
       "  1.0,\n",
       "  0.9871794871794872,\n",
       "  0.9655172413793103,\n",
       "  0.9659090909090908,\n",
       "  1.0,\n",
       "  0.9880952380952381,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9833333333333334,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9676113360323887,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9861111111111112,\n",
       "  0.9852941176470589,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  0.986842105263158,\n",
       "  0.9880952380952381,\n",
       "  0.9655172413793103,\n",
       "  0.9538706256627784,\n",
       "  0.9875,\n",
       "  0.9848484848484849,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.967741935483871,\n",
       "  0.9838709677419355,\n",
       "  1.0,\n",
       "  0.9838709677419355,\n",
       "  1.0,\n",
       "  0.9821428571428572,\n",
       "  0.9833333333333334,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.986842105263158,\n",
       "  0.9705882352941176,\n",
       "  1.0,\n",
       "  0.9848484848484849,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9814814814814814,\n",
       "  0.962962962962963,\n",
       "  0.9541666666666666,\n",
       "  1.0,\n",
       "  0.9676113360323887,\n",
       "  0.9821428571428572,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.984375,\n",
       "  0.9852941176470589,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.98,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9544544544544544,\n",
       "  0.9838709677419355,\n",
       "  1.0,\n",
       "  0.9852941176470589,\n",
       "  1.0,\n",
       "  0.986842105263158,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9852941176470589,\n",
       "  1.0,\n",
       "  0.9838709677419355,\n",
       "  0.9833333333333334,\n",
       "  1.0,\n",
       "  0.953125,\n",
       "  0.9814814814814814,\n",
       "  0.986842105263158,\n",
       "  1.0,\n",
       "  0.9791666666666667,\n",
       "  0.984375,\n",
       "  0.9848484848484849,\n",
       "  1.0,\n",
       "  0.962962962962963,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9705882352941176,\n",
       "  0.9682539682539683,\n",
       "  0.9705882352941176,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9807692307692308,\n",
       "  0.9864864864864865,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9852941176470589,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9857142857142858,\n",
       "  0.9861111111111112,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.986842105263158,\n",
       "  0.96875,\n",
       "  0.9722222222222222,\n",
       "  1.0,\n",
       "  0.9583333333333333,\n",
       "  0.9864864864864865,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9671794871794872,\n",
       "  1.0,\n",
       "  0.9682539682539683,\n",
       "  0.9705882352941176,\n",
       "  0.984375,\n",
       "  0.9696969696969697,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9833333333333334,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.953125,\n",
       "  0.9857142857142858,\n",
       "  0.9375,\n",
       "  1.0,\n",
       "  0.9615384615384616,\n",
       "  0.9714285714285714,\n",
       "  0.986842105263158,\n",
       "  0.9791666666666667,\n",
       "  0.9875,\n",
       "  1.0,\n",
       "  0.9821428571428572,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.986842105263158,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9852941176470589,\n",
       "  0.9821428571428572,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9682539682539683,\n",
       "  1.0,\n",
       "  0.98,\n",
       "  0.9857142857142858,\n",
       "  0.9687194525904204,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9878048780487805,\n",
       "  0.9696969696969697,\n",
       "  1.0,\n",
       "  0.9676113360323887,\n",
       "  0.984375,\n",
       "  0.9684729064039409,\n",
       "  0.9736842105263157,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9852941176470589,\n",
       "  0.9864864864864865,\n",
       "  0.986842105263158,\n",
       "  0.9871794871794872,\n",
       "  1.0,\n",
       "  0.9814814814814814,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9857142857142858,\n",
       "  0.9539215686274509,\n",
       "  0.9883720930232558,\n",
       "  0.9875,\n",
       "  0.9848484848484849,\n",
       "  0.9838709677419355,\n",
       "  0.9878048780487805,\n",
       "  0.9838709677419355,\n",
       "  1.0,\n",
       "  0.9814814814814814,\n",
       "  1.0,\n",
       "  0.9878048780487805,\n",
       "  1.0,\n",
       "  0.9852941176470589,\n",
       "  0.9736842105263157,\n",
       "  0.98,\n",
       "  0.9821428571428572,\n",
       "  0.9875,\n",
       "  0.986842105263158,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.98,\n",
       "  1.0,\n",
       "  0.9736842105263157,\n",
       "  0.984375,\n",
       "  0.9875,\n",
       "  0.9861111111111112,\n",
       "  0.9827586206896552,\n",
       "  1.0,\n",
       "  0.9833333333333334,\n",
       "  1.0,\n",
       "  0.9743589743589743,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9833333333333334,\n",
       "  0.986842105263158,\n",
       "  1.0,\n",
       "  0.9791666666666667,\n",
       "  1.0,\n",
       "  0.96875,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9696969696969697,\n",
       "  1.0,\n",
       "  0.9875,\n",
       "  1.0,\n",
       "  0.9833333333333334,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9653679653679654,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9833333333333334,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9666666666666667,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9444444444444444,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9864864864864865,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9743589743589743,\n",
       "  0.9687194525904204,\n",
       "  0.9807692307692308,\n",
       "  0.9852941176470589,\n",
       "  0.9852941176470589,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9833333333333334,\n",
       "  0.9833333333333334,\n",
       "  0.9821428571428572,\n",
       "  0.9535679374389052,\n",
       "  0.9782608695652174,\n",
       "  0.9848484848484849,\n",
       "  0.9852941176470589,\n",
       "  0.986842105263158,\n",
       "  0.9684729064039409,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9857142857142858,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9687194525904204,\n",
       "  0.975,\n",
       "  0.98,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9827586206896552,\n",
       "  1.0,\n",
       "  0.967967967967968,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9544534412955465,\n",
       "  0.9687194525904204,\n",
       "  1.0,\n",
       "  0.9833333333333334,\n",
       "  0.9821428571428572,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9705882352941176,\n",
       "  1.0,\n",
       "  0.9864864864864865,\n",
       "  0.9615384615384616,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.986842105263158,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  0.9848484848484849,\n",
       "  0.9821428571428572,\n",
       "  0.9821428571428572,\n",
       "  0.98,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9696969696969697,\n",
       "  0.9494494494494494,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.98,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9535679374389052,\n",
       "  0.9605263157894737,\n",
       "  0.9807692307692308,\n",
       "  0.9671794871794872,\n",
       "  1.0,\n",
       "  0.986842105263158,\n",
       "  1.0,\n",
       "  0.9857142857142858,\n",
       "  1.0,\n",
       "  0.9852941176470589,\n",
       "  0.984375,\n",
       "  0.9615384615384616,\n",
       "  0.986842105263158,\n",
       "  1.0,\n",
       "  0.9807692307692308,\n",
       "  1.0,\n",
       "  0.9875,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9864864864864865,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9687194525904204,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9615384615384616,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9833333333333334,\n",
       "  0.9848484848484849,\n",
       "  0.9852941176470589,\n",
       "  1.0,\n",
       "  0.9821428571428572,\n",
       "  0.9857142857142858,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9827586206896552,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9782608695652174,\n",
       "  0.9399014778325123,\n",
       "  1.0,\n",
       "  0.9535679374389052,\n",
       "  0.9848484848484849,\n",
       "  1.0,\n",
       "  0.9583333333333333,\n",
       "  0.9875,\n",
       "  0.9666666666666667,\n",
       "  0.9886363636363636,\n",
       "  0.984375,\n",
       "  0.9821428571428572,\n",
       "  1.0,\n",
       "  0.9571428571428571,\n",
       "  0.9687194525904204,\n",
       "  1.0,\n",
       "  0.9743589743589743,\n",
       "  1.0,\n",
       "  0.9676113360323887,\n",
       "  1.0,\n",
       "  0.9782608695652174,\n",
       "  0.9682539682539683,\n",
       "  1.0,\n",
       "  0.9807692307692308,\n",
       "  0.9833333333333334,\n",
       "  0.9848484848484849,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9838709677419355,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9821428571428572,\n",
       "  1.0,\n",
       "  0.96875,\n",
       "  0.9777777777777779,\n",
       "  0.9864864864864865,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.967967967967968,\n",
       "  1.0,\n",
       "  0.9861111111111112,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.96875,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9883720930232558,\n",
       "  0.9848484848484849,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9821428571428572,\n",
       "  0.9852941176470589,\n",
       "  0.9583333333333333,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  0.9871794871794872,\n",
       "  1.0,\n",
       "  0.9687194525904204,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9838709677419355,\n",
       "  1.0,\n",
       "  0.9821428571428572,\n",
       "  1.0,\n",
       "  0.9848484848484849,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9852941176470589,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9827586206896552,\n",
       "  0.9682539682539683,\n",
       "  1.0,\n",
       "  0.9861111111111112,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9848484848484849,\n",
       "  0.9642857142857143,\n",
       "  1.0,\n",
       "  0.9782608695652174,\n",
       "  0.9864864864864865,\n",
       "  0.9827586206896552,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9833333333333334,\n",
       "  0.9861111111111112,\n",
       "  1.0,\n",
       "  0.9821428571428572,\n",
       "  0.9814814814814814,\n",
       "  0.9736842105263157,\n",
       "  1.0,\n",
       "  0.9807692307692308,\n",
       "  0.9814814814814814,\n",
       "  0.9827586206896552,\n",
       "  1.0,\n",
       "  0.96875,\n",
       "  0.9676113360323887,\n",
       "  1.0,\n",
       "  0.9891304347826086,\n",
       "  1.0,\n",
       "  0.9705882352941176,\n",
       "  0.9821428571428572,\n",
       "  0.9821428571428572,\n",
       "  1.0,\n",
       "  0.96875,\n",
       "  0.9666666666666667,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9838709677419355,\n",
       "  1.0,\n",
       "  0.9374389051808407,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9852941176470589,\n",
       "  0.951231527093596,\n",
       "  0.9687194525904204,\n",
       "  1.0,\n",
       "  0.98,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9848484848484849,\n",
       "  1.0,\n",
       "  0.9871794871794872,\n",
       "  0.9864864864864865,\n",
       "  0.984375,\n",
       "  0.9833333333333334,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9814814814814814,\n",
       "  1.0,\n",
       "  0.9827586206896552,\n",
       "  1.0,\n",
       "  0.9857142857142858,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9543650793650793,\n",
       "  1.0,\n",
       "  0.9848484848484849,\n",
       "  0.9671794871794872,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9684729064039409,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9736842105263157,\n",
       "  0.9543650793650793,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9838709677419355,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9687194525904204,\n",
       "  0.9857142857142858,\n",
       "  0.9852941176470589,\n",
       "  0.9833333333333334,\n",
       "  1.0,\n",
       "  0.9516129032258065,\n",
       "  1.0,\n",
       "  0.98,\n",
       "  0.984375,\n",
       "  0.9861111111111112,\n",
       "  1.0,\n",
       "  0.9838709677419355,\n",
       "  1.0,\n",
       "  0.9583333333333333,\n",
       "  0.9861111111111112,\n",
       "  0.9821428571428572,\n",
       "  0.9682539682539683,\n",
       "  0.9365079365079365,\n",
       "  1.0,\n",
       "  0.9833333333333334,\n",
       "  1.0,\n",
       "  0.9838709677419355,\n",
       "  0.9705882352941176,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9875,\n",
       "  0.9653679653679654,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9838709677419355,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9857142857142858,\n",
       "  0.9535679374389052,\n",
       "  0.9838709677419355,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9687194525904204,\n",
       "  1.0,\n",
       "  0.9309309309309309,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.967967967967968,\n",
       "  0.9852941176470589,\n",
       "  0.9838709677419355,\n",
       "  1.0,\n",
       "  0.9871794871794872,\n",
       "  1.0,\n",
       "  0.9827586206896552,\n",
       "  0.9827586206896552,\n",
       "  1.0,\n",
       "  0.9682539682539683,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9625,\n",
       "  1.0,\n",
       "  0.9696969696969697,\n",
       "  0.9666666666666667,\n",
       "  1.0,\n",
       "  0.9861111111111112,\n",
       "  1.0,\n",
       "  0.98,\n",
       "  0.9833333333333334,\n",
       "  0.9857142857142858,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9883720930232558,\n",
       "  1.0,\n",
       "  0.967741935483871,\n",
       "  0.9687194525904204,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.98,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9642857142857143,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9687194525904204,\n",
       "  0.9838709677419355,\n",
       "  0.9864864864864865,\n",
       "  1.0,\n",
       "  0.984375,\n",
       "  0.9861111111111112,\n",
       "  0.9814814814814814,\n",
       "  1.0,\n",
       "  0.9583333333333333,\n",
       "  0.9861111111111112,\n",
       "  0.9861111111111112,\n",
       "  0.9857142857142858,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9875,\n",
       "  0.9861111111111112,\n",
       "  1.0,\n",
       "  0.9827586206896552,\n",
       "  0.9696969696969697,\n",
       "  0.9857142857142858,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9827586206896552,\n",
       "  0.9686274509803922,\n",
       "  0.9666666666666667,\n",
       "  1.0,\n",
       "  0.9833333333333334,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9666666666666667,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9852941176470589,\n",
       "  1.0,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  0.9767441860465116,\n",
       "  0.9807692307692308,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9541871921182266,\n",
       "  1.0,\n",
       "  0.967741935483871,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9687194525904204,\n",
       "  0.9605263157894737,\n",
       "  0.9864864864864865,\n",
       "  0.9861111111111112,\n",
       "  1.0,\n",
       "  0.9782608695652174,\n",
       "  0.986842105263158,\n",
       "  0.9891304347826086,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9543650793650793,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9857142857142858,\n",
       "  0.98,\n",
       "  1.0,\n",
       "  0.9722222222222222,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.986842105263158,\n",
       "  1.0,\n",
       "  0.9682539682539683,\n",
       "  0.9852941176470589,\n",
       "  0.9821428571428572,\n",
       "  1.0,\n",
       "  0.9666666666666667,\n",
       "  1.0,\n",
       "  0.953125,\n",
       "  1.0,\n",
       "  0.9864864864864865,\n",
       "  1.0,\n",
       "  0.9687194525904204,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9861111111111112,\n",
       "  0.9722222222222222,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9833333333333334,\n",
       "  1.0,\n",
       "  0.9722222222222222,\n",
       "  0.9736842105263157,\n",
       "  0.9857142857142858,\n",
       "  0.9687194525904204,\n",
       "  1.0,\n",
       "  0.9372549019607843,\n",
       "  0.9696969696969697,\n",
       "  0.9814814814814814,\n",
       "  0.9807692307692308,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.96875,\n",
       "  0.9871794871794872,\n",
       "  1.0,\n",
       "  0.975,\n",
       "  0.9875,\n",
       "  0.9821428571428572,\n",
       "  0.984375,\n",
       "  0.9838709677419355,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9539215686274509,\n",
       "  0.9782608695652174,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9807692307692308,\n",
       "  0.9852941176470589,\n",
       "  1.0,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9687194525904204,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9686274509803922,\n",
       "  0.9848484848484849,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9848484848484849,\n",
       "  0.9827586206896552,\n",
       "  1.0,\n",
       "  0.9615384615384616,\n",
       "  1.0,\n",
       "  0.9833333333333334,\n",
       "  0.984375,\n",
       "  0.9544534412955465,\n",
       "  0.9848484848484849,\n",
       "  1.0,\n",
       "  0.986842105263158,\n",
       "  1.0,\n",
       "  0.9736842105263157,\n",
       "  0.9838709677419355,\n",
       "  0.9767441860465116,\n",
       "  0.9671794871794872,\n",
       "  1.0,\n",
       "  0.9655172413793103,\n",
       "  0.9684729064039409,\n",
       "  1.0,\n",
       "  0.9852941176470589,\n",
       "  0.9852941176470589,\n",
       "  1.0,\n",
       "  0.9852941176470589,\n",
       "  0.9807692307692308,\n",
       "  0.9864864864864865,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.967967967967968,\n",
       "  0.9615384615384616,\n",
       "  0.9827586206896552,\n",
       "  1.0,\n",
       "  0.9541666666666666,\n",
       "  0.9821428571428572,\n",
       "  0.9852941176470589,\n",
       "  0.9807692307692308,\n",
       "  1.0,\n",
       "  0.9848484848484849,\n",
       "  0.9807692307692308,\n",
       "  0.9827586206896552,\n",
       "  0.9852941176470589,\n",
       "  1.0,\n",
       "  0.9827586206896552,\n",
       "  1.0,\n",
       "  0.9687194525904204,\n",
       "  0.9857142857142858,\n",
       "  1.0,\n",
       "  0.972972972972973,\n",
       "  0.9494494494494494,\n",
       "  0.9861111111111112,\n",
       "  0.9705882352941176,\n",
       "  0.9761904761904762,\n",
       "  0.9838709677419355,\n",
       "  0.9714285714285714,\n",
       "  0.9666666666666667,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9838709677419355,\n",
       "  1.0,\n",
       "  0.9852941176470589,\n",
       "  0.9814814814814814,\n",
       "  0.9871794871794872,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9671794871794872,\n",
       "  0.9864864864864865,\n",
       "  0.9880952380952381,\n",
       "  1.0,\n",
       "  0.9743589743589743,\n",
       "  0.9535679374389052,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9852941176470589,\n",
       "  1.0,\n",
       "  0.986842105263158,\n",
       "  0.9857142857142858,\n",
       "  0.986842105263158,\n",
       "  0.9848484848484849,\n",
       "  0.9878048780487805,\n",
       "  0.9848484848484849,\n",
       "  0.9852941176470589,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.984375,\n",
       "  0.9861111111111112,\n",
       "  1.0,\n",
       "  0.9821428571428572,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9671794871794872,\n",
       "  0.9857142857142858,\n",
       "  0.9714285714285714,\n",
       "  0.986842105263158,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  ...],\n",
       " [1.0,\n",
       "  0.9782608695652174,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9814814814814814,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.984375,\n",
       "  0.9857142857142858,\n",
       "  0.9687194525904204,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9814814814814814,\n",
       "  1.0,\n",
       "  0.9714285714285714,\n",
       "  0.9666666666666667,\n",
       "  0.9827586206896552,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  0.9875,\n",
       "  0.9676113360323887,\n",
       "  0.9861111111111112,\n",
       "  1.0,\n",
       "  0.9833333333333334,\n",
       "  1.0,\n",
       "  0.9852941176470589,\n",
       "  0.9483805668016194,\n",
       "  1.0,\n",
       "  0.9861111111111112,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.98,\n",
       "  0.9833333333333334,\n",
       "  0.972972972972973,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9871794871794872,\n",
       "  0.9857142857142858,\n",
       "  0.9736842105263157,\n",
       "  1.0,\n",
       "  0.9671794871794872,\n",
       "  0.9821428571428572,\n",
       "  0.984375,\n",
       "  0.9696969696969697,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9687194525904204,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.984375,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  0.9861111111111112,\n",
       "  0.9880952380952381,\n",
       "  1.0,\n",
       "  0.967741935483871,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.984375,\n",
       "  0.9687194525904204,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9827586206896552,\n",
       "  0.984375,\n",
       "  0.9848484848484849,\n",
       "  1.0,\n",
       "  0.9838709677419355,\n",
       "  1.0,\n",
       "  0.9827586206896552,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9827586206896552,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9821428571428572,\n",
       "  0.9848484848484849,\n",
       "  1.0,\n",
       "  0.9807692307692308,\n",
       "  1.0,\n",
       "  0.9838709677419355,\n",
       "  0.986842105263158,\n",
       "  1.0,\n",
       "  0.9857142857142858,\n",
       "  0.9838709677419355,\n",
       "  0.9838709677419355,\n",
       "  1.0,\n",
       "  0.9594594594594594,\n",
       "  0.9875,\n",
       "  1.0,\n",
       "  0.9833333333333334,\n",
       "  1.0,\n",
       "  0.9861111111111112,\n",
       "  1.0,\n",
       "  0.9686274509803922,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.967967967967968,\n",
       "  1.0,\n",
       "  0.9871794871794872,\n",
       "  1.0,\n",
       "  0.9352941176470588,\n",
       "  0.9736842105263157,\n",
       "  0.986842105263158,\n",
       "  1.0,\n",
       "  0.9833333333333334,\n",
       "  0.9827586206896552,\n",
       "  0.972972972972973,\n",
       "  1.0,\n",
       "  0.9807692307692308,\n",
       "  0.972972972972973,\n",
       "  0.9347826086956521,\n",
       "  1.0,\n",
       "  0.9782608695652174,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9857142857142858,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9676113360323887,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9827586206896552,\n",
       "  0.9838709677419355,\n",
       "  0.9848484848484849,\n",
       "  1.0,\n",
       "  0.9814814814814814,\n",
       "  0.9782608695652174,\n",
       "  0.972972972972973,\n",
       "  0.9458333333333333,\n",
       "  0.98,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9714285714285714,\n",
       "  0.9852941176470589,\n",
       "  1.0,\n",
       "  0.9852941176470589,\n",
       "  1.0,\n",
       "  0.9864864864864865,\n",
       "  0.9857142857142858,\n",
       "  0.9848484848484849,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9814814814814814,\n",
       "  0.96875,\n",
       "  1.0,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.986842105263158,\n",
       "  0.9743589743589743,\n",
       "  0.9471794871794872,\n",
       "  1.0,\n",
       "  0.9676113360323887,\n",
       "  0.9864864864864865,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9848484848484849,\n",
       "  0.9838709677419355,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9875,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9503968253968254,\n",
       "  0.9852941176470589,\n",
       "  1.0,\n",
       "  0.9838709677419355,\n",
       "  1.0,\n",
       "  0.9814814814814814,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9838709677419355,\n",
       "  1.0,\n",
       "  0.9852941176470589,\n",
       "  0.9857142857142858,\n",
       "  1.0,\n",
       "  0.9535679374389052,\n",
       "  0.986842105263158,\n",
       "  0.9814814814814814,\n",
       "  1.0,\n",
       "  0.9878048780487805,\n",
       "  0.9848484848484849,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  0.9743589743589743,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.96875,\n",
       "  0.9682539682539683,\n",
       "  0.96875,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9871794871794872,\n",
       "  0.9821428571428572,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9838709677419355,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9833333333333334,\n",
       "  0.9827586206896552,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9814814814814814,\n",
       "  0.9705882352941176,\n",
       "  0.9666666666666667,\n",
       "  1.0,\n",
       "  0.9761904761904762,\n",
       "  0.9821428571428572,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9671794871794872,\n",
       "  1.0,\n",
       "  0.9682539682539683,\n",
       "  0.96875,\n",
       "  0.9848484848484849,\n",
       "  0.9696969696969697,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9857142857142858,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9535679374389052,\n",
       "  0.9833333333333334,\n",
       "  0.9444444444444444,\n",
       "  1.0,\n",
       "  0.975,\n",
       "  0.967741935483871,\n",
       "  0.9814814814814814,\n",
       "  0.9878048780487805,\n",
       "  0.98,\n",
       "  1.0,\n",
       "  0.9864864864864865,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9814814814814814,\n",
       "  0.9848484848484849,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9838709677419355,\n",
       "  0.9864864864864865,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9682539682539683,\n",
       "  1.0,\n",
       "  0.9875,\n",
       "  0.9833333333333334,\n",
       "  0.9687194525904204,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9791666666666667,\n",
       "  0.9696969696969697,\n",
       "  1.0,\n",
       "  0.9676113360323887,\n",
       "  0.9848484848484849,\n",
       "  0.9684729064039409,\n",
       "  0.9642857142857143,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9838709677419355,\n",
       "  0.9821428571428572,\n",
       "  0.9814814814814814,\n",
       "  0.9807692307692308,\n",
       "  1.0,\n",
       "  0.986842105263158,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9833333333333334,\n",
       "  0.9525904203323559,\n",
       "  0.9772727272727273,\n",
       "  0.98,\n",
       "  0.984375,\n",
       "  0.9852941176470589,\n",
       "  0.9791666666666667,\n",
       "  0.9852941176470589,\n",
       "  1.0,\n",
       "  0.986842105263158,\n",
       "  1.0,\n",
       "  0.9791666666666667,\n",
       "  1.0,\n",
       "  0.9838709677419355,\n",
       "  0.9642857142857143,\n",
       "  0.9875,\n",
       "  0.9864864864864865,\n",
       "  0.98,\n",
       "  0.9814814814814814,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9875,\n",
       "  1.0,\n",
       "  0.9642857142857143,\n",
       "  0.9848484848484849,\n",
       "  0.98,\n",
       "  0.9827586206896552,\n",
       "  0.9861111111111112,\n",
       "  1.0,\n",
       "  0.9857142857142858,\n",
       "  1.0,\n",
       "  0.962962962962963,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9857142857142858,\n",
       "  0.9814814814814814,\n",
       "  1.0,\n",
       "  0.9878048780487805,\n",
       "  1.0,\n",
       "  0.96875,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9696969696969697,\n",
       "  1.0,\n",
       "  0.98,\n",
       "  1.0,\n",
       "  0.9857142857142858,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9653679653679654,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9857142857142858,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9722222222222222,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9625,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9848484848484849,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9821428571428572,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.962962962962963,\n",
       "  0.9687194525904204,\n",
       "  0.9871794871794872,\n",
       "  0.9838709677419355,\n",
       "  0.9838709677419355,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9857142857142858,\n",
       "  0.9857142857142858,\n",
       "  0.9864864864864865,\n",
       "  0.953125,\n",
       "  0.9880952380952381,\n",
       "  0.984375,\n",
       "  0.9838709677419355,\n",
       "  0.9814814814814814,\n",
       "  0.9684729064039409,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9833333333333334,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9687194525904204,\n",
       "  0.9615384615384616,\n",
       "  0.9875,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9861111111111112,\n",
       "  1.0,\n",
       "  0.967967967967968,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9494494494494494,\n",
       "  0.9687194525904204,\n",
       "  1.0,\n",
       "  0.9857142857142858,\n",
       "  0.9864864864864865,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.96875,\n",
       "  1.0,\n",
       "  0.9821428571428572,\n",
       "  0.975,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9814814814814814,\n",
       "  0.9848484848484849,\n",
       "  1.0,\n",
       "  0.984375,\n",
       "  0.9864864864864865,\n",
       "  0.9864864864864865,\n",
       "  0.9875,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9696969696969697,\n",
       "  0.9544534412955465,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9875,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.953125,\n",
       "  0.9482758620689655,\n",
       "  0.9871794871794872,\n",
       "  0.9671794871794872,\n",
       "  1.0,\n",
       "  0.9814814814814814,\n",
       "  1.0,\n",
       "  0.9833333333333334,\n",
       "  1.0,\n",
       "  0.9838709677419355,\n",
       "  0.9848484848484849,\n",
       "  0.9464285714285714,\n",
       "  0.9814814814814814,\n",
       "  1.0,\n",
       "  0.9871794871794872,\n",
       "  1.0,\n",
       "  0.98,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9821428571428572,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9687194525904204,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.975,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9857142857142858,\n",
       "  0.984375,\n",
       "  0.9838709677419355,\n",
       "  1.0,\n",
       "  0.9864864864864865,\n",
       "  0.9833333333333334,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9861111111111112,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9880952380952381,\n",
       "  0.9364613880742914,\n",
       "  1.0,\n",
       "  0.953125,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  0.9761904761904762,\n",
       "  0.98,\n",
       "  0.9666666666666667,\n",
       "  0.9761904761904762,\n",
       "  0.9848484848484849,\n",
       "  0.9864864864864865,\n",
       "  1.0,\n",
       "  0.953125,\n",
       "  0.9687194525904204,\n",
       "  1.0,\n",
       "  0.962962962962963,\n",
       "  1.0,\n",
       "  0.9676113360323887,\n",
       "  1.0,\n",
       "  0.9880952380952381,\n",
       "  0.9682539682539683,\n",
       "  1.0,\n",
       "  0.9871794871794872,\n",
       "  0.9857142857142858,\n",
       "  0.984375,\n",
       "  0.9848484848484849,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9852941176470589,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9864864864864865,\n",
       "  1.0,\n",
       "  0.96875,\n",
       "  0.9523809523809523,\n",
       "  0.9821428571428572,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.967967967967968,\n",
       "  1.0,\n",
       "  0.9827586206896552,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9705882352941176,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9772727272727273,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9864864864864865,\n",
       "  0.9838709677419355,\n",
       "  0.9516129032258065,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9848484848484849,\n",
       "  1.0,\n",
       "  0.9807692307692308,\n",
       "  1.0,\n",
       "  0.9687194525904204,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9852941176470589,\n",
       "  1.0,\n",
       "  0.9864864864864865,\n",
       "  1.0,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9838709677419355,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9861111111111112,\n",
       "  0.9682539682539683,\n",
       "  1.0,\n",
       "  0.9827586206896552,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.984375,\n",
       "  0.9736842105263157,\n",
       "  1.0,\n",
       "  0.9880952380952381,\n",
       "  0.9821428571428572,\n",
       "  0.9861111111111112,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9857142857142858,\n",
       "  0.9827586206896552,\n",
       "  1.0,\n",
       "  0.9864864864864865,\n",
       "  0.986842105263158,\n",
       "  0.9642857142857143,\n",
       "  1.0,\n",
       "  0.9871794871794872,\n",
       "  0.986842105263158,\n",
       "  0.9861111111111112,\n",
       "  1.0,\n",
       "  0.96875,\n",
       "  0.9676113360323887,\n",
       "  1.0,\n",
       "  0.9736842105263157,\n",
       "  1.0,\n",
       "  0.96875,\n",
       "  0.9864864864864865,\n",
       "  0.9864864864864865,\n",
       "  1.0,\n",
       "  0.9705882352941176,\n",
       "  0.9666666666666667,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9848484848484849,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9852941176470589,\n",
       "  1.0,\n",
       "  0.9374389051808407,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9838709677419355,\n",
       "  0.9543650793650793,\n",
       "  0.9687194525904204,\n",
       "  1.0,\n",
       "  0.9875,\n",
       "  0.9848484848484849,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  0.9807692307692308,\n",
       "  0.9821428571428572,\n",
       "  0.9848484848484849,\n",
       "  0.9857142857142858,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.986842105263158,\n",
       "  1.0,\n",
       "  0.9861111111111112,\n",
       "  1.0,\n",
       "  0.9833333333333334,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.951231527093596,\n",
       "  1.0,\n",
       "  0.984375,\n",
       "  0.9671794871794872,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9684729064039409,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9642857142857143,\n",
       "  0.951231527093596,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9852941176470589,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9687194525904204,\n",
       "  0.9833333333333334,\n",
       "  0.9838709677419355,\n",
       "  0.9857142857142858,\n",
       "  1.0,\n",
       "  0.9583333333333333,\n",
       "  1.0,\n",
       "  0.9875,\n",
       "  0.9848484848484849,\n",
       "  0.9827586206896552,\n",
       "  1.0,\n",
       "  0.9852941176470589,\n",
       "  1.0,\n",
       "  0.9761904761904762,\n",
       "  0.9827586206896552,\n",
       "  0.9864864864864865,\n",
       "  0.9682539682539683,\n",
       "  0.9365079365079365,\n",
       "  1.0,\n",
       "  0.9857142857142858,\n",
       "  1.0,\n",
       "  0.9852941176470589,\n",
       "  0.96875,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.98,\n",
       "  0.9653679653679654,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9852941176470589,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9833333333333334,\n",
       "  0.953125,\n",
       "  0.9852941176470589,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9687194525904204,\n",
       "  1.0,\n",
       "  0.9415384615384615,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.967967967967968,\n",
       "  0.9838709677419355,\n",
       "  0.9852941176470589,\n",
       "  1.0,\n",
       "  0.9807692307692308,\n",
       "  1.0,\n",
       "  0.9861111111111112,\n",
       "  0.9861111111111112,\n",
       "  1.0,\n",
       "  0.9682539682539683,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9444444444444444,\n",
       "  1.0,\n",
       "  0.9696969696969697,\n",
       "  0.9722222222222222,\n",
       "  1.0,\n",
       "  0.9827586206896552,\n",
       "  1.0,\n",
       "  0.9875,\n",
       "  0.9857142857142858,\n",
       "  0.9833333333333334,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9772727272727273,\n",
       "  1.0,\n",
       "  0.9714285714285714,\n",
       "  0.9687194525904204,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9875,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9736842105263157,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9687194525904204,\n",
       "  0.9852941176470589,\n",
       "  0.9821428571428572,\n",
       "  1.0,\n",
       "  0.9848484848484849,\n",
       "  0.9827586206896552,\n",
       "  0.986842105263158,\n",
       "  1.0,\n",
       "  0.9516129032258065,\n",
       "  0.9827586206896552,\n",
       "  0.9827586206896552,\n",
       "  0.9833333333333334,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.98,\n",
       "  0.9827586206896552,\n",
       "  1.0,\n",
       "  0.9861111111111112,\n",
       "  0.9696969696969697,\n",
       "  0.9833333333333334,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9861111111111112,\n",
       "  0.9686274509803922,\n",
       "  0.9666666666666667,\n",
       "  1.0,\n",
       "  0.9857142857142858,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9722222222222222,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9838709677419355,\n",
       "  1.0,\n",
       "  0.9848484848484849,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9848484848484849,\n",
       "  1.0,\n",
       "  0.9565217391304348,\n",
       "  0.9871794871794872,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9519607843137254,\n",
       "  1.0,\n",
       "  0.9714285714285714,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9687194525904204,\n",
       "  0.9482758620689655,\n",
       "  0.9821428571428572,\n",
       "  0.9827586206896552,\n",
       "  1.0,\n",
       "  0.9880952380952381,\n",
       "  0.9814814814814814,\n",
       "  0.9736842105263157,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.951231527093596,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9833333333333334,\n",
       "  0.9875,\n",
       "  1.0,\n",
       "  0.9666666666666667,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9814814814814814,\n",
       "  1.0,\n",
       "  0.9682539682539683,\n",
       "  0.9838709677419355,\n",
       "  0.9864864864864865,\n",
       "  1.0,\n",
       "  0.9666666666666667,\n",
       "  1.0,\n",
       "  0.9535679374389052,\n",
       "  1.0,\n",
       "  0.9821428571428572,\n",
       "  1.0,\n",
       "  0.9687194525904204,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9827586206896552,\n",
       "  0.9666666666666667,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9857142857142858,\n",
       "  1.0,\n",
       "  0.9666666666666667,\n",
       "  0.9891304347826086,\n",
       "  0.9833333333333334,\n",
       "  0.9687194525904204,\n",
       "  1.0,\n",
       "  0.9372549019607843,\n",
       "  0.9696969696969697,\n",
       "  0.986842105263158,\n",
       "  0.9871794871794872,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9705882352941176,\n",
       "  0.9807692307692308,\n",
       "  1.0,\n",
       "  0.9615384615384616,\n",
       "  0.98,\n",
       "  0.9864864864864865,\n",
       "  0.9848484848484849,\n",
       "  0.9852941176470589,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9525904203323559,\n",
       "  0.9880952380952381,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9871794871794872,\n",
       "  0.9838709677419355,\n",
       "  1.0,\n",
       "  0.9848484848484849,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9687194525904204,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9686274509803922,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.984375,\n",
       "  0.9861111111111112,\n",
       "  1.0,\n",
       "  0.975,\n",
       "  1.0,\n",
       "  0.9857142857142858,\n",
       "  0.9848484848484849,\n",
       "  0.9494494494494494,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  0.9814814814814814,\n",
       "  1.0,\n",
       "  0.9642857142857143,\n",
       "  0.9852941176470589,\n",
       "  0.9565217391304348,\n",
       "  0.9671794871794872,\n",
       "  1.0,\n",
       "  0.972972972972973,\n",
       "  0.9684729064039409,\n",
       "  1.0,\n",
       "  0.9838709677419355,\n",
       "  0.9838709677419355,\n",
       "  1.0,\n",
       "  0.9838709677419355,\n",
       "  0.9871794871794872,\n",
       "  0.9821428571428572,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.967967967967968,\n",
       "  0.9464285714285714,\n",
       "  0.9861111111111112,\n",
       "  1.0,\n",
       "  0.9471794871794872,\n",
       "  0.9864864864864865,\n",
       "  0.9838709677419355,\n",
       "  0.9871794871794872,\n",
       "  1.0,\n",
       "  0.984375,\n",
       "  0.9871794871794872,\n",
       "  0.9861111111111112,\n",
       "  0.9838709677419355,\n",
       "  1.0,\n",
       "  0.9861111111111112,\n",
       "  1.0,\n",
       "  0.9687194525904204,\n",
       "  0.9833333333333334,\n",
       "  1.0,\n",
       "  0.9655172413793103,\n",
       "  0.9544534412955465,\n",
       "  0.9827586206896552,\n",
       "  0.96875,\n",
       "  0.9886363636363636,\n",
       "  0.9852941176470589,\n",
       "  0.967741935483871,\n",
       "  0.9722222222222222,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9852941176470589,\n",
       "  1.0,\n",
       "  0.9838709677419355,\n",
       "  0.986842105263158,\n",
       "  0.9807692307692308,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9671794871794872,\n",
       "  0.9821428571428572,\n",
       "  0.9782608695652174,\n",
       "  1.0,\n",
       "  0.962962962962963,\n",
       "  0.953125,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9838709677419355,\n",
       "  1.0,\n",
       "  0.9814814814814814,\n",
       "  0.9833333333333334,\n",
       "  0.9814814814814814,\n",
       "  0.984375,\n",
       "  0.9791666666666667,\n",
       "  0.984375,\n",
       "  0.9838709677419355,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9848484848484849,\n",
       "  0.9827586206896552,\n",
       "  1.0,\n",
       "  0.9864864864864865,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9671794871794872,\n",
       "  0.9833333333333334,\n",
       "  0.967741935483871,\n",
       "  0.9814814814814814,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9848484848484849,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  ...],\n",
       " [1.0,\n",
       "  0.9828647925033467,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9838993710691823,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9843711843711844,\n",
       "  0.9842790469172193,\n",
       "  0.9687194525904204,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9838993710691823,\n",
       "  1.0,\n",
       "  0.968627450980392,\n",
       "  0.9684729064039409,\n",
       "  0.9841858166543118,\n",
       "  0.9843711843711844,\n",
       "  1.0,\n",
       "  0.9834668044432963,\n",
       "  0.9676113360323887,\n",
       "  0.9841858166543118,\n",
       "  1.0,\n",
       "  0.9842790469172193,\n",
       "  1.0,\n",
       "  0.9843405921213604,\n",
       "  0.9511077158135982,\n",
       "  1.0,\n",
       "  0.9841858166543118,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9834668044432963,\n",
       "  0.9842790469172193,\n",
       "  0.9682539682539683,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.983702571937866,\n",
       "  0.9842790469172193,\n",
       "  0.967967967967968,\n",
       "  1.0,\n",
       "  0.9671794871794872,\n",
       "  0.9840597758405978,\n",
       "  0.9843711843711844,\n",
       "  0.96875,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9687194525904204,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9843711843711844,\n",
       "  0.9843711843711844,\n",
       "  1.0,\n",
       "  0.9841858166543118,\n",
       "  0.9828647925033467,\n",
       "  1.0,\n",
       "  0.968627450980392,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9843711843711844,\n",
       "  0.9687194525904204,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9841858166543118,\n",
       "  0.9843711843711844,\n",
       "  0.9843711843711844,\n",
       "  1.0,\n",
       "  0.9843405921213604,\n",
       "  1.0,\n",
       "  0.9841858166543118,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9841858166543118,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9840597758405978,\n",
       "  0.9843711843711844,\n",
       "  1.0,\n",
       "  0.983702571937866,\n",
       "  1.0,\n",
       "  0.9843405921213604,\n",
       "  0.9838993710691823,\n",
       "  1.0,\n",
       "  0.9842790469172193,\n",
       "  0.9843405921213604,\n",
       "  0.9843405921213604,\n",
       "  1.0,\n",
       "  0.9525574499629356,\n",
       "  0.9834668044432963,\n",
       "  1.0,\n",
       "  0.9842790469172193,\n",
       "  1.0,\n",
       "  0.9841858166543118,\n",
       "  1.0,\n",
       "  0.9686274509803922,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.967967967967968,\n",
       "  1.0,\n",
       "  0.983702571937866,\n",
       "  1.0,\n",
       "  0.9369458128078818,\n",
       "  0.967967967967968,\n",
       "  0.9838993710691823,\n",
       "  1.0,\n",
       "  0.9842790469172193,\n",
       "  0.9841858166543118,\n",
       "  0.9682539682539683,\n",
       "  1.0,\n",
       "  0.983702571937866,\n",
       "  0.9682539682539683,\n",
       "  0.947469220246238,\n",
       "  1.0,\n",
       "  0.9828647925033467,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9842790469172193,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9676113360323887,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9841858166543118,\n",
       "  0.9843405921213604,\n",
       "  0.9843711843711844,\n",
       "  1.0,\n",
       "  0.9838993710691823,\n",
       "  0.9828647925033467,\n",
       "  0.9682539682539683,\n",
       "  0.9495665878644601,\n",
       "  0.9834668044432963,\n",
       "  0.9843711843711844,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.968627450980392,\n",
       "  0.9843405921213604,\n",
       "  1.0,\n",
       "  0.9843405921213604,\n",
       "  1.0,\n",
       "  0.9840597758405978,\n",
       "  0.9842790469172193,\n",
       "  0.9843711843711844,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9838993710691823,\n",
       "  0.9687194525904204,\n",
       "  1.0,\n",
       "  0.9843711843711844,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9838993710691823,\n",
       "  0.9676113360323886,\n",
       "  0.9504004133298889,\n",
       "  1.0,\n",
       "  0.9676113360323887,\n",
       "  0.9840597758405978,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9843711843711844,\n",
       "  0.9843405921213604,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9834668044432963,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9521793275217934,\n",
       "  0.9843405921213604,\n",
       "  1.0,\n",
       "  0.9843405921213604,\n",
       "  1.0,\n",
       "  0.9838993710691823,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9843405921213604,\n",
       "  1.0,\n",
       "  0.9843405921213604,\n",
       "  0.9842790469172193,\n",
       "  1.0,\n",
       "  0.9531135531135531,\n",
       "  0.9838993710691823,\n",
       "  0.9838993710691823,\n",
       "  1.0,\n",
       "  0.9831888626214866,\n",
       "  0.9843711843711844,\n",
       "  0.9843711843711844,\n",
       "  1.0,\n",
       "  0.9676113360323886,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9687194525904204,\n",
       "  0.9682539682539683,\n",
       "  0.9687194525904204,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.983702571937866,\n",
       "  0.9840597758405978,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9843405921213604,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9842790469172193,\n",
       "  0.9841858166543118,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9838993710691823,\n",
       "  0.9687194525904204,\n",
       "  0.9684729064039409,\n",
       "  1.0,\n",
       "  0.9660657476139979,\n",
       "  0.9840597758405978,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9671794871794872,\n",
       "  1.0,\n",
       "  0.9682539682539683,\n",
       "  0.9687194525904204,\n",
       "  0.9843711843711844,\n",
       "  0.96875,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9842790469172193,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9531135531135531,\n",
       "  0.9842790469172193,\n",
       "  0.9372549019607843,\n",
       "  1.0,\n",
       "  0.9671794871794872,\n",
       "  0.968627450980392,\n",
       "  0.9838993710691823,\n",
       "  0.9831888626214866,\n",
       "  0.9834668044432963,\n",
       "  1.0,\n",
       "  0.9840597758405978,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9838993710691823,\n",
       "  0.9843711843711844,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9843405921213604,\n",
       "  0.9840597758405978,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9682539682539683,\n",
       "  1.0,\n",
       "  0.9834668044432963,\n",
       "  0.9842790469172193,\n",
       "  0.9687194525904204,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9831888626214866,\n",
       "  0.96875,\n",
       "  1.0,\n",
       "  0.9676113360323887,\n",
       "  0.9843711843711844,\n",
       "  0.9684729064039409,\n",
       "  0.967967967967968,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9843405921213604,\n",
       "  0.9840597758405978,\n",
       "  0.9838993710691823,\n",
       "  0.983702571937866,\n",
       "  1.0,\n",
       "  0.9838993710691823,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9842790469172193,\n",
       "  0.9530217763640814,\n",
       "  0.9824897400820793,\n",
       "  0.9834668044432963,\n",
       "  0.9843711843711844,\n",
       "  0.9843405921213604,\n",
       "  0.9831888626214866,\n",
       "  0.9843405921213604,\n",
       "  1.0,\n",
       "  0.9838993710691823,\n",
       "  1.0,\n",
       "  0.9831888626214866,\n",
       "  1.0,\n",
       "  0.9843405921213604,\n",
       "  0.967967967967968,\n",
       "  0.9834668044432963,\n",
       "  0.9840597758405978,\n",
       "  0.9834668044432963,\n",
       "  0.9838993710691823,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9834668044432963,\n",
       "  1.0,\n",
       "  0.967967967967968,\n",
       "  0.9843711843711844,\n",
       "  0.9834668044432963,\n",
       "  0.9841858166543118,\n",
       "  0.9841858166543118,\n",
       "  1.0,\n",
       "  0.9842790469172193,\n",
       "  1.0,\n",
       "  0.9676113360323886,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9842790469172193,\n",
       "  0.9838993710691823,\n",
       "  1.0,\n",
       "  0.9831888626214866,\n",
       "  1.0,\n",
       "  0.96875,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.96875,\n",
       "  1.0,\n",
       "  0.9834668044432963,\n",
       "  1.0,\n",
       "  0.9842790469172193,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9653679653679654,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9842790469172193,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9684729064039409,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9511077158135981,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9843711843711844,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9840597758405978,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9676113360323886,\n",
       "  0.9687194525904204,\n",
       "  0.983702571937866,\n",
       "  0.9843405921213604,\n",
       "  0.9843405921213604,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9842790469172193,\n",
       "  0.9842790469172193,\n",
       "  0.9840597758405978,\n",
       "  0.9531135531135531,\n",
       "  0.9828647925033467,\n",
       "  0.9843711843711844,\n",
       "  0.9843405921213604,\n",
       "  0.9838993710691823,\n",
       "  0.9684729064039409,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9842790469172193,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9687194525904204,\n",
       "  0.9671794871794872,\n",
       "  0.9834668044432963,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9841858166543118,\n",
       "  1.0,\n",
       "  0.967967967967968,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.951698113207547,\n",
       "  0.9687194525904204,\n",
       "  1.0,\n",
       "  0.9842790469172193,\n",
       "  0.9840597758405978,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9687194525904204,\n",
       "  1.0,\n",
       "  0.9840597758405978,\n",
       "  0.9671794871794872,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9838993710691823,\n",
       "  0.9843711843711844,\n",
       "  1.0,\n",
       "  0.9843711843711844,\n",
       "  0.9840597758405978,\n",
       "  0.9840597758405978,\n",
       "  0.9834668044432963,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.96875,\n",
       "  0.951698113207547,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9834668044432963,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9531135531135531,\n",
       "  0.9521793275217932,\n",
       "  0.983702571937866,\n",
       "  0.9671794871794872,\n",
       "  1.0,\n",
       "  0.9838993710691823,\n",
       "  1.0,\n",
       "  0.9842790469172193,\n",
       "  1.0,\n",
       "  0.9843405921213604,\n",
       "  0.9843711843711844,\n",
       "  0.9516981132075473,\n",
       "  0.9838993710691823,\n",
       "  1.0,\n",
       "  0.983702571937866,\n",
       "  1.0,\n",
       "  0.9834668044432963,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9840597758405978,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9687194525904204,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9671794871794872,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9842790469172193,\n",
       "  0.9843711843711844,\n",
       "  0.9843405921213604,\n",
       "  1.0,\n",
       "  0.9840597758405978,\n",
       "  0.9842790469172193,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9841858166543118,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9828647925033467,\n",
       "  0.9372549019607843,\n",
       "  1.0,\n",
       "  0.9531135531135531,\n",
       "  0.9843711843711844,\n",
       "  1.0,\n",
       "  0.9660657476139979,\n",
       "  0.9834668044432963,\n",
       "  0.9666666666666667,\n",
       "  0.9820577516119988,\n",
       "  0.9843711843711844,\n",
       "  0.9840597758405978,\n",
       "  1.0,\n",
       "  0.9530217763640813,\n",
       "  0.9687194525904204,\n",
       "  1.0,\n",
       "  0.9676113360323886,\n",
       "  1.0,\n",
       "  0.9676113360323887,\n",
       "  1.0,\n",
       "  0.9828647925033467,\n",
       "  0.9682539682539683,\n",
       "  1.0,\n",
       "  0.983702571937866,\n",
       "  0.9842790469172193,\n",
       "  0.9843711843711844,\n",
       "  0.9843711843711844,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9843405921213604,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9840597758405978,\n",
       "  1.0,\n",
       "  0.96875,\n",
       "  0.9636363636363636,\n",
       "  0.9840597758405978,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.967967967967968,\n",
       "  1.0,\n",
       "  0.9841858166543118,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9687194525904204,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9824897400820793,\n",
       "  0.9843711843711844,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9840597758405978,\n",
       "  0.9843405921213604,\n",
       "  0.952837140751658,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9843711843711844,\n",
       "  1.0,\n",
       "  0.983702571937866,\n",
       "  1.0,\n",
       "  0.9687194525904204,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9843405921213604,\n",
       "  1.0,\n",
       "  0.9840597758405978,\n",
       "  1.0,\n",
       "  0.9843711843711844,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9843405921213604,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9841858166543118,\n",
       "  0.9682539682539683,\n",
       "  1.0,\n",
       "  0.9841858166543118,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9843711843711844,\n",
       "  0.967967967967968,\n",
       "  1.0,\n",
       "  0.9828647925033467,\n",
       "  0.9840597758405978,\n",
       "  0.9841858166543118,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9842790469172193,\n",
       "  0.9841858166543118,\n",
       "  1.0,\n",
       "  0.9840597758405978,\n",
       "  0.9838993710691823,\n",
       "  0.967967967967968,\n",
       "  1.0,\n",
       "  0.983702571937866,\n",
       "  0.9838993710691823,\n",
       "  0.9841858166543118,\n",
       "  1.0,\n",
       "  0.96875,\n",
       "  0.9676113360323887,\n",
       "  1.0,\n",
       "  0.980991980991981,\n",
       "  1.0,\n",
       "  0.9687194525904204,\n",
       "  0.9840597758405978,\n",
       "  0.9840597758405978,\n",
       "  1.0,\n",
       "  0.9687194525904204,\n",
       "  0.9666666666666667,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9843711843711844,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9843405921213604,\n",
       "  1.0,\n",
       "  0.9374389051808407,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9843405921213604,\n",
       "  0.9525574499629356,\n",
       "  0.9687194525904204,\n",
       "  1.0,\n",
       "  0.9834668044432963,\n",
       "  0.9843711843711844,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9843711843711844,\n",
       "  1.0,\n",
       "  0.983702571937866,\n",
       "  0.9840597758405978,\n",
       "  0.9843711843711844,\n",
       "  0.9842790469172193,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9838993710691823,\n",
       "  1.0,\n",
       "  0.9841858166543118,\n",
       "  1.0,\n",
       "  0.9842790469172193,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9525574499629356,\n",
       "  1.0,\n",
       "  0.9843711843711844,\n",
       "  0.9671794871794872,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9684729064039409,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.967967967967968,\n",
       "  0.9525574499629356,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9843405921213604,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9687194525904204,\n",
       "  0.9842790469172193,\n",
       "  0.9843405921213604,\n",
       "  0.9842790469172193,\n",
       "  1.0,\n",
       "  0.952837140751658,\n",
       "  1.0,\n",
       "  0.9834668044432963,\n",
       "  0.9843711843711844,\n",
       "  0.9841858166543118,\n",
       "  1.0,\n",
       "  0.9843405921213604,\n",
       "  1.0,\n",
       "  0.9660657476139979,\n",
       "  0.9841858166543118,\n",
       "  0.9840597758405978,\n",
       "  0.9682539682539683,\n",
       "  0.9365079365079365,\n",
       "  1.0,\n",
       "  0.9842790469172193,\n",
       "  1.0,\n",
       "  0.9843405921213604,\n",
       "  0.9687194525904204,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9834668044432963,\n",
       "  0.9653679653679654,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9843405921213604,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9842790469172193,\n",
       "  0.9531135531135531,\n",
       "  0.9843405921213604,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9687194525904204,\n",
       "  1.0,\n",
       "  0.9352226720647773,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.967967967967968,\n",
       "  0.9843405921213604,\n",
       "  0.9843405921213604,\n",
       "  1.0,\n",
       "  0.983702571937866,\n",
       "  1.0,\n",
       "  0.9841858166543118,\n",
       "  0.9841858166543118,\n",
       "  1.0,\n",
       "  0.9682539682539683,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9511077158135981,\n",
       "  1.0,\n",
       "  0.96875,\n",
       "  0.9684729064039409,\n",
       "  1.0,\n",
       "  0.9841858166543118,\n",
       "  1.0,\n",
       "  0.9834668044432963,\n",
       "  0.9842790469172193,\n",
       "  0.9842790469172193,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9824897400820793,\n",
       "  1.0,\n",
       "  0.968627450980392,\n",
       "  0.9687194525904204,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9834668044432963,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.967967967967968,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9687194525904204,\n",
       "  0.9843405921213604,\n",
       "  0.9840597758405978,\n",
       "  1.0,\n",
       "  0.9843711843711844,\n",
       "  0.9841858166543118,\n",
       "  0.9838993710691823,\n",
       "  1.0,\n",
       "  0.952837140751658,\n",
       "  0.9841858166543118,\n",
       "  0.9841858166543118,\n",
       "  0.9842790469172193,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9834668044432963,\n",
       "  0.9841858166543118,\n",
       "  1.0,\n",
       "  0.9841858166543118,\n",
       "  0.96875,\n",
       "  0.9842790469172193,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9841858166543118,\n",
       "  0.9686274509803922,\n",
       "  0.9666666666666667,\n",
       "  1.0,\n",
       "  0.9842790469172193,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9684729064039409,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9843405921213604,\n",
       "  1.0,\n",
       "  0.9843711843711844,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9843711843711844,\n",
       "  1.0,\n",
       "  0.9653679653679654,\n",
       "  0.983702571937866,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9528371407516582,\n",
       "  1.0,\n",
       "  0.968627450980392,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9687194525904204,\n",
       "  0.9521793275217932,\n",
       "  0.9840597758405978,\n",
       "  0.9841858166543118,\n",
       "  1.0,\n",
       "  0.9828647925033467,\n",
       "  0.9838993710691823,\n",
       "  0.980991980991981,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9525574499629356,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9842790469172193,\n",
       "  0.9834668044432963,\n",
       "  1.0,\n",
       "  0.9684729064039409,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9838993710691823,\n",
       "  1.0,\n",
       "  0.9682539682539683,\n",
       "  0.9843405921213604,\n",
       "  0.9840597758405978,\n",
       "  1.0,\n",
       "  0.9666666666666667,\n",
       "  1.0,\n",
       "  0.9531135531135531,\n",
       "  1.0,\n",
       "  0.9840597758405978,\n",
       "  1.0,\n",
       "  0.9687194525904204,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9841858166543118,\n",
       "  0.9684729064039409,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9842790469172193,\n",
       "  1.0,\n",
       "  0.9684729064039409,\n",
       "  0.980991980991981,\n",
       "  0.9842790469172193,\n",
       "  0.9687194525904204,\n",
       "  1.0,\n",
       "  0.9372549019607843,\n",
       "  0.96875,\n",
       "  0.9838993710691823,\n",
       "  0.983702571937866,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9687194525904204,\n",
       "  0.983702571937866,\n",
       "  1.0,\n",
       "  0.9671794871794872,\n",
       "  0.9834668044432963,\n",
       "  0.9840597758405978,\n",
       "  0.9843711843711844,\n",
       "  0.9843405921213604,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9530217763640814,\n",
       "  0.9828647925033467,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.983702571937866,\n",
       "  0.9843405921213604,\n",
       "  1.0,\n",
       "  0.9843711843711844,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9687194525904204,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9686274509803922,\n",
       "  0.9843711843711844,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9843711843711844,\n",
       "  0.9841858166543118,\n",
       "  1.0,\n",
       "  0.9671794871794872,\n",
       "  1.0,\n",
       "  0.9842790469172193,\n",
       "  0.9843711843711844,\n",
       "  0.951698113207547,\n",
       "  0.9843711843711844,\n",
       "  1.0,\n",
       "  0.9838993710691823,\n",
       "  1.0,\n",
       "  0.967967967967968,\n",
       "  0.9843405921213604,\n",
       "  0.9653679653679654,\n",
       "  0.9671794871794872,\n",
       "  1.0,\n",
       "  0.9682539682539683,\n",
       "  0.9684729064039409,\n",
       "  1.0,\n",
       "  0.9843405921213604,\n",
       "  0.9843405921213604,\n",
       "  1.0,\n",
       "  0.9843405921213604,\n",
       "  0.983702571937866,\n",
       "  0.9840597758405978,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.967967967967968,\n",
       "  0.9516981132075473,\n",
       "  0.9841858166543118,\n",
       "  1.0,\n",
       "  0.9504004133298889,\n",
       "  0.9840597758405978,\n",
       "  0.9843405921213604,\n",
       "  0.983702571937866,\n",
       "  1.0,\n",
       "  0.9843711843711844,\n",
       "  0.983702571937866,\n",
       "  0.9841858166543118,\n",
       "  0.9843405921213604,\n",
       "  1.0,\n",
       "  0.9841858166543118,\n",
       "  1.0,\n",
       "  0.9687194525904204,\n",
       "  0.9842790469172193,\n",
       "  1.0,\n",
       "  0.9682539682539683,\n",
       "  0.951698113207547,\n",
       "  0.9841858166543118,\n",
       "  0.9687194525904204,\n",
       "  0.9820577516119988,\n",
       "  0.9843405921213604,\n",
       "  0.968627450980392,\n",
       "  0.9684729064039409,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9843405921213604,\n",
       "  1.0,\n",
       "  0.9843405921213604,\n",
       "  0.9838993710691823,\n",
       "  0.983702571937866,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9671794871794872,\n",
       "  0.9840597758405978,\n",
       "  0.9828647925033467,\n",
       "  1.0,\n",
       "  0.9676113360323886,\n",
       "  0.9531135531135531,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9843405921213604,\n",
       "  1.0,\n",
       "  0.9838993710691823,\n",
       "  0.9842790469172193,\n",
       "  0.9838993710691823,\n",
       "  0.9843711843711844,\n",
       "  0.9831888626214866,\n",
       "  0.9843711843711844,\n",
       "  0.9843405921213604,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9843711843711844,\n",
       "  0.9841858166543118,\n",
       "  1.0,\n",
       "  0.9840597758405978,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9671794871794872,\n",
       "  0.9842790469172193,\n",
       "  0.968627450980392,\n",
       "  0.9838993710691823,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9843711843711844,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  ...],\n",
       " [1.0,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.984375,\n",
       "  0.984375,\n",
       "  0.96875,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  0.96875,\n",
       "  0.96875,\n",
       "  0.984375,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  0.984375,\n",
       "  0.96875,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  0.984375,\n",
       "  0.953125,\n",
       "  1.0,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.984375,\n",
       "  0.984375,\n",
       "  0.96875,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.984375,\n",
       "  0.984375,\n",
       "  0.96875,\n",
       "  1.0,\n",
       "  0.96875,\n",
       "  0.984375,\n",
       "  0.984375,\n",
       "  0.96875,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.96875,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.984375,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  0.984375,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  0.96875,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.984375,\n",
       "  0.96875,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.984375,\n",
       "  0.984375,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.984375,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  0.984375,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  0.984375,\n",
       "  0.984375,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  0.953125,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  0.96875,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.96875,\n",
       "  1.0,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  0.9375,\n",
       "  0.96875,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  0.984375,\n",
       "  0.984375,\n",
       "  0.96875,\n",
       "  1.0,\n",
       "  0.984375,\n",
       "  0.96875,\n",
       "  0.953125,\n",
       "  1.0,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.96875,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.984375,\n",
       "  0.984375,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  0.984375,\n",
       "  0.984375,\n",
       "  0.96875,\n",
       "  0.953125,\n",
       "  0.984375,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.96875,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  0.984375,\n",
       "  0.984375,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.984375,\n",
       "  0.96875,\n",
       "  1.0,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.984375,\n",
       "  0.96875,\n",
       "  0.953125,\n",
       "  1.0,\n",
       "  0.96875,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.984375,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.953125,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  0.984375,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  0.953125,\n",
       "  0.984375,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  0.984375,\n",
       "  0.984375,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  0.96875,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.96875,\n",
       "  0.96875,\n",
       "  0.96875,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.984375,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.984375,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.984375,\n",
       "  0.96875,\n",
       "  0.96875,\n",
       "  1.0,\n",
       "  0.96875,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.96875,\n",
       "  1.0,\n",
       "  0.96875,\n",
       "  0.96875,\n",
       "  0.984375,\n",
       "  0.96875,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.953125,\n",
       "  0.984375,\n",
       "  0.9375,\n",
       "  1.0,\n",
       "  0.96875,\n",
       "  0.96875,\n",
       "  0.984375,\n",
       "  0.984375,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.984375,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.984375,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.96875,\n",
       "  1.0,\n",
       "  0.984375,\n",
       "  0.984375,\n",
       "  0.96875,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.984375,\n",
       "  0.96875,\n",
       "  1.0,\n",
       "  0.96875,\n",
       "  0.984375,\n",
       "  0.96875,\n",
       "  0.96875,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.984375,\n",
       "  0.984375,\n",
       "  0.984375,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.984375,\n",
       "  0.953125,\n",
       "  0.984375,\n",
       "  0.984375,\n",
       "  0.984375,\n",
       "  0.984375,\n",
       "  0.984375,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  0.984375,\n",
       "  0.96875,\n",
       "  0.984375,\n",
       "  0.984375,\n",
       "  0.984375,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  0.96875,\n",
       "  0.984375,\n",
       "  0.984375,\n",
       "  0.984375,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  0.96875,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.984375,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  0.96875,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.96875,\n",
       "  1.0,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.96875,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.96875,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.953125,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.96875,\n",
       "  0.96875,\n",
       "  0.984375,\n",
       "  0.984375,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.984375,\n",
       "  0.984375,\n",
       "  0.984375,\n",
       "  0.953125,\n",
       "  0.984375,\n",
       "  0.984375,\n",
       "  0.984375,\n",
       "  0.984375,\n",
       "  0.96875,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.96875,\n",
       "  0.96875,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  0.96875,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.953125,\n",
       "  0.96875,\n",
       "  1.0,\n",
       "  0.984375,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.96875,\n",
       "  1.0,\n",
       "  0.984375,\n",
       "  0.96875,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.984375,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  0.984375,\n",
       "  0.984375,\n",
       "  0.984375,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.96875,\n",
       "  0.953125,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.953125,\n",
       "  0.953125,\n",
       "  0.984375,\n",
       "  0.96875,\n",
       "  1.0,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  0.984375,\n",
       "  0.984375,\n",
       "  0.953125,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.96875,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.96875,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.984375,\n",
       "  0.984375,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  0.984375,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.984375,\n",
       "  0.9375,\n",
       "  1.0,\n",
       "  0.953125,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  0.96875,\n",
       "  0.984375,\n",
       "  0.96875,\n",
       "  0.984375,\n",
       "  0.984375,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  0.953125,\n",
       "  0.96875,\n",
       "  1.0,\n",
       "  0.96875,\n",
       "  1.0,\n",
       "  0.96875,\n",
       "  1.0,\n",
       "  0.984375,\n",
       "  0.96875,\n",
       "  1.0,\n",
       "  0.984375,\n",
       "  0.984375,\n",
       "  0.984375,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  0.96875,\n",
       "  0.96875,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.96875,\n",
       "  1.0,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.96875,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.984375,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.984375,\n",
       "  0.984375,\n",
       "  0.953125,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  0.96875,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.984375,\n",
       "  0.96875,\n",
       "  1.0,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.984375,\n",
       "  0.96875,\n",
       "  1.0,\n",
       "  0.984375,\n",
       "  0.984375,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.984375,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  0.984375,\n",
       "  0.984375,\n",
       "  0.96875,\n",
       "  1.0,\n",
       "  0.984375,\n",
       "  0.984375,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  0.96875,\n",
       "  0.96875,\n",
       "  1.0,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  0.96875,\n",
       "  0.984375,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  0.96875,\n",
       "  0.96875,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  0.9375,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.984375,\n",
       "  0.953125,\n",
       "  0.96875,\n",
       "  1.0,\n",
       "  0.984375,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  0.984375,\n",
       "  0.984375,\n",
       "  0.984375,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.953125,\n",
       "  1.0,\n",
       "  0.984375,\n",
       "  0.96875,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.96875,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.96875,\n",
       "  0.953125,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.96875,\n",
       "  0.984375,\n",
       "  0.984375,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  0.953125,\n",
       "  1.0,\n",
       "  0.984375,\n",
       "  0.984375,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  0.96875,\n",
       "  0.984375,\n",
       "  0.984375,\n",
       "  0.96875,\n",
       "  0.9375,\n",
       "  1.0,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  0.984375,\n",
       "  0.96875,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.984375,\n",
       "  0.96875,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.984375,\n",
       "  0.953125,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.96875,\n",
       "  1.0,\n",
       "  0.9375,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.96875,\n",
       "  0.984375,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  0.984375,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  0.96875,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.953125,\n",
       "  1.0,\n",
       "  0.96875,\n",
       "  0.96875,\n",
       "  1.0,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  0.984375,\n",
       "  0.984375,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  0.96875,\n",
       "  0.96875,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.96875,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.96875,\n",
       "  0.984375,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  0.984375,\n",
       "  0.984375,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  0.953125,\n",
       "  0.984375,\n",
       "  0.984375,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.984375,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  0.984375,\n",
       "  0.96875,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.984375,\n",
       "  0.96875,\n",
       "  0.96875,\n",
       "  1.0,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.96875,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  0.96875,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.953125,\n",
       "  1.0,\n",
       "  0.96875,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.96875,\n",
       "  0.953125,\n",
       "  0.984375,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  0.984375,\n",
       "  0.984375,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.953125,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.984375,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  0.96875,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  0.96875,\n",
       "  0.984375,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  0.96875,\n",
       "  1.0,\n",
       "  0.953125,\n",
       "  1.0,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  0.96875,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.984375,\n",
       "  0.96875,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  0.96875,\n",
       "  0.984375,\n",
       "  0.984375,\n",
       "  0.96875,\n",
       "  1.0,\n",
       "  0.9375,\n",
       "  0.96875,\n",
       "  0.984375,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.96875,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  0.96875,\n",
       "  0.984375,\n",
       "  0.984375,\n",
       "  0.984375,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.953125,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.984375,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.96875,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.96875,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.984375,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  0.96875,\n",
       "  1.0,\n",
       "  0.984375,\n",
       "  0.984375,\n",
       "  0.953125,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  0.96875,\n",
       "  0.984375,\n",
       "  0.96875,\n",
       "  0.96875,\n",
       "  1.0,\n",
       "  0.96875,\n",
       "  0.96875,\n",
       "  1.0,\n",
       "  0.984375,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  0.984375,\n",
       "  0.984375,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.96875,\n",
       "  0.953125,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  0.953125,\n",
       "  0.984375,\n",
       "  0.984375,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  0.984375,\n",
       "  0.984375,\n",
       "  0.984375,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  0.96875,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  0.96875,\n",
       "  0.953125,\n",
       "  0.984375,\n",
       "  0.96875,\n",
       "  0.984375,\n",
       "  0.984375,\n",
       "  0.96875,\n",
       "  0.96875,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  0.984375,\n",
       "  0.984375,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.96875,\n",
       "  0.984375,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  0.96875,\n",
       "  0.953125,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  0.984375,\n",
       "  0.984375,\n",
       "  0.984375,\n",
       "  0.984375,\n",
       "  0.984375,\n",
       "  0.984375,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.984375,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.96875,\n",
       "  0.984375,\n",
       "  0.96875,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.984375,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  ...])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_metrics(dataGeneratorTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.8230120314303593],\n",
       " [0.8265459602989258],\n",
       " [0.8138184762114316],\n",
       " [0.8139194464158978])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_metrics(dataGeneratorVal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pList, rList, fList, accList = get_metrics(dataGeneratorTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8226786962065603"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pArr = np.array(pList)\n",
    "pArr.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8264853246357611"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rArr = np.array(rList)\n",
    "rArr.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8111749478177027"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fArr = np.array(fList)\n",
    "fArr.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8136508498583569"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accArr = np.array(accList)\n",
    "accArr.mean()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
