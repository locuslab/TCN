{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import sys\n",
    "sys.path.append(\"../../\")\n",
    "from TCN.mnist_pixel.utils import data_generator\n",
    "from TCN.mnist_pixel.modeltcan import TCAN\n",
    "import numpy as np\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def customOneHotEncoder(data):\n",
    "    dataAdjust = data.ljust(200,'0')[:200] # padding if not of length and adjusting the data lenght to get a 200x39 input matrix\n",
    "    # define universe of possible input values\n",
    "    alphabet = '0123456789abcdefghijklmnopqrstuvwxyz,._'\n",
    "    # define a mapping of chars to integers\n",
    "    char_to_int = dict((c, i) for i, c in enumerate(alphabet))\n",
    "    int_to_char = dict((i, c) for i, c in enumerate(alphabet))\n",
    "    # integer encode input data\n",
    "    integer_encoded = [char_to_int[char] for char in dataAdjust]\n",
    "    #print(integer_encoded)\n",
    "    # one hot encode\n",
    "    onehot_encoded = list()\n",
    "    for i, value in enumerate(integer_encoded):\n",
    "        letter = [0 for _ in range(len(alphabet))]\n",
    "        letter[value] = 1\n",
    "        onehot_encoded.append(letter)\n",
    "    #print(onehot_encoded) # the real encoding\n",
    "    return onehot_encoded\n",
    "\n",
    "# takes a .csv filename\n",
    "def dataPreprocessing(fileName):\n",
    "    df = pd.read_csv(fileName, header = None)\n",
    "    \n",
    "    #prepare the imput data\n",
    "    xString = df.iloc[:,:41].to_string(header=False, index=False, index_names = False).split('\\n')\n",
    "    xList = [','.join(ele.split()) for ele in xString] # gives comma separated strings for each row of DataFrame\n",
    "    xData = []\n",
    "    for string in xList:\n",
    "        stringLower = string.lower()\n",
    "        oneHot = customOneHotEncoder(stringLower)\n",
    "        xData.append(oneHot)\n",
    "    xMid = np.array(xData)\n",
    "    xArray = xMid.transpose(0,2,1) # convert xMid's dim (size, 200, 39) to (size, 39, 200)\n",
    "    \n",
    "    #prepare the label data\n",
    "    df[41] = np.where(df[41]=='normal', 'normal', 'attack') # replacing anything except 'normal' with 'attack'\n",
    "    Ydf = df[41]\n",
    "    #labelName = Ydf.unique().tolist().sort() # sorted 38 label names\n",
    "    #yArray = Ydf.str.get_dummies().to_numpy() # ndarray of shape(rows/lines, 38)\n",
    "    yArray = Ydf.to_numpy()\n",
    "    \n",
    "    assert xArray.shape[0] == yArray.shape[0], 'unequal input and label sample size'\n",
    "    \n",
    "    \n",
    "    return xArray, yArray # return processed array of input and label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class NSLKDDDataset(Dataset):\n",
    "    def __init__(self, fileName):\n",
    "        self.data = pd.read_csv(fileName, header = None)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # prepare x data\n",
    "        print(\"value of idx is %f \" %idx)\n",
    "        string = list(','.join('%s' %x for x in y) for y in self.data.iloc[[idx], :41].values)\n",
    "        stringLower = string[0].lower()\n",
    "        xData = customOneHotEncoder(stringLower) # Dim (200, 39)\n",
    "        xMid = np.array(xData)\n",
    "        xArray = xMid.transpose() # should be now (39, 200)\n",
    "        \n",
    "        # prepate y data\n",
    "        #self.data.iloc[idx, 41] = np.where(self.data.iloc[idx, 41]=='normal', 0, 1) # replacing normals with 0 and anything else with 1\n",
    "        yArray = np.where(self.data.iloc[idx, 41]=='normal', 0, 1)\n",
    "        \n",
    "        #yArray = Ydf.to_numpy()\n",
    "    \n",
    "        #assert xArray.shape == yArray.shape, 'unequal input and label sample size'\n",
    "        \n",
    "        return torch.from_numpy(xArray), torch.from_numpy(yArray) # returns torch tensor of x and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'batch_size': 64, 'shuffle': True}\n",
    "fileNameTrain = 'UNSW_NB15_training-set.csv'\n",
    "fileNameTest = 'UNSW_NB15_testing-set.csv'\n",
    "datasetTrain = NSLKDDDataset(fileNameTrain)\n",
    "datasetTest = NSLKDDDataset(fileNameTest)\n",
    "dataGeneratorTrain = DataLoader(datasetTrain, **params)\n",
    "dataGeneratorTest = DataLoader(datasetTest, **params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0         1    2  3    4   5   6      7    8              9   ...  \\\n",
      "0          1  0.000011  udp  -  INT   2   0    496    0   90909.090200  ...   \n",
      "1          2  0.000008  udp  -  INT   2   0   1762    0  125000.000300  ...   \n",
      "2          3  0.000005  udp  -  INT   2   0   1068    0  200000.005100  ...   \n",
      "3          4  0.000006  udp  -  INT   2   0    900    0  166666.660800  ...   \n",
      "4          5  0.000010  udp  -  INT   2   0   2126    0  100000.002500  ...   \n",
      "...      ...       ...  ... ..  ...  ..  ..    ...  ...            ...  ...   \n",
      "82327  82328  0.000005  udp  -  INT   2   0    104    0  200000.005100  ...   \n",
      "82328  82329  1.106101  tcp  -  FIN  20   8  18062  354      24.410067  ...   \n",
      "82329  82330  0.000000  arp  -  INT   1   0     46    0       0.000000  ...   \n",
      "82330  82331  0.000000  arp  -  INT   1   0     46    0       0.000000  ...   \n",
      "82331  82332  0.000009  udp  -  INT   2   0    104    0  111111.107200  ...   \n",
      "\n",
      "       35  36  37  38  39  40  41  42      43  44  \n",
      "0       1   2   0   0   0   1   2   0  Normal   0  \n",
      "1       1   2   0   0   0   1   2   0  Normal   0  \n",
      "2       1   3   0   0   0   1   3   0  Normal   0  \n",
      "3       1   3   0   0   0   2   3   0  Normal   0  \n",
      "4       1   3   0   0   0   2   3   0  Normal   0  \n",
      "...    ..  ..  ..  ..  ..  ..  ..  ..     ...  ..  \n",
      "82327   1   2   0   0   0   2   1   0  Normal   0  \n",
      "82328   1   1   0   0   0   3   2   0  Normal   0  \n",
      "82329   1   1   0   0   0   1   1   1  Normal   0  \n",
      "82330   1   1   0   0   0   1   1   1  Normal   0  \n",
      "82331   1   1   0   0   0   1   1   0  Normal   0  \n",
      "\n",
      "[82332 rows x 45 columns]\n"
     ]
    }
   ],
   "source": [
    "a = pd.read_csv('UNSW_NB15_training-set.csv', header = None)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        0    1         2   3     4     5   6   7   8   9   ...    33    34  \\\n",
      "0        0  tcp  ftp_data  SF   491     0   0   0   0   0  ...  0.17  0.03   \n",
      "1        0  udp     other  SF   146     0   0   0   0   0  ...  0.00  0.60   \n",
      "2        0  tcp   private  S0     0     0   0   0   0   0  ...  0.10  0.05   \n",
      "3        0  tcp      http  SF   232  8153   0   0   0   0  ...  1.00  0.00   \n",
      "4        0  tcp      http  SF   199   420   0   0   0   0  ...  1.00  0.00   \n",
      "...     ..  ...       ...  ..   ...   ...  ..  ..  ..  ..  ...   ...   ...   \n",
      "125968   0  tcp   private  S0     0     0   0   0   0   0  ...  0.10  0.06   \n",
      "125969   8  udp   private  SF   105   145   0   0   0   0  ...  0.96  0.01   \n",
      "125970   0  tcp      smtp  SF  2231   384   0   0   0   0  ...  0.12  0.06   \n",
      "125971   0  tcp    klogin  S0     0     0   0   0   0   0  ...  0.03  0.05   \n",
      "125972   0  tcp  ftp_data  SF   151     0   0   0   0   0  ...  0.30  0.03   \n",
      "\n",
      "          35    36    37    38    39    40       41  42  \n",
      "0       0.17  0.00  0.00  0.00  0.05  0.00   normal  20  \n",
      "1       0.88  0.00  0.00  0.00  0.00  0.00   normal  15  \n",
      "2       0.00  0.00  1.00  1.00  0.00  0.00  neptune  19  \n",
      "3       0.03  0.04  0.03  0.01  0.00  0.01   normal  21  \n",
      "4       0.00  0.00  0.00  0.00  0.00  0.00   normal  21  \n",
      "...      ...   ...   ...   ...   ...   ...      ...  ..  \n",
      "125968  0.00  0.00  1.00  1.00  0.00  0.00  neptune  20  \n",
      "125969  0.01  0.00  0.00  0.00  0.00  0.00   normal  21  \n",
      "125970  0.00  0.00  0.72  0.00  0.01  0.00   normal  18  \n",
      "125971  0.00  0.00  1.00  1.00  0.00  0.00  neptune  20  \n",
      "125972  0.30  0.00  0.00  0.00  0.00  0.00   normal  21  \n",
      "\n",
      "[125973 rows x 43 columns]\n"
     ]
    }
   ],
   "source": [
    "b = pd.read_csv('KDDTrain+.csv', header = None)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
